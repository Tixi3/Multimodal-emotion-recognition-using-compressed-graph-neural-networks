{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOoFPHYFNUFvlmYUuxErjjI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5myReDyIz_8r","executionInfo":{"status":"ok","timestamp":1725098899177,"user_tz":-120,"elapsed":33210,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"3f732c1f-9c43-41d6-808d-612ab0a89e3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Master_2023_sept/COGMEN-main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jncFGbZ70KLy","executionInfo":{"status":"ok","timestamp":1725098909942,"user_tz":-120,"elapsed":310,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"6b497761-8833-4727-a3b9-b3d43bb83b2d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Master_2023_sept/COGMEN-main\n"]}]},{"cell_type":"code","source":["\n","!pip3 install torch torchvision #--use-deprecated=legacy-resolver\n","!pip3 install torchaudio #--use-deprecated=legacy-resolver\n","!pip3 install -U torch_geometric #--use-deprecated=legacy-resolver\n","!pip3 install comet_ml #--upgrade --quiet --use-deprecated=legacy-resolver\n","!pip3 install -U sentence-transformers #--use-deprecated=legacy-resolver"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFdTppGf0Q1P","executionInfo":{"status":"ok","timestamp":1725098944343,"user_tz":-120,"elapsed":19270,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"403c4216-bcdf-4ce5-a036-3d46e0711d69"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchaudio) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchaudio) (1.3.0)\n","Collecting torch_geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n","Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.5.3\n","Collecting comet_ml\n","  Downloading comet_ml-3.45.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.23.0)\n","Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n","Collecting python-box<7.0.0 (from comet_ml)\n","  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n","Collecting requests-toolbelt>=0.8.0 (from comet_ml)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.32.3)\n","Collecting semantic-version>=2.8.0 (from comet_ml)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting sentry-sdk>=1.1.0 (from comet_ml)\n","  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting simplejson (from comet_ml)\n","  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.0.7)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n","Collecting wurlitzer>=1.0.2 (from comet_ml)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n","  Downloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.8.0)\n","Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Downloading configobj-5.0.8-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.20.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.7.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet_ml) (1.16.0)\n","Downloading comet_ml-3.45.0-py3-none-any.whl (687 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m687.3/687.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (979 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n","Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n","Installing collected packages: everett, wurlitzer, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n","  Attempting uninstall: python-box\n","    Found existing installation: python-box 7.2.0\n","    Uninstalling python-box-7.2.0:\n","      Successfully uninstalled python-box-7.2.0\n","Successfully installed comet_ml-3.45.0 configobj-5.0.8 dulwich-0.22.1 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-2.13.0 simplejson-3.19.3 wurlitzer-3.1.1\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","Successfully installed sentence-transformers-3.0.1\n"]}]},{"cell_type":"code","source":["!python eval_FP8_mil.py --dataset=\"iemocap_4\" --modalities=\"atv\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9OWVDJ414wA","executionInfo":{"status":"ok","timestamp":1725056575115,"user_tz":-120,"elapsed":12615,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"41140da2-0ea8-4bc7-d443-1e6cf4e52a26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-08-30 22:22:46.030909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-30 22:22:46.050702: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-30 22:22:46.056836: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-30 22:22:47.309116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","comet_ml is installed but `COMET_API_KEY` is not set.\n","/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_FP8_mil.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_dict = torch.load(\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_FP8_mil.py\", line 249, in <module>\n","    main(args)\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_FP8_mil.py\", line 81, in main\n","    model_dict = torch.load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1097, in load\n","    return _load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1525, in _load\n","    result = unpickler.load()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1515, in find_class\n","    return super().find_class(mod_name, name)\n","ModuleNotFoundError: No module named 'torch_geometric.nn.conv.utils.inspector'\n"]}]},{"cell_type":"code","source":["!python eval_bin_mil.py --dataset=\"iemocap_4\" --modalities=\"atv\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQyoC9kC_sOQ","executionInfo":{"status":"ok","timestamp":1725055803565,"user_tz":-120,"elapsed":13602,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"a15b60fc-012e-4d48-c048-eec766b29389"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-08-30 22:09:54.117340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-30 22:09:54.138357: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-30 22:09:54.144264: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-30 22:09:54.158546: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-08-30 22:09:55.392170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","comet_ml is installed but `COMET_API_KEY` is not set.\n","/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_bin_mil.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_dict = torch.load(\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_bin_mil.py\", line 199, in <module>\n","    main(args)\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_bin_mil.py\", line 49, in main\n","    model_dict = torch.load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1097, in load\n","    return _load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1525, in _load\n","    result = unpickler.load()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1515, in find_class\n","    return super().find_class(mod_name, name)\n","ModuleNotFoundError: No module named 'torch_geometric.nn.conv.utils.inspector'\n"]}]},{"cell_type":"code","source":["!python eval_bin_svi.py --dataset=\"iemocap_4\" --modalities=\"atv\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"godNdHgE51Hz","executionInfo":{"status":"ok","timestamp":1725055827361,"user_tz":-120,"elapsed":13351,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"fb94b230-ccf5-4a3a-b8a4-b2caee1ddfcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-08-30 22:10:18.394442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-30 22:10:18.415052: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-30 22:10:18.421028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-30 22:10:18.435025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-08-30 22:10:19.669564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","comet_ml is installed but `COMET_API_KEY` is not set.\n","/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_bin_svi.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_dict = torch.load(\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_bin_svi.py\", line 233, in <module>\n","    main(args)\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_bin_svi.py\", line 81, in main\n","    model_dict = torch.load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1097, in load\n","    return _load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1525, in _load\n","    result = unpickler.load()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1515, in find_class\n","    return super().find_class(mod_name, name)\n","ModuleNotFoundError: No module named 'torch_geometric.nn.conv.utils.inspector'\n"]}]},{"cell_type":"code","source":["!python eval_FP8_svi.py --dataset=\"iemocap_4\" --modalities=\"atv\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00gtWxvjBLaf","executionInfo":{"status":"ok","timestamp":1725055854611,"user_tz":-120,"elapsed":13440,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"69683127-c788-4ca2-93b3-14a348523841"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-08-30 22:10:45.429215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-30 22:10:45.451157: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-30 22:10:45.457329: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-30 22:10:45.472867: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-08-30 22:10:46.717980: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","comet_ml is installed but `COMET_API_KEY` is not set.\n","/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_FP8_svi.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_dict = torch.load(\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_FP8_svi.py\", line 234, in <module>\n","    main(args)\n","  File \"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/eval_FP8_svi.py\", line 81, in main\n","    model_dict = torch.load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1097, in load\n","    return _load(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1525, in _load\n","    result = unpickler.load()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1515, in find_class\n","    return super().find_class(mod_name, name)\n","ModuleNotFoundError: No module named 'torch_geometric.nn.conv.utils.inspector'\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","!pip3 install torch-geometric<2.2.0\n","import torch_geometric"],"metadata":{"id":"5iG27Tl00Xsz","executionInfo":{"status":"ok","timestamp":1725100006310,"user_tz":-120,"elapsed":373,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3f16715-1964-49ed-f188-ea265d35b091"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: 2.2.0: No such file or directory\n"]}]},{"cell_type":"code","source":["model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/trained_model3.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":533},"id":"7Mp3ime80bVa","executionInfo":{"status":"error","timestamp":1725100011122,"user_tz":-120,"elapsed":715,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"e6e43d76-6e12-461e-942b-c092a75368b2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-abc098b37b9e>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/trained_model3.pt')\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric.nn.conv.utils.inspector'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-abc098b37b9e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Master_2023_sept/COGMEN-main/trained_model3.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1098\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     \u001b[0;31m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1513\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric.nn.conv.utils.inspector'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["weights1=[]\n","bias1=[]\n","def get_wb(model):\n","    for name, param in model.named_parameters():\n","        if 'weight' in name:\n","            print(f'Weight matrix for {name}:')\n","            print(param)\n","            weights1.append(param.view(-1))\n","        elif 'bias' in name:\n","            print(f'Bias vector for {name}:')\n","            print(param)\n","            bias1.append(param.view(-1))\n","    # print(weights_and_biases_vector)\n","    weights_vec=torch.cat(weights1)\n","    bias_vec=torch.cat(bias1)\n","    #print('weights vector')\n","    #print(weights_vec)\n","    #print('bias vector')\n","    return weights1, weights_vec, bias_vec"],"metadata":{"id":"bvNt1qzA0bys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights1, weights_vec, bias_vec = get_wb(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMKA76x80e2f","executionInfo":{"status":"ok","timestamp":1700604588924,"user_tz":-60,"elapsed":305,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"e5c0533b-1e51-4e6f-9bb9-760a245ecb36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weight matrix for rnn.encoding_layer.weight:\n","Parameter containing:\n","tensor([[-1.5405, -0.3515, -0.3186,  ...,  0.6964,  1.0487, -0.4811],\n","        [ 0.8839, -0.1836, -0.0400,  ...,  0.5956, -0.0908,  0.0568],\n","        [ 0.0724, -0.8025,  0.7511,  ...,  0.9484, -1.0034, -1.4723],\n","        ...,\n","        [ 1.0028,  0.0467, -0.6503,  ..., -0.5072, -0.6748,  1.6817],\n","        [ 1.0575, -0.2266,  0.2583,  ...,  0.2257, -0.0640,  0.3134],\n","        [-0.4202,  0.1140, -0.7010,  ...,  0.8381,  2.6865,  2.0627]],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.LayerNorm.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.LayerNorm.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.self_attn.in_proj_weight:\n","Parameter containing:\n","tensor([[-0.0259,  0.0252, -0.0164,  ...,  0.0188, -0.0027,  0.0262],\n","        [-0.0071,  0.0112, -0.0260,  ..., -0.0024,  0.0040,  0.0174],\n","        [-0.0320,  0.0311, -0.0278,  ...,  0.0122, -0.0134,  0.0101],\n","        ...,\n","        [ 0.0119, -0.0051,  0.0007,  ...,  0.0123, -0.0144,  0.0256],\n","        [ 0.0249, -0.0212,  0.0166,  ...,  0.0063, -0.0140,  0.0194],\n","        [ 0.0010,  0.0051, -0.0188,  ...,  0.0316,  0.0012, -0.0100]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.self_attn.in_proj_bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.self_attn.out_proj.weight:\n","Parameter containing:\n","tensor([[-0.0014, -0.0226, -0.0189,  ..., -0.0200, -0.0068,  0.0220],\n","        [ 0.0086,  0.0007,  0.0198,  ...,  0.0250,  0.0038, -0.0009],\n","        [ 0.0010, -0.0074, -0.0139,  ..., -0.0221,  0.0087, -0.0049],\n","        ...,\n","        [-0.0157, -0.0159,  0.0214,  ...,  0.0228,  0.0173, -0.0126],\n","        [-0.0174,  0.0208,  0.0102,  ..., -0.0101,  0.0187, -0.0011],\n","        [-0.0118,  0.0135,  0.0247,  ...,  0.0206, -0.0031, -0.0079]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.self_attn.out_proj.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.linear1.weight:\n","Parameter containing:\n","tensor([[-0.0084,  0.0118,  0.0040,  ..., -0.0175, -0.0062, -0.0097],\n","        [ 0.0020,  0.0058, -0.0152,  ..., -0.0127,  0.0120,  0.0075],\n","        [ 0.0050, -0.0022,  0.0027,  ...,  0.0217,  0.0047, -0.0232],\n","        ...,\n","        [-0.0251, -0.0140, -0.0253,  ..., -0.0110, -0.0251,  0.0013],\n","        [ 0.0171,  0.0218,  0.0146,  ...,  0.0206, -0.0252,  0.0053],\n","        [ 0.0104, -0.0117, -0.0199,  ..., -0.0194,  0.0004,  0.0190]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.linear1.bias:\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.linear2.weight:\n","Parameter containing:\n","tensor([[ 2.0869e-02, -8.5141e-03,  2.1004e-02,  ..., -1.8733e-03,\n","          1.1463e-02,  1.6535e-02],\n","        [-1.6825e-02,  1.6355e-02, -6.2599e-03,  ..., -4.5087e-05,\n","          1.2243e-02,  1.0091e-02],\n","        [ 3.3961e-04, -1.4036e-02, -6.5373e-03,  ..., -1.0413e-02,\n","         -1.9913e-03,  4.7169e-03],\n","        ...,\n","        [-2.0588e-02, -1.0654e-02,  1.2563e-02,  ...,  9.3520e-03,\n","          1.8594e-03,  7.0706e-03],\n","        [-6.6939e-03, -1.0174e-02, -5.4319e-03,  ...,  1.2738e-03,\n","          1.9165e-02, -2.0058e-02],\n","        [ 1.5700e-02, -6.7736e-03,  1.9677e-02,  ..., -8.6711e-03,\n","          4.6090e-03,  2.6161e-03]], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.linear2.bias:\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.norm1.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.norm1.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.norm2.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.norm2.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.self_attn.in_proj_weight:\n","Parameter containing:\n","tensor([[-0.0259,  0.0252, -0.0164,  ...,  0.0188, -0.0027,  0.0262],\n","        [-0.0071,  0.0112, -0.0260,  ..., -0.0024,  0.0040,  0.0174],\n","        [-0.0320,  0.0311, -0.0278,  ...,  0.0122, -0.0134,  0.0101],\n","        ...,\n","        [ 0.0119, -0.0051,  0.0007,  ...,  0.0123, -0.0144,  0.0256],\n","        [ 0.0249, -0.0212,  0.0166,  ...,  0.0063, -0.0140,  0.0194],\n","        [ 0.0010,  0.0051, -0.0188,  ...,  0.0316,  0.0012, -0.0100]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.self_attn.in_proj_bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.self_attn.out_proj.weight:\n","Parameter containing:\n","tensor([[-0.0014, -0.0226, -0.0189,  ..., -0.0200, -0.0068,  0.0220],\n","        [ 0.0086,  0.0007,  0.0198,  ...,  0.0250,  0.0038, -0.0009],\n","        [ 0.0010, -0.0074, -0.0139,  ..., -0.0221,  0.0087, -0.0049],\n","        ...,\n","        [-0.0157, -0.0159,  0.0214,  ...,  0.0228,  0.0173, -0.0126],\n","        [-0.0174,  0.0208,  0.0102,  ..., -0.0101,  0.0187, -0.0011],\n","        [-0.0118,  0.0135,  0.0247,  ...,  0.0206, -0.0031, -0.0079]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.self_attn.out_proj.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.linear1.weight:\n","Parameter containing:\n","tensor([[-0.0084,  0.0118,  0.0040,  ..., -0.0175, -0.0062, -0.0097],\n","        [ 0.0020,  0.0058, -0.0152,  ..., -0.0127,  0.0120,  0.0075],\n","        [ 0.0050, -0.0022,  0.0027,  ...,  0.0217,  0.0047, -0.0232],\n","        ...,\n","        [-0.0251, -0.0140, -0.0253,  ..., -0.0110, -0.0251,  0.0013],\n","        [ 0.0171,  0.0218,  0.0146,  ...,  0.0206, -0.0252,  0.0053],\n","        [ 0.0104, -0.0117, -0.0199,  ..., -0.0194,  0.0004,  0.0190]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.linear1.bias:\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.linear2.weight:\n","Parameter containing:\n","tensor([[ 2.0869e-02, -8.5141e-03,  2.1004e-02,  ..., -1.8733e-03,\n","          1.1463e-02,  1.6535e-02],\n","        [-1.6825e-02,  1.6355e-02, -6.2599e-03,  ..., -4.5087e-05,\n","          1.2243e-02,  1.0091e-02],\n","        [ 3.3961e-04, -1.4036e-02, -6.5373e-03,  ..., -1.0413e-02,\n","         -1.9913e-03,  4.7169e-03],\n","        ...,\n","        [-2.0588e-02, -1.0654e-02,  1.2563e-02,  ...,  9.3520e-03,\n","          1.8594e-03,  7.0706e-03],\n","        [-6.6939e-03, -1.0174e-02, -5.4319e-03,  ...,  1.2738e-03,\n","          1.9165e-02, -2.0058e-02],\n","        [ 1.5700e-02, -6.7736e-03,  1.9677e-02,  ..., -8.6711e-03,\n","          4.6090e-03,  2.6161e-03]], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.linear2.bias:\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.norm1.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.norm1.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.norm2.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.norm2.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_out.weight:\n","Parameter containing:\n","tensor([[ 2.4984e-02,  1.6558e-02, -2.6441e-02,  ..., -3.8561e-03,\n","          2.0609e-02,  1.2387e-02],\n","        [-8.8269e-03,  1.4057e-02, -1.1591e-02,  ..., -1.7771e-02,\n","         -1.2314e-02,  2.3355e-05],\n","        [ 1.8611e-02, -2.0347e-02,  6.3983e-03,  ..., -1.3365e-02,\n","          2.3725e-02,  3.1175e-03],\n","        ...,\n","        [ 1.4700e-02, -5.5198e-03,  9.9011e-03,  ..., -3.3344e-03,\n","         -2.0279e-02,  1.5662e-02],\n","        [-1.3611e-02,  2.5969e-02, -1.3062e-02,  ..., -2.4252e-02,\n","          7.9059e-03,  1.4950e-02],\n","        [ 1.8431e-02,  9.6439e-03,  2.5457e-02,  ..., -1.3059e-02,\n","          1.1863e-02,  7.4251e-03]], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_out.bias:\n","Parameter containing:\n","tensor([-0.0237, -0.0019,  0.0154, -0.0216,  0.0066, -0.0017,  0.0199,  0.0266,\n","         0.0194, -0.0110,  0.0025, -0.0085,  0.0250, -0.0166, -0.0241,  0.0258,\n","         0.0260, -0.0247, -0.0003, -0.0005,  0.0119,  0.0039, -0.0158, -0.0170,\n","        -0.0240, -0.0061,  0.0159,  0.0231,  0.0239, -0.0204,  0.0044, -0.0196,\n","         0.0142,  0.0097, -0.0032,  0.0267, -0.0169,  0.0210, -0.0201,  0.0115,\n","        -0.0181,  0.0268, -0.0008, -0.0108,  0.0223, -0.0038, -0.0031, -0.0022,\n","        -0.0057, -0.0128, -0.0033,  0.0261,  0.0150, -0.0189, -0.0142, -0.0236,\n","         0.0166, -0.0081,  0.0063,  0.0098,  0.0240, -0.0096,  0.0039,  0.0220,\n","        -0.0135, -0.0248,  0.0123,  0.0050, -0.0178, -0.0239, -0.0010,  0.0140,\n","        -0.0104,  0.0111, -0.0201, -0.0107, -0.0067, -0.0072, -0.0202,  0.0213,\n","        -0.0018, -0.0013, -0.0051, -0.0153,  0.0069,  0.0127, -0.0123, -0.0153,\n","         0.0236, -0.0034, -0.0097,  0.0066,  0.0089,  0.0014,  0.0149, -0.0040,\n","        -0.0189,  0.0242, -0.0119,  0.0069], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv1.weight:\n","Parameter containing:\n","tensor([[[ 1.6582e-02, -1.3431e-01,  1.6853e-01,  ...,  1.2562e-01,\n","          -6.8343e-02,  9.3560e-02],\n","         [-2.0877e-02,  1.6033e-01,  2.8398e-02,  ...,  4.4662e-02,\n","          -8.9625e-02,  1.3199e-01],\n","         [-9.5914e-03,  1.0323e-01,  3.0253e-02,  ..., -1.9400e-03,\n","          -1.4211e-01, -3.8304e-02],\n","         ...,\n","         [ 6.5313e-02,  1.4216e-01, -9.1744e-02,  ...,  9.6574e-02,\n","          -1.1501e-01,  1.1290e-01],\n","         [-1.1431e-01,  1.0135e-01,  1.4859e-01,  ..., -2.4445e-02,\n","           1.0971e-01,  1.5096e-01],\n","         [ 1.6420e-01, -3.7805e-02, -2.6450e-02,  ...,  1.1648e-01,\n","           7.9652e-02,  1.3288e-01]],\n","\n","        [[ 1.5409e-02, -5.6110e-02, -2.0907e-02,  ...,  9.3222e-02,\n","          -5.1245e-02,  1.6460e-01],\n","         [-1.2521e-01,  1.1457e-01, -6.1809e-02,  ..., -1.2908e-01,\n","          -1.7091e-03, -6.0869e-02],\n","         [ 2.4026e-03,  7.3515e-02, -1.3289e-01,  ...,  4.3223e-02,\n","          -9.7678e-02,  7.4335e-03],\n","         ...,\n","         [-8.4151e-02, -1.0343e-01, -4.8406e-02,  ..., -5.7894e-02,\n","          -1.4149e-01,  3.5637e-02],\n","         [-1.3587e-01, -5.7538e-02, -4.1014e-02,  ...,  6.7520e-02,\n","          -2.9771e-02, -3.5700e-02],\n","         [-3.0564e-02,  4.9192e-02, -3.5899e-03,  ..., -4.2687e-02,\n","          -1.0330e-01,  1.0585e-01]],\n","\n","        [[-1.1084e-01,  7.6488e-02, -1.6731e-01,  ..., -1.5689e-01,\n","           1.6446e-01,  3.8542e-02],\n","         [ 9.8609e-02, -1.0977e-01, -1.6547e-01,  ..., -4.6237e-02,\n","          -1.7273e-01, -1.2512e-01],\n","         [ 6.5630e-02, -1.2892e-01, -1.0988e-01,  ...,  9.2844e-02,\n","           7.1886e-02,  4.0516e-02],\n","         ...,\n","         [ 1.1855e-01,  4.7659e-02,  2.5397e-06,  ..., -4.1719e-02,\n","          -8.5762e-02,  1.2041e-02],\n","         [ 1.7116e-01,  1.2255e-03,  1.3028e-01,  ...,  7.5069e-02,\n","           4.1681e-02, -3.3303e-02],\n","         [ 1.5025e-01,  8.7002e-02, -1.3950e-01,  ..., -1.6624e-01,\n","           6.5730e-02, -1.3794e-01]],\n","\n","        ...,\n","\n","        [[ 1.1076e-01, -1.1498e-03, -1.4969e-02,  ...,  2.7424e-02,\n","           1.4174e-01, -1.0429e-01],\n","         [ 1.6850e-02,  3.6850e-03,  8.4550e-02,  ..., -7.5537e-02,\n","           3.7585e-02,  8.9450e-02],\n","         [-1.6513e-02, -6.2987e-02,  3.2054e-02,  ...,  5.5465e-02,\n","          -1.5556e-01,  8.0662e-02],\n","         ...,\n","         [-7.9558e-02,  6.9347e-02, -1.1021e-01,  ..., -8.0035e-02,\n","          -1.4888e-01, -2.9130e-02],\n","         [-3.1670e-02, -7.9053e-03, -3.4559e-02,  ...,  7.9934e-02,\n","           2.3772e-02,  1.0117e-01],\n","         [ 1.7169e-01, -4.5485e-02,  8.9173e-02,  ..., -1.3702e-01,\n","          -7.0493e-02, -1.3707e-01]],\n","\n","        [[-1.7282e-01, -6.7311e-02, -4.5677e-04,  ...,  8.2353e-02,\n","           3.5404e-02, -1.6631e-01],\n","         [ 9.6810e-02,  9.6563e-02, -4.6726e-02,  ..., -1.5660e-02,\n","          -4.4498e-02,  5.5897e-02],\n","         [-2.0039e-02,  2.3450e-02, -3.1461e-02,  ..., -8.4559e-02,\n","           6.4600e-02, -5.2359e-02],\n","         ...,\n","         [ 1.3008e-01,  8.9584e-03, -1.6023e-01,  ..., -7.9813e-02,\n","          -5.7333e-03, -6.1719e-02],\n","         [-7.5051e-02, -4.8246e-02,  1.2212e-01,  ...,  1.0150e-01,\n","          -1.3183e-01, -8.4711e-02],\n","         [-9.7848e-02,  7.1510e-02,  1.6363e-01,  ..., -1.1801e-01,\n","          -1.2522e-01, -1.5734e-02]],\n","\n","        [[ 3.2423e-02,  1.1153e-01, -2.2742e-02,  ...,  1.1291e-02,\n","          -3.5621e-03, -1.6378e-01],\n","         [ 1.7007e-03, -1.5814e-02,  3.9323e-02,  ..., -1.4504e-01,\n","          -3.6988e-02, -3.0379e-02],\n","         [-5.5274e-02, -9.2263e-02,  6.0870e-02,  ...,  5.1990e-02,\n","          -1.3338e-01, -2.5550e-02],\n","         ...,\n","         [-1.4579e-01, -3.0353e-02,  1.7217e-01,  ..., -1.3854e-02,\n","          -4.1705e-02,  7.1086e-02],\n","         [ 7.5531e-02,  1.0533e-02,  1.0539e-01,  ..., -1.5635e-01,\n","          -2.0977e-02,  1.1567e-01],\n","         [-9.1419e-02,  1.3962e-01,  6.3996e-02,  ...,  9.5708e-02,\n","          -1.6083e-01, -1.2422e-01]]], device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv1.bias:\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for gcn.conv2.lin_key.weight:\n","Parameter containing:\n","tensor([[-0.0865,  0.0557,  0.0943,  ...,  0.0423, -0.0932, -0.0796],\n","        [ 0.0401,  0.0460, -0.0147,  ...,  0.0491,  0.0223,  0.0244],\n","        [ 0.0470,  0.0826, -0.0856,  ...,  0.0547,  0.0779, -0.0666],\n","        ...,\n","        [-0.0128,  0.0663, -0.0294,  ...,  0.0499,  0.0731,  0.0199],\n","        [ 0.0939, -0.0319,  0.0667,  ..., -0.0079, -0.0990, -0.0265],\n","        [ 0.0504, -0.0166,  0.0392,  ..., -0.0230,  0.0501, -0.0204]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_key.bias:\n","Parameter containing:\n","tensor([-0.0991, -0.0645,  0.0659,  0.0654, -0.0402, -0.0288,  0.0769, -0.0589,\n","        -0.0395,  0.0581, -0.0294,  0.0154, -0.0524, -0.0345, -0.0896, -0.0972,\n","         0.0742, -0.0360, -0.0624,  0.0558, -0.0155,  0.0944, -0.0256,  0.0330,\n","        -0.0339,  0.0102, -0.0313,  0.0378,  0.0945,  0.0516,  0.0905, -0.0068,\n","        -0.0480,  0.0047, -0.0101,  0.0159,  0.0123,  0.0081, -0.0227,  0.0719,\n","        -0.0500, -0.0148,  0.0014, -0.0990, -0.0476, -0.0772,  0.0749,  0.0579,\n","         0.0348,  0.0828,  0.0040, -0.0983,  0.0519,  0.0715, -0.0695,  0.0353,\n","         0.0111,  0.0414,  0.0267,  0.0704,  0.0966,  0.0561, -0.0895, -0.0112,\n","         0.0244, -0.0855,  0.0741, -0.0169,  0.0806,  0.0364, -0.0460, -0.0708,\n","        -0.0234, -0.0690,  0.0912, -0.0198,  0.0560, -0.0923, -0.0191,  0.0723,\n","        -0.0498, -0.0692, -0.0081, -0.0869, -0.0146, -0.0728, -0.0717, -0.0291,\n","         0.0041, -0.0866,  0.0837, -0.0719,  0.0169, -0.0703, -0.0148,  0.0263,\n","         0.0859, -0.0849,  0.0308,  0.0992], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_query.weight:\n","Parameter containing:\n","tensor([[-0.0791,  0.0795,  0.0408,  ...,  0.0377,  0.0531, -0.0626],\n","        [-0.0050,  0.0656,  0.0530,  ...,  0.0558, -0.0417,  0.0387],\n","        [ 0.0983,  0.0689, -0.0153,  ..., -0.0122, -0.0768, -0.0312],\n","        ...,\n","        [-0.0043,  0.0522,  0.0273,  ..., -0.0355,  0.0241, -0.0647],\n","        [-0.0206, -0.0310,  0.0278,  ..., -0.0044,  0.0822,  0.0784],\n","        [ 0.0896, -0.0077,  0.0540,  ..., -0.0592,  0.0440, -0.0459]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_query.bias:\n","Parameter containing:\n","tensor([ 0.0844, -0.0540,  0.0126, -0.0950,  0.0963,  0.0158,  0.0484, -0.0252,\n","        -0.0592, -0.0308, -0.0575,  0.0020,  0.0458,  0.0818,  0.0884, -0.0058,\n","        -0.0778,  0.0817, -0.0452,  0.0860,  0.0510,  0.0915, -0.0950,  0.0601,\n","         0.0545,  0.0739, -0.0680,  0.0799,  0.0136,  0.0287, -0.0594, -0.0541,\n","         0.0699, -0.0706,  0.0047,  0.0079,  0.0449, -0.0395,  0.0789, -0.0041,\n","         0.0744, -0.0185, -0.0451,  0.0060, -0.0579,  0.0737, -0.0798, -0.0454,\n","        -0.0783,  0.0356,  0.0202, -0.0507, -0.0163, -0.0913,  0.0450, -0.0299,\n","         0.0291, -0.0776, -0.0830,  0.0933,  0.0382,  0.0338,  0.0806,  0.0377,\n","        -0.0619,  0.0079, -0.0473,  0.0775,  0.0367, -0.0272, -0.0228,  0.0356,\n","         0.0633,  0.0148, -0.0781,  0.0601, -0.0574, -0.0071,  0.0348,  0.0293,\n","        -0.0004,  0.0148, -0.0091, -0.0914,  0.0584, -0.0131,  0.0069,  0.0793,\n","         0.0437, -0.0174,  0.0669, -0.0204, -0.0894, -0.0581,  0.0307,  0.0181,\n","        -0.0044,  0.0399,  0.0194,  0.0123], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_value.weight:\n","Parameter containing:\n","tensor([[ 0.0830, -0.0755,  0.0408,  ...,  0.0959,  0.0083,  0.0700],\n","        [-0.0234, -0.0279,  0.0745,  ..., -0.0575,  0.0525,  0.0360],\n","        [ 0.0344, -0.0929,  0.0970,  ..., -0.0875,  0.0350, -0.0099],\n","        ...,\n","        [-0.0051, -0.0935, -0.0476,  ..., -0.0231, -0.0791, -0.0835],\n","        [ 0.0914, -0.0294, -0.0212,  ..., -0.0998,  0.0005, -0.0455],\n","        [-0.0267, -0.0676,  0.0431,  ..., -0.0472,  0.0400,  0.0232]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_value.bias:\n","Parameter containing:\n","tensor([ 0.0306, -0.0675,  0.0779, -0.0751,  0.0946,  0.0238,  0.0302,  0.0231,\n","         0.0905, -0.0692, -0.0250, -0.0581, -0.0854,  0.0074,  0.0140, -0.0213,\n","         0.0408, -0.0691, -0.0963,  0.0497,  0.0574,  0.0611, -0.0365,  0.0188,\n","         0.0154,  0.0268, -0.0787, -0.0108,  0.0175,  0.0115,  0.0355,  0.0209,\n","         0.0909,  0.0026, -0.0055, -0.0443, -0.0840, -0.0966,  0.0668,  0.0801,\n","         0.0125,  0.0825, -0.0179,  0.0365, -0.0724,  0.0683,  0.0884, -0.0132,\n","         0.0536, -0.0181, -0.0505, -0.0995,  0.0074,  0.0134,  0.0057,  0.0421,\n","        -0.0250, -0.0813,  0.0889, -0.0230,  0.0081,  0.0937,  0.0527,  0.0064,\n","        -0.0635,  0.0295,  0.0940,  0.0128, -0.0440, -0.0997,  0.0727, -0.0642,\n","         0.0064, -0.0042,  0.0485,  0.0016, -0.0898,  0.0380, -0.0373,  0.0329,\n","        -0.0438, -0.0771,  0.0502,  0.0544,  0.0896,  0.0860,  0.0351, -0.0568,\n","        -0.0504, -0.0295,  0.0136,  0.0565,  0.0154, -0.0799,  0.0566,  0.0004,\n","        -0.0276, -0.0160,  0.0806, -0.0563], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_skip.weight:\n","Parameter containing:\n","tensor([[ 0.0565, -0.0222, -0.0746,  ...,  0.0417, -0.0265, -0.0481],\n","        [-0.0166, -0.0396,  0.0173,  ..., -0.0797, -0.0762, -0.0712],\n","        [ 0.0338,  0.0527,  0.0186,  ...,  0.0390,  0.0497,  0.0731],\n","        ...,\n","        [ 0.0352,  0.0104, -0.0592,  ..., -0.0887, -0.0895, -0.0871],\n","        [ 0.0406, -0.0364, -0.0565,  ..., -0.0911,  0.0900,  0.0389],\n","        [-0.0684,  0.0821, -0.0839,  ..., -0.0797,  0.0916,  0.0085]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_skip.bias:\n","Parameter containing:\n","tensor([-0.0308,  0.0801,  0.0266, -0.0314,  0.0104,  0.0130, -0.0156,  0.0803,\n","         0.0438, -0.0490, -0.0382, -0.0941, -0.0902, -0.0199, -0.0012,  0.0091,\n","        -0.0841,  0.0825,  0.0716,  0.0114,  0.0145,  0.0292, -0.0095, -0.0523,\n","        -0.0435,  0.0970, -0.0484, -0.0765,  0.0037,  0.0982,  0.0957, -0.0860,\n","         0.0990, -0.0020,  0.0885,  0.0925, -0.0574,  0.0311,  0.0379,  0.0964,\n","         0.0221, -0.0952, -0.0198,  0.0791,  0.0117, -0.0456, -0.0678, -0.0059,\n","        -0.0833, -0.0743,  0.0641,  0.0344,  0.0156,  0.0787, -0.0277, -0.0554,\n","         0.0258,  0.0452,  0.0385, -0.0764,  0.0068, -0.0177, -0.0807,  0.0157,\n","         0.0582, -0.0685, -0.0224,  0.0935, -0.0355, -0.0810,  0.0225,  0.0638,\n","        -0.0300,  0.0542, -0.0498,  0.0452,  0.0785, -0.0273,  0.0495,  0.0386,\n","        -0.0396, -0.0357,  0.0272,  0.0535, -0.0344,  0.0526,  0.0696,  0.0649,\n","        -0.0151, -0.0117, -0.0287, -0.0673, -0.0992,  0.0611, -0.0836,  0.0084,\n","         0.0388, -0.0170, -0.0613,  0.0066], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.bn.weight:\n","Parameter containing:\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.bn.bias:\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for clf.emotion_att.lin.weight:\n","Parameter containing:\n","tensor([[-0.0172,  0.0947, -0.0276,  ..., -0.0499,  0.0160, -0.0662],\n","        [ 0.0054,  0.0051, -0.0466,  ..., -0.0585, -0.0102, -0.0598],\n","        [ 0.0408, -0.0813,  0.0862,  ...,  0.0764,  0.0062, -0.0187],\n","        ...,\n","        [-0.0210,  0.0758, -0.0153,  ...,  0.0263, -0.0525, -0.0431],\n","        [-0.0590, -0.0256,  0.0882,  ..., -0.0912, -0.0024, -0.0855],\n","        [-0.0632,  0.0205, -0.0181,  ...,  0.0766,  0.0883,  0.0985]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for clf.emotion_att.lin.bias:\n","Parameter containing:\n","tensor([ 0.0310,  0.0380, -0.0270,  0.0616,  0.0820,  0.0194,  0.0414,  0.0748,\n","         0.0330,  0.0831,  0.0034,  0.0888,  0.0091,  0.0931, -0.0020, -0.0580,\n","         0.0661, -0.0747, -0.0491,  0.0810,  0.0530,  0.0116, -0.0121,  0.0282,\n","        -0.0779,  0.0609, -0.0757, -0.0821,  0.0575,  0.0776,  0.0181, -0.0829,\n","         0.0946, -0.0726, -0.0235,  0.0449, -0.0922,  0.0536, -0.0730,  0.0249,\n","         0.0904,  0.0433, -0.0917,  0.0633,  0.0089,  0.0950,  0.0087, -0.0402,\n","        -0.0597,  0.0468,  0.0204,  0.0430,  0.0969,  0.0721, -0.0305,  0.0817,\n","        -0.0891,  0.0436,  0.0550, -0.0598,  0.0487,  0.0882, -0.0499,  0.0563,\n","        -0.0053, -0.0135,  0.0023,  0.0129,  0.0088,  0.0951,  0.0256,  0.0588,\n","         0.0467, -0.0100,  0.0629,  0.0385,  0.0327, -0.0063,  0.0411,  0.0238,\n","        -0.0555,  0.0076, -0.0277,  0.0397,  0.0540, -0.0323,  0.0654,  0.0193,\n","         0.0073, -0.0495,  0.0974,  0.0709, -0.0407,  0.0425, -0.0466, -0.0998,\n","        -0.0476,  0.0579,  0.0170, -0.0154], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin1.weight:\n","Parameter containing:\n","tensor([[-0.0434,  0.0086, -0.0120,  ...,  0.0496,  0.0390, -0.0866],\n","        [-0.0749,  0.0350, -0.0951,  ..., -0.0706,  0.0588,  0.0021],\n","        [-0.0388,  0.0280,  0.0116,  ...,  0.0584, -0.0222, -0.0533],\n","        ...,\n","        [ 0.0911, -0.0513, -0.0338,  ...,  0.0881, -0.0520, -0.0913],\n","        [-0.0867, -0.0916,  0.0116,  ...,  0.0382, -0.0891,  0.0327],\n","        [ 0.0650,  0.0633, -0.0304,  ..., -0.0735, -0.0848,  0.0331]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for clf.lin1.bias:\n","Parameter containing:\n","tensor([ 0.0762,  0.0880,  0.0464, -0.0047, -0.0801,  0.0563, -0.0795,  0.0890,\n","        -0.0352,  0.0643,  0.0485, -0.0053,  0.0714,  0.0026, -0.0216, -0.0704,\n","        -0.0150, -0.0501,  0.0022, -0.0042, -0.0394, -0.0176, -0.0425, -0.0123,\n","         0.0639,  0.0825,  0.0975,  0.0034, -0.0228,  0.0310, -0.0805, -0.0970,\n","         0.0286,  0.0184, -0.0883, -0.0630, -0.0171,  0.0793, -0.0963,  0.0190,\n","        -0.0941,  0.0329, -0.0340,  0.0827, -0.0255, -0.0977, -0.0589, -0.0200,\n","         0.0264,  0.0662, -0.0427, -0.0884,  0.0804, -0.0999,  0.0478, -0.0508,\n","        -0.0996, -0.0331,  0.0474, -0.0676, -0.0393,  0.0500,  0.0556, -0.0434,\n","         0.0044,  0.0449, -0.0820,  0.0411,  0.0597, -0.0488, -0.0330, -0.0831,\n","        -0.0663,  0.0483,  0.0922,  0.0776,  0.0448,  0.0970, -0.0049,  0.0961,\n","        -0.0691, -0.0696,  0.0078,  0.0822,  0.0409, -0.0339, -0.0016,  0.0115,\n","         0.0268,  0.0511, -0.0959,  0.0652, -0.0786, -0.0495,  0.0145, -0.0486,\n","        -0.0473,  0.0061, -0.0123, -0.0757], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin2.weight:\n","Parameter containing:\n","tensor([[-0.0231,  0.0611, -0.0787,  0.0208, -0.0325, -0.0179,  0.0858,  0.0240,\n","          0.0452,  0.0141, -0.0551, -0.0677, -0.0971,  0.0159, -0.0582,  0.0989,\n","          0.0087,  0.0731,  0.0133, -0.0791,  0.0133, -0.0140, -0.0680, -0.0884,\n","          0.0878,  0.0514,  0.0080, -0.0810, -0.0717, -0.0309,  0.0464,  0.0950,\n","         -0.0992, -0.0224,  0.0128, -0.0534, -0.0526,  0.0388, -0.0183,  0.0360,\n","         -0.0100,  0.0593,  0.0493, -0.0215, -0.0399,  0.0005, -0.0545,  0.0124,\n","          0.0686,  0.0796, -0.0474,  0.0033, -0.0698, -0.0670, -0.0236,  0.0904,\n","         -0.0590,  0.0498,  0.0334, -0.0610,  0.0215, -0.0607, -0.0125, -0.0627,\n","         -0.0616, -0.0220, -0.0340,  0.0952, -0.0740, -0.0041,  0.0940, -0.0466,\n","          0.0726,  0.0101,  0.0199,  0.0670,  0.0270,  0.0532,  0.0753,  0.0052,\n","         -0.0570, -0.0499, -0.0217, -0.0514, -0.0888, -0.0517,  0.0741,  0.0367,\n","         -0.0051, -0.0141, -0.0624, -0.0814,  0.0996,  0.0777, -0.0336, -0.0545,\n","          0.0083, -0.0372, -0.0658,  0.0475],\n","        [-0.0887,  0.0061,  0.0557, -0.0997,  0.0822,  0.0523, -0.0168,  0.0312,\n","         -0.0675,  0.0925,  0.0723, -0.0089, -0.0586,  0.0305,  0.0751,  0.0910,\n","         -0.0702,  0.0365, -0.0543,  0.0682, -0.0177, -0.0043,  0.0875, -0.0217,\n","         -0.0706,  0.0450,  0.0845,  0.0509, -0.0112, -0.0370, -0.0791,  0.0290,\n","          0.0335,  0.0942,  0.0801,  0.0361, -0.0462, -0.0519, -0.0091, -0.0028,\n","          0.0286,  0.0074, -0.0334, -0.0272,  0.0954, -0.0801, -0.0716,  0.0755,\n","          0.0281,  0.0286,  0.0978, -0.0170, -0.0588, -0.0374, -0.0474,  0.0943,\n","          0.0406, -0.0713,  0.0811,  0.0846,  0.0425, -0.0403,  0.0748,  0.0964,\n","         -0.0210, -0.0854, -0.0432,  0.0674, -0.0986, -0.0366, -0.0024,  0.0736,\n","          0.0814,  0.0468,  0.0756,  0.0454,  0.0611,  0.0264, -0.0832, -0.0504,\n","          0.0090,  0.0613,  0.0328,  0.0011, -0.0781, -0.0569,  0.0580, -0.0612,\n","         -0.0112,  0.0953, -0.0890, -0.0999,  0.0757, -0.0432,  0.0427,  0.0807,\n","         -0.0198,  0.0426,  0.0032,  0.0097],\n","        [ 0.0825, -0.0316,  0.0453,  0.0068, -0.0850, -0.0506,  0.0938, -0.0513,\n","         -0.0469,  0.0407,  0.0207,  0.0267,  0.0225, -0.0345,  0.0514,  0.0943,\n","         -0.0311, -0.0429, -0.0698,  0.0349, -0.0202,  0.0334,  0.0748,  0.0123,\n","          0.0807, -0.0216,  0.0192,  0.0024, -0.0322,  0.0853,  0.0491, -0.0157,\n","         -0.0202, -0.0946,  0.0741,  0.0896,  0.0888, -0.0490, -0.0973,  0.0734,\n","         -0.0716,  0.0176, -0.0960,  0.0396,  0.0915,  0.0535, -0.0481, -0.0212,\n","          0.0518,  0.0345, -0.0641,  0.0643,  0.0553,  0.0081, -0.0131,  0.0127,\n","          0.0161, -0.0391, -0.0295, -0.0814,  0.0737, -0.0275, -0.0418, -0.0424,\n","          0.0463,  0.0891,  0.0742, -0.0046,  0.0606,  0.0959, -0.0709, -0.0815,\n","          0.0237,  0.0311,  0.0638,  0.0702, -0.0930,  0.0841, -0.0597, -0.0945,\n","          0.0463,  0.0697, -0.0951,  0.0020, -0.0887,  0.0725,  0.0481, -0.0451,\n","          0.0489,  0.0637, -0.0421, -0.0598, -0.0954,  0.0333,  0.0910,  0.0746,\n","          0.0395, -0.0464, -0.0081, -0.0824],\n","        [ 0.0778, -0.0546,  0.0047, -0.0767,  0.0650,  0.0398,  0.0628, -0.0937,\n","          0.0413, -0.0449, -0.0507, -0.0671,  0.0834,  0.0504,  0.0832, -0.0265,\n","          0.0783,  0.0608, -0.0791,  0.0599,  0.0739,  0.0311, -0.0644,  0.0349,\n","         -0.0015,  0.0565,  0.0164, -0.0660, -0.0076, -0.0227, -0.0965, -0.0106,\n","         -0.0431,  0.0682, -0.0372,  0.0505,  0.0818, -0.0070, -0.0835,  0.0195,\n","         -0.0873, -0.0902,  0.0371, -0.0529, -0.0749, -0.0305,  0.0309,  0.0817,\n","          0.0396,  0.0594, -0.0438,  0.0624,  0.0223, -0.0925, -0.0875, -0.0883,\n","          0.0504, -0.0554, -0.0019,  0.0331,  0.0189,  0.0051,  0.0196,  0.0796,\n","          0.0688,  0.0385,  0.0221, -0.0991,  0.0325,  0.0400, -0.0945,  0.0311,\n","          0.0793,  0.0572, -0.0698,  0.0879,  0.0373, -0.0683, -0.0723, -0.0222,\n","          0.0959,  0.0928,  0.0266, -0.0771, -0.0363,  0.0733,  0.0795,  0.0285,\n","         -0.0027, -0.0727,  0.0796,  0.0783,  0.0180,  0.0913, -0.0250, -0.0435,\n","         -0.0145, -0.0692,  0.0756, -0.0741]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for clf.lin2.bias:\n","Parameter containing:\n","tensor([-0.0843,  0.0371, -0.0800, -0.0725], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin_7.weight:\n","Parameter containing:\n","tensor([[ 0.0834, -0.0943, -0.0705,  0.0911, -0.0330, -0.0189,  0.0987,  0.0758,\n","          0.0289,  0.0720,  0.0602,  0.0332,  0.0455,  0.0811, -0.0423,  0.0805,\n","         -0.0394,  0.0671,  0.0845,  0.0420, -0.0059, -0.0127,  0.0781,  0.0794,\n","         -0.0482,  0.0572, -0.0529,  0.0534, -0.0361, -0.0407,  0.0101, -0.0319,\n","         -0.0118,  0.0230, -0.0789, -0.0331,  0.0113,  0.0227,  0.0860,  0.0705,\n","          0.0890,  0.0987,  0.0989, -0.0740, -0.0629, -0.0839, -0.0753,  0.0157,\n","         -0.0468, -0.0048, -0.0836,  0.0416, -0.0390, -0.0940, -0.0979, -0.0835,\n","         -0.0644, -0.0229, -0.0746,  0.0164, -0.0059, -0.0550, -0.0054,  0.0785,\n","         -0.0571,  0.0904, -0.0996,  0.0173, -0.0248, -0.0958, -0.0299, -0.0607,\n","          0.0070, -0.0818,  0.0665,  0.0225, -0.0498,  0.0327, -0.0248, -0.0195,\n","         -0.0613,  0.0506, -0.0522, -0.0319, -0.0972, -0.0708, -0.0468,  0.0667,\n","          0.0707, -0.0882, -0.0700,  0.0230, -0.0451,  0.0618,  0.0738, -0.0748,\n","         -0.0888,  0.0003, -0.0213, -0.0383],\n","        [ 0.0497, -0.0458,  0.0927, -0.0153,  0.0009,  0.0293,  0.0871, -0.0481,\n","          0.0630, -0.0508,  0.0252,  0.0323, -0.0280,  0.0664, -0.0858,  0.0442,\n","         -0.0731,  0.0453, -0.0157, -0.0409, -0.0930, -0.0486, -0.0395, -0.0944,\n","          0.0748,  0.0622,  0.0129, -0.0515, -0.0476,  0.0368, -0.0816,  0.0527,\n","         -0.0799,  0.0560,  0.0601, -0.0146,  0.0822,  0.0537,  0.0035, -0.0194,\n","         -0.0526, -0.0206,  0.0178,  0.0630, -0.0139,  0.0730,  0.0578, -0.0139,\n","         -0.0865, -0.0500, -0.0048, -0.0909,  0.0481,  0.0913, -0.0351, -0.0844,\n","         -0.0699,  0.0820, -0.0775,  0.0288, -0.0444, -0.0145, -0.0224, -0.0172,\n","         -0.0339,  0.0793,  0.0209, -0.0790,  0.0667,  0.0368, -0.0456,  0.0910,\n","          0.0074,  0.0121, -0.0539,  0.0283, -0.0199,  0.0225,  0.0534,  0.0749,\n","         -0.0153,  0.0936, -0.0455,  0.0848,  0.0759,  0.0415,  0.0477, -0.0499,\n","         -0.0073,  0.0589, -0.0157,  0.0777, -0.0837, -0.0231, -0.0239,  0.0670,\n","          0.0211,  0.0998, -0.0108, -0.0313],\n","        [-0.0044, -0.0766,  0.0886,  0.0985, -0.0030, -0.0609,  0.0598, -0.0406,\n","          0.0581,  0.0063, -0.0064, -0.0004, -0.0520,  0.0610, -0.0324, -0.0353,\n","          0.0076, -0.0156,  0.0271, -0.0889, -0.0285,  0.0449,  0.0864,  0.0541,\n","         -0.0959,  0.0447,  0.0733,  0.0415,  0.0349,  0.0182, -0.0116, -0.0967,\n","          0.0041,  0.0286,  0.0215, -0.0519,  0.0629, -0.0355,  0.0282,  0.0492,\n","          0.0018,  0.0136,  0.0058, -0.0089,  0.0610,  0.0892,  0.0526,  0.0336,\n","         -0.0876, -0.0336, -0.0566,  0.0631,  0.0933, -0.0117,  0.0882,  0.0115,\n","          0.0193, -0.0981, -0.0300,  0.0051,  0.0401, -0.0464, -0.0553, -0.0293,\n","          0.0426, -0.0720,  0.0768, -0.0069, -0.0725,  0.0814,  0.0939,  0.0849,\n","          0.0276,  0.0921, -0.0836,  0.0572, -0.0279,  0.0794, -0.0763, -0.0896,\n","          0.0899,  0.0730, -0.0071, -0.0560,  0.0354, -0.0346, -0.0768, -0.0906,\n","         -0.0238, -0.0126,  0.0227, -0.0536, -0.0682,  0.0545,  0.0326, -0.0374,\n","          0.0867, -0.0085, -0.0234, -0.0539],\n","        [ 0.0988, -0.0278,  0.0172,  0.0964, -0.0943, -0.0260,  0.0052, -0.0308,\n","          0.0644,  0.0345, -0.0402,  0.0902, -0.0790,  0.0657,  0.0951,  0.0436,\n","         -0.0865, -0.0450,  0.0290, -0.0203, -0.0309,  0.0625, -0.0372,  0.0942,\n","          0.0334, -0.0268, -0.0774,  0.0576, -0.0727,  0.0482,  0.0437, -0.0098,\n","          0.0723,  0.0262, -0.0801,  0.0842,  0.0108,  0.0202, -0.0788, -0.0456,\n","         -0.0515,  0.0389, -0.0465,  0.0086,  0.0035,  0.0658,  0.0625,  0.0381,\n","         -0.0832,  0.0167, -0.0885,  0.0868, -0.0384, -0.0213, -0.0223,  0.0176,\n","         -0.0634, -0.0803, -0.0502, -0.0043,  0.0372,  0.0203, -0.0668, -0.0611,\n","          0.0760, -0.0323,  0.0928,  0.0137, -0.0029, -0.0912,  0.0032, -0.0700,\n","         -0.0506,  0.0061,  0.0126,  0.0724,  0.0073,  0.0654, -0.0269, -0.0865,\n","          0.0970, -0.0166, -0.0321,  0.0384, -0.0476, -0.0943,  0.0246,  0.0782,\n","          0.0913,  0.0398,  0.0495,  0.0481,  0.0314,  0.0634,  0.0430,  0.0513,\n","          0.0203, -0.0662, -0.0516, -0.0097],\n","        [ 0.0053,  0.0321,  0.0597,  0.0981,  0.0801, -0.0124,  0.0739,  0.0257,\n","          0.0044,  0.0693, -0.0201,  0.0722, -0.0360,  0.0197,  0.0762, -0.0949,\n","         -0.0464, -0.0865,  0.0838, -0.0212,  0.0503, -0.0560,  0.0530,  0.0675,\n","         -0.0285,  0.0816,  0.0473, -0.0365, -0.0081, -0.0398, -0.0872, -0.0282,\n","          0.0220,  0.0824, -0.0558,  0.0553,  0.0835,  0.0524,  0.0593, -0.0467,\n","         -0.0999, -0.0225, -0.0604,  0.0902, -0.0133, -0.0549,  0.0590, -0.0328,\n","         -0.0773, -0.0715,  0.0832,  0.0928, -0.0181, -0.0761,  0.0081,  0.0977,\n","         -0.0420, -0.0114,  0.0421,  0.0971,  0.0026,  0.0032, -0.0531,  0.0744,\n","          0.0503, -0.0076, -0.0771,  0.0600, -0.0271,  0.0825,  0.0879, -0.0415,\n","          0.0207,  0.0258,  0.0167, -0.0342,  0.0966, -0.0766, -0.0261,  0.0056,\n","          0.0188,  0.0993, -0.0326,  0.0800,  0.0157,  0.0716, -0.0925,  0.0570,\n","          0.0349, -0.0835, -0.0458,  0.0830, -0.0727,  0.0977, -0.0981,  0.0615,\n","         -0.0933, -0.0832,  0.0037, -0.0677],\n","        [ 0.0606, -0.0847, -0.0863, -0.0942, -0.0155, -0.0866, -0.0359, -0.0417,\n","          0.0576,  0.0920,  0.0527, -0.0705,  0.0965, -0.0434, -0.0656, -0.0341,\n","         -0.0035,  0.0793, -0.0757,  0.0104,  0.0389,  0.0310,  0.0682, -0.0947,\n","         -0.0813, -0.0803, -0.0248,  0.0200, -0.0964, -0.0205, -0.0373,  0.0561,\n","          0.0146,  0.0463, -0.0118, -0.0605, -0.0317, -0.0645, -0.0037,  0.0946,\n","         -0.0662,  0.0861,  0.0470, -0.0370,  0.0128, -0.0678,  0.0611, -0.0047,\n","         -0.0314, -0.0583, -0.0399, -0.0407,  0.0028,  0.0023, -0.0588, -0.0990,\n","          0.0073, -0.0277, -0.0750,  0.0258,  0.0632,  0.0005,  0.0089, -0.0121,\n","         -0.0017,  0.0884, -0.0091,  0.0768,  0.0894,  0.0743,  0.0424, -0.0002,\n","         -0.0688,  0.0524,  0.0670,  0.0388, -0.0205,  0.0624, -0.0983, -0.0177,\n","         -0.0486,  0.0553,  0.0246,  0.0269,  0.0305, -0.0652, -0.0485,  0.0919,\n","         -0.0216, -0.0200,  0.0214,  0.0211, -0.0773,  0.0633,  0.0704,  0.0210,\n","         -0.0108,  0.0251,  0.0873,  0.0616],\n","        [-0.0254,  0.0773,  0.0265,  0.0140, -0.0605,  0.0805,  0.0552,  0.0976,\n","          0.0713, -0.0765, -0.0159,  0.0100, -0.0533, -0.0970,  0.0002, -0.0736,\n","         -0.0393,  0.0227, -0.0079, -0.0616,  0.0222, -0.0873,  0.0775, -0.0589,\n","         -0.0828,  0.0047,  0.0745,  0.0901, -0.0091, -0.0408,  0.0549,  0.0559,\n","          0.0198, -0.0997,  0.0980, -0.0453,  0.0699,  0.0590, -0.0176, -0.0028,\n","         -0.0762, -0.0339,  0.0825,  0.0282, -0.0280,  0.0690, -0.0955,  0.0282,\n","          0.0971,  0.0300, -0.0761, -0.0903, -0.0982, -0.0928,  0.0668, -0.0974,\n","         -0.0169,  0.0213, -0.0546,  0.0489, -0.0981,  0.0656,  0.0099,  0.0584,\n","          0.0716, -0.0411,  0.0817,  0.0224,  0.0323, -0.0643, -0.0453, -0.0654,\n","          0.0893,  0.0732, -0.0483,  0.0959, -0.0846,  0.0975,  0.0915, -0.0078,\n","         -0.0387,  0.0094, -0.0690, -0.0198, -0.0028, -0.0963, -0.0324, -0.0567,\n","          0.0942,  0.0600,  0.0350,  0.0691,  0.0972, -0.0835,  0.0025, -0.0361,\n","         -0.0909, -0.0528,  0.0532,  0.0739]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for clf.lin_7.bias:\n","Parameter containing:\n","tensor([-0.0149, -0.0465,  0.0099,  0.0570,  0.0250,  0.0233,  0.0425],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for clf.linear.weight:\n","Parameter containing:\n","tensor([[-3.7008e-02,  7.9037e-02, -9.6631e-02, -7.0181e-02, -7.6220e-02,\n","          7.1087e-02, -7.5496e-02,  8.5444e-02,  8.7223e-02, -9.8911e-03,\n","         -3.8743e-02, -8.4766e-03,  2.1881e-03, -2.2703e-02, -7.0989e-02,\n","         -6.1675e-02,  9.1017e-02,  1.4013e-03,  2.3171e-02,  6.5210e-02,\n","          7.9242e-02, -9.6024e-02,  6.0686e-02,  5.0447e-02,  1.6530e-02,\n","          6.9341e-02, -7.2576e-02,  2.7377e-02, -6.3856e-02, -5.2966e-02,\n","          5.3378e-02,  7.0123e-02, -5.0479e-02, -5.2138e-02, -3.8304e-03,\n","         -8.3463e-02,  7.4907e-02,  2.8172e-02,  3.7462e-02, -7.6788e-03,\n","          1.8110e-02,  7.7666e-02, -9.6967e-02,  1.3185e-02, -2.1135e-02,\n","         -2.3898e-02, -3.2826e-02, -4.0910e-03, -7.9721e-02,  8.5199e-05,\n","          2.4464e-02,  9.9989e-02, -5.4309e-02,  7.1346e-02,  6.5091e-02,\n","          1.5353e-03, -4.1694e-02, -2.0742e-02, -3.5608e-02,  9.5540e-02,\n","          5.2335e-02,  5.4811e-02, -1.8522e-02,  9.6849e-02, -4.3480e-02,\n","          1.1354e-02, -4.5472e-02, -1.7418e-02, -4.4014e-02, -6.7276e-02,\n","          4.8936e-02, -6.7930e-02, -8.2183e-02, -5.6574e-02, -9.4692e-02,\n","          1.7621e-02, -3.1185e-02, -8.5019e-02,  9.4946e-02,  9.2544e-02,\n","         -4.0547e-02, -3.5450e-02,  8.7012e-03, -7.7085e-02,  7.3096e-02,\n","         -7.1997e-02,  3.8798e-02, -8.4740e-02, -2.8832e-02, -7.5049e-02,\n","         -6.9656e-02,  9.5774e-02, -3.8677e-02,  6.0808e-02,  9.4806e-02,\n","         -4.9833e-02, -3.1621e-02,  9.3813e-02, -6.9384e-02, -9.3193e-03],\n","        [-3.7745e-02, -7.9007e-02, -1.7935e-02,  6.8221e-02, -9.0862e-02,\n","         -6.8590e-02,  5.1396e-02,  7.7880e-02, -9.4537e-02,  6.0982e-03,\n","          2.9019e-02, -8.7506e-02,  6.8044e-02, -9.6501e-02,  4.1874e-02,\n","          2.8795e-02, -7.7057e-02, -4.1877e-02,  5.0183e-02,  6.6718e-02,\n","          2.0940e-02, -9.5209e-02, -1.9943e-02,  8.4095e-02, -9.0228e-02,\n","          3.4417e-02,  5.2373e-02, -8.8105e-04,  5.8477e-02, -6.2850e-02,\n","          8.4223e-02, -9.5687e-02, -2.4482e-02, -7.8081e-02,  7.9597e-02,\n","          7.3302e-02, -5.9369e-02, -9.9129e-02, -6.3159e-02, -3.4013e-02,\n","         -1.7812e-02,  6.3520e-02, -5.9161e-02, -1.3957e-02, -6.4666e-02,\n","         -4.7442e-04,  6.0808e-02,  3.7877e-02, -6.4255e-02, -1.6429e-02,\n","          2.5644e-02,  7.2984e-02,  6.0184e-02, -8.8059e-02, -1.7612e-04,\n","          1.4169e-02,  1.3707e-02,  4.0183e-03, -7.9349e-02,  3.1504e-02,\n","          6.0621e-02,  2.9338e-03, -2.1643e-02,  6.5091e-02,  3.2192e-02,\n","         -3.1672e-02, -6.6403e-02,  4.1171e-02, -5.7829e-02,  3.3459e-02,\n","         -8.2749e-02,  6.7642e-02, -7.0015e-02,  1.8995e-02, -2.2135e-02,\n","          6.3580e-02,  9.7481e-02, -9.5915e-02,  1.7965e-02,  7.9938e-02,\n","          8.7038e-02, -7.5593e-02,  6.1347e-02, -2.1588e-02, -8.8184e-02,\n","         -7.1365e-02,  5.0654e-02, -8.8025e-02,  5.5075e-02, -8.3050e-02,\n","          9.2819e-02, -4.7950e-02,  3.8860e-03, -9.7744e-02, -7.4342e-02,\n","          5.2791e-02, -2.1618e-02,  2.3624e-02,  7.2822e-02, -5.7874e-02],\n","        [-2.3270e-02, -1.5211e-03,  4.1247e-02,  1.9910e-02, -1.9437e-02,\n","          8.8854e-02, -9.8614e-02,  5.6692e-03,  4.9072e-02, -4.2134e-02,\n","         -7.2613e-02, -6.7751e-02,  1.4715e-03,  8.6936e-02, -5.6619e-02,\n","         -8.2791e-02,  1.9850e-02,  6.4453e-02,  7.8848e-02, -4.4176e-02,\n","         -1.6888e-03,  3.1146e-02, -4.6494e-02, -4.0280e-02, -5.5082e-02,\n","         -4.7983e-02,  1.3688e-02, -8.2617e-02, -3.1518e-02,  2.5145e-02,\n","         -2.5668e-02, -6.8683e-02, -1.3039e-02, -8.6417e-02,  8.1937e-02,\n","          6.1219e-02,  7.5593e-02,  5.3760e-02, -1.8178e-02,  7.2424e-02,\n","         -4.9915e-04,  1.8730e-02, -2.2597e-02, -1.4228e-02,  8.8367e-02,\n","         -3.0545e-02,  5.3947e-02,  8.5745e-02,  6.6053e-02, -3.2359e-02,\n","          7.6245e-02,  7.8341e-02, -2.8932e-02, -6.8282e-02, -5.8860e-02,\n","          4.4998e-02, -6.3171e-02, -8.1229e-02,  1.4758e-02,  4.3752e-02,\n","         -8.5168e-02, -3.8906e-03, -1.4217e-02,  6.2258e-02, -2.4902e-03,\n","          3.6246e-02,  5.4489e-02, -7.9997e-02, -8.1948e-02, -4.3276e-02,\n","         -7.6598e-02,  4.6952e-03,  2.6509e-02, -8.0612e-02, -7.7331e-02,\n","          4.3601e-02, -5.4205e-02, -1.4563e-02, -1.1350e-03, -4.4241e-02,\n","         -3.3826e-02, -3.9662e-02, -4.4156e-02, -8.6949e-02, -8.3765e-02,\n","          9.8169e-02, -2.1302e-02, -5.2295e-02, -7.6495e-02,  2.2235e-02,\n","          1.9128e-03, -1.6625e-02,  3.9996e-03,  1.1191e-02, -3.9572e-02,\n","          8.5813e-03,  7.1226e-02,  7.7405e-02, -8.5258e-02,  6.7660e-02],\n","        [ 7.8416e-03,  1.2034e-02,  8.2138e-02, -3.5759e-02, -2.0921e-02,\n","          7.2613e-02, -7.2832e-04, -3.1847e-03,  3.6389e-02, -9.4404e-02,\n","          9.1278e-02,  9.2122e-02, -2.1923e-02,  8.1143e-02,  4.8857e-02,\n","         -2.4481e-02,  7.3477e-03,  3.0317e-02, -8.8428e-02,  4.7145e-02,\n","          2.5772e-02,  6.5719e-02,  1.9353e-02,  3.0849e-02, -9.5636e-02,\n","          8.7274e-02, -1.8570e-02,  2.7611e-02,  5.5938e-02,  7.1570e-02,\n","          9.8848e-02,  7.0887e-02, -9.6928e-02, -6.4049e-02, -4.0442e-02,\n","          1.0175e-02, -6.8428e-02, -6.2817e-02, -8.2198e-02, -1.7435e-02,\n","         -8.0656e-02, -7.7271e-02, -1.0531e-02, -7.3998e-02,  2.5480e-02,\n","          8.6857e-02, -3.2961e-02,  9.4465e-02, -5.0641e-02,  1.0545e-02,\n","         -3.4710e-02,  5.8775e-02,  8.7024e-02,  1.0644e-02, -4.8731e-03,\n","          6.0092e-02, -9.9729e-02, -5.0344e-03,  1.2238e-02,  9.4780e-02,\n","         -5.3323e-03, -5.2668e-02,  9.1019e-02, -7.5829e-02, -5.8037e-02,\n","          7.5552e-02,  2.1613e-02,  2.8930e-03,  2.0486e-02,  2.2625e-02,\n","         -7.9617e-02,  5.8514e-02,  9.8570e-02, -4.8506e-02,  8.5897e-02,\n","         -9.6173e-02, -9.1424e-02, -2.9320e-02, -8.3531e-02,  6.1074e-02,\n","         -8.1568e-02, -4.6341e-02, -6.3764e-02, -2.3561e-02, -6.6538e-02,\n","          5.4579e-02,  6.2349e-02, -1.8254e-02,  9.6255e-02,  8.4739e-02,\n","          1.1746e-02, -1.8906e-02, -8.3243e-02, -9.6534e-02,  7.4305e-02,\n","          4.1302e-02,  4.1058e-02, -1.0615e-02,  6.3407e-02, -2.0454e-03]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for clf.linear.bias:\n","Parameter containing:\n","tensor([ 0.0163,  0.0140, -0.0578, -0.0828], device='cuda:0',\n","       requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["Binarizacija"],"metadata":{"id":"5YkhUeEzi0rK"}},{"cell_type":"code","source":["#Binarizacija\n","novi_param = []\n","poz = []\n","for i in range(len(weights1)):\n","  if int(weights1[i].numel()) >1000000:\n","    print(weights1[i].size)\n","    novi = torch.where(weights1[i] > 0, torch.tensor(1), torch.tensor(-1))\n","    a = novi.cpu()\n","    novi_np = a.detach().numpy()\n","\n","    novi_np = np.asarray(novi_np).astype(np.float32)\n","    print(novi_np.shape)\n","    #novi = np.asarray(novi).astype(np.float32)\n","    print(novi_np)\n","    #print(int(novi_np.numel()))\n","    poz.append(i)\n","    novi_param.append(novi_np)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1vc7kyc0h9o","executionInfo":{"status":"ok","timestamp":1698858385070,"user_tz":-60,"elapsed":461,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"63f8db0a-b44a-460e-941e-87f084046069"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<built-in method size of Tensor object at 0x7cd1d31309f0>\n","(5713200,)\n","[-1.  1. -1. ...  1.  1. -1.]\n","<built-in method size of Tensor object at 0x7cd1d310fd80>\n","(1904400,)\n","[-1. -1. -1. ...  1. -1. -1.]\n","<built-in method size of Tensor object at 0x7cd1d3130630>\n","(2826240,)\n","[-1.  1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7cd1d31301d0>\n","(2826240,)\n","[ 1. -1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7cd1d3130180>\n","(5713200,)\n","[-1.  1. -1. ...  1.  1. -1.]\n","<built-in method size of Tensor object at 0x7cd1d3130220>\n","(1904400,)\n","[-1. -1. -1. ...  1. -1. -1.]\n","<built-in method size of Tensor object at 0x7cd1d31300e0>\n","(2826240,)\n","[-1.  1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7cd1d30d9ee0>\n","(2826240,)\n","[ 1. -1.  1. ... -1.  1.  1.]\n"]}]},{"cell_type":"code","source":["i=0\n","with torch.no_grad():\n","  for name, params in model.named_parameters():\n","    print(name)\n","    print(params.shape)\n","    if 'weight' in name:\n","      if params.numel()>1000000:\n","        print(i)\n","        velicina = params.shape\n","        novi_param[i] = np.asarray(novi_param[i]).astype(np.float32)\n","        print(novi_param[i].dtype)\n","        novi_reshaped = np.reshape(novi_param[i], velicina)\n","        params.data.copy_(torch.from_numpy(novi_reshaped))\n","        i=i+1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgQqlZ480n3F","executionInfo":{"status":"ok","timestamp":1698858395209,"user_tz":-60,"elapsed":10,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"04494b65-85c7-46cc-d645-495ed440f295"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rnn.encoding_layer.weight\n","torch.Size([110, 1380])\n","rnn.LayerNorm.weight\n","torch.Size([1380])\n","rnn.LayerNorm.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_weight\n","torch.Size([4140, 1380])\n","0\n","float32\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_bias\n","torch.Size([4140])\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.weight\n","torch.Size([1380, 1380])\n","1\n","float32\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.linear1.weight\n","torch.Size([2048, 1380])\n","2\n","float32\n","rnn.transformer_encoder.layers.0.linear1.bias\n","torch.Size([2048])\n","rnn.transformer_encoder.layers.0.linear2.weight\n","torch.Size([1380, 2048])\n","3\n","float32\n","rnn.transformer_encoder.layers.0.linear2.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm1.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm1.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm2.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm2.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_weight\n","torch.Size([4140, 1380])\n","4\n","float32\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_bias\n","torch.Size([4140])\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.weight\n","torch.Size([1380, 1380])\n","5\n","float32\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.linear1.weight\n","torch.Size([2048, 1380])\n","6\n","float32\n","rnn.transformer_encoder.layers.1.linear1.bias\n","torch.Size([2048])\n","rnn.transformer_encoder.layers.1.linear2.weight\n","torch.Size([1380, 2048])\n","7\n","float32\n","rnn.transformer_encoder.layers.1.linear2.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm1.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm1.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm2.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm2.bias\n","torch.Size([1380])\n","rnn.transformer_out.weight\n","torch.Size([100, 1380])\n","rnn.transformer_out.bias\n","torch.Size([100])\n","gcn.conv1.weight\n","torch.Size([8, 100, 100])\n","gcn.conv1.root\n","torch.Size([100, 100])\n","gcn.conv1.bias\n","torch.Size([100])\n","gcn.conv2.lin_key.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_key.bias\n","torch.Size([100])\n","gcn.conv2.lin_query.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_query.bias\n","torch.Size([100])\n","gcn.conv2.lin_value.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_value.bias\n","torch.Size([100])\n","gcn.conv2.lin_skip.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_skip.bias\n","torch.Size([100])\n","gcn.bn.weight\n","torch.Size([100])\n","gcn.bn.bias\n","torch.Size([100])\n","clf.emotion_att.lin.weight\n","torch.Size([100, 100])\n","clf.emotion_att.lin.bias\n","torch.Size([100])\n","clf.lin1.weight\n","torch.Size([100, 100])\n","clf.lin1.bias\n","torch.Size([100])\n","clf.lin2.weight\n","torch.Size([4, 100])\n","clf.lin2.bias\n","torch.Size([4])\n","clf.lin_7.weight\n","torch.Size([7, 100])\n","clf.lin_7.bias\n","torch.Size([7])\n","clf.linear.weight\n","torch.Size([4, 100])\n","clf.linear.bias\n","torch.Size([4])\n"]}]},{"cell_type":"markdown","source":["FP8"],"metadata":{"id":"znewVgdei4Rm"}},{"cell_type":"code","source":["def FP8_v2(input_data):\n","  sgn_len=1\n","  exp_len=5\n","  mant_len=2\n","\n","  if input_data >=  0:\n","    s = 0\n","  else:\n","    #s = - 1 # proveriti i ovu varijantu ako postoji neslaganje\n","    s = 1\n","\n","  Eb = np.floor(np.log2(np.abs(input_data)))\n","\n","  if Eb > 2 ** (exp_len - 1) - 1:\n","    Eb = 2 ** (exp_len - 1)\n","\n","  if Eb < - 2 ** (exp_len - 1):\n","    Eb = - 2 ** (exp_len - 1)\n","\n","  #M = np.round((2 ** (mant_len)) * ((np.abs(input_data)/Eb) - 1)) # ovde je bila greska u tekstu izgleda, tj. treba deliti sa 2^Eb umesto sa Eb.\n","  M = np.round((2 ** (mant_len)) * (np.abs(input_data)/(2 ** (Eb)) - 1))\n","\n","  if M > (2 ** (mant_len)) - 1:\n","    M = (2 ** (mant_len)) - 1\n","\n","  if M < 0:\n","    M = 0\n","\n","  Quantized_data = ((-1)**s) * (2 ** Eb) * (1 + M / (2 ** (mant_len)))\n","\n","  return Quantized_data"],"metadata":{"id":"NNLe7fXNsqZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t = []\n","for i in range(len(weights1[2])):\n","  x = weights1[2][i]\n","\n","  a = x.cpu()\n","  y = a.detach().numpy()\n","\n","  x1 = FP8_v2(y)\n","  t.append(x1)"],"metadata":{"id":"lcZOaRFQvXFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"il9RVM_Ekxv4","executionInfo":{"status":"ok","timestamp":1700605534654,"user_tz":-60,"elapsed":8,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"c558ff56-ca10-4e90-fcca-75d662676d90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-0.010036595\n"]}]},{"cell_type":"code","source":["print(t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CW-6eGfk406","executionInfo":{"status":"ok","timestamp":1700581847184,"user_tz":-60,"elapsed":1218,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"d1060ec6-e451-4792-8728-fc065c77aea0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}]},{"cell_type":"code","source":["\n","print(t.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"iEZ5vVEIhqzu","executionInfo":{"status":"error","timestamp":1700582748832,"user_tz":-60,"elapsed":367,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"1474725b-755c-4986-87dd-0bb3d93f8cc3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-70cabf0199c7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"]}]},{"cell_type":"code","source":["t = torch.tensor(t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"3LfykyK5oeJt","executionInfo":{"status":"error","timestamp":1700598869263,"user_tz":-60,"elapsed":472,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"1b27d8cb-362a-46c9-fed0-f5e8572dcae3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-2ecf697bd457>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: len() of unsized object"]}]},{"cell_type":"code","source":["\n","with torch.no_grad():\n","  for name, params in model.named_parameters():\n","    print(name)\n","    print(params.shape)\n","    if name == 'rnn.transformer_encoder.layers.0.self_attn.in_proj_weight':\n","        velicina = params.shape\n","        novi_param = np.asarray(t).astype(np.float32)\n","        print(novi_param.dtype)\n","        novi_reshaped = np.reshape(novi_param, velicina)\n","        params.data.copy_(torch.from_numpy(novi_reshaped))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrKVCTEQ-bOP","executionInfo":{"status":"ok","timestamp":1700605411490,"user_tz":-60,"elapsed":42533,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"9301d674-2b8d-445a-c8dd-2607590bb59f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rnn.encoding_layer.weight\n","torch.Size([110, 1380])\n","rnn.LayerNorm.weight\n","torch.Size([1380])\n","rnn.LayerNorm.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_weight\n","torch.Size([4140, 1380])\n","float32\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_bias\n","torch.Size([4140])\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.weight\n","torch.Size([1380, 1380])\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.linear1.weight\n","torch.Size([2048, 1380])\n","rnn.transformer_encoder.layers.0.linear1.bias\n","torch.Size([2048])\n","rnn.transformer_encoder.layers.0.linear2.weight\n","torch.Size([1380, 2048])\n","rnn.transformer_encoder.layers.0.linear2.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm1.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm1.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm2.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.0.norm2.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_weight\n","torch.Size([4140, 1380])\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_bias\n","torch.Size([4140])\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.weight\n","torch.Size([1380, 1380])\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.linear1.weight\n","torch.Size([2048, 1380])\n","rnn.transformer_encoder.layers.1.linear1.bias\n","torch.Size([2048])\n","rnn.transformer_encoder.layers.1.linear2.weight\n","torch.Size([1380, 2048])\n","rnn.transformer_encoder.layers.1.linear2.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm1.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm1.bias\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm2.weight\n","torch.Size([1380])\n","rnn.transformer_encoder.layers.1.norm2.bias\n","torch.Size([1380])\n","rnn.transformer_out.weight\n","torch.Size([100, 1380])\n","rnn.transformer_out.bias\n","torch.Size([100])\n","gcn.conv1.weight\n","torch.Size([8, 100, 100])\n","gcn.conv1.root\n","torch.Size([100, 100])\n","gcn.conv1.bias\n","torch.Size([100])\n","gcn.conv2.lin_key.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_key.bias\n","torch.Size([100])\n","gcn.conv2.lin_query.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_query.bias\n","torch.Size([100])\n","gcn.conv2.lin_value.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_value.bias\n","torch.Size([100])\n","gcn.conv2.lin_skip.weight\n","torch.Size([100, 100])\n","gcn.conv2.lin_skip.bias\n","torch.Size([100])\n","gcn.bn.weight\n","torch.Size([100])\n","gcn.bn.bias\n","torch.Size([100])\n","clf.emotion_att.lin.weight\n","torch.Size([100, 100])\n","clf.emotion_att.lin.bias\n","torch.Size([100])\n","clf.lin1.weight\n","torch.Size([100, 100])\n","clf.lin1.bias\n","torch.Size([100])\n","clf.lin2.weight\n","torch.Size([4, 100])\n","clf.lin2.bias\n","torch.Size([4])\n","clf.lin_7.weight\n","torch.Size([7, 100])\n","clf.lin_7.bias\n","torch.Size([7])\n","clf.linear.weight\n","torch.Size([4, 100])\n","clf.linear.bias\n","torch.Size([4])\n"]}]},{"cell_type":"code","source":["novi_np = []\n","novi_param=[]\n","\n","for i in range(len(weights1)):\n","  if int(weights1[i].numel()) >1000000:\n","    print(weights1[i].size)\n","    novi =[]\n","    print(novi)\n","    for j in range(len(weights1[i])):\n","      input_data_t = weights1[i][j]\n","      a = input_data_t.cpu()\n","      input_data = a.detach().numpy()\n","      x = FP8_v2(input_data)\n","      #x1 = np.asarray(x).astype(np.float32)\n","      novi.append(x)\n","    novi_np = novi\n","    #novi_np = np.asarray(novi_np).astype(np.float32)\n","    #print(int(novi_np.numel()))\n","    poz.append(i)\n","    novi_param.append(novi_np)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"S51A4xXzvTHA","executionInfo":{"status":"error","timestamp":1699126764346,"user_tz":-60,"elapsed":537481,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"50d667bc-cbb0-46a3-efc4-e32e6b77972f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<built-in method size of Tensor object at 0x7b03a99ae390>\n","[]\n","<built-in method size of Tensor object at 0x7b03a99adee0>\n","[]\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-8a84407526f1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;31m#x1 = np.asarray(x).astype(np.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mnovi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnovi_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnovi_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnovi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mnovi_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnovi_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#print(int(novi_np.numel()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"]}]},{"cell_type":"code","source":["for name, params in model.named_parameters():\n","  print(name)\n","  print(params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VP7dIZWk06Bk","executionInfo":{"status":"ok","timestamp":1699296890498,"user_tz":-60,"elapsed":474,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"93fdc752-0ba6-454b-9dc5-6a21220f93c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rnn.encoding_layer.weight\n","Parameter containing:\n","tensor([[-1.5405, -0.3515, -0.3186,  ...,  0.6964,  1.0487, -0.4811],\n","        [ 0.8839, -0.1836, -0.0400,  ...,  0.5956, -0.0908,  0.0568],\n","        [ 0.0724, -0.8025,  0.7511,  ...,  0.9484, -1.0034, -1.4723],\n","        ...,\n","        [ 1.0028,  0.0467, -0.6503,  ..., -0.5072, -0.6748,  1.6817],\n","        [ 1.0575, -0.2266,  0.2583,  ...,  0.2257, -0.0640,  0.3134],\n","        [-0.4202,  0.1140, -0.7010,  ...,  0.8381,  2.6865,  2.0627]],\n","       device='cuda:0', requires_grad=True)\n","rnn.LayerNorm.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.LayerNorm.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_weight\n","Parameter containing:\n","tensor([[-0.0273,  0.0234, -0.0156,  ...,  0.0195, -0.0024,  0.0273],\n","        [-0.0068,  0.0117, -0.0273,  ..., -0.0024,  0.0039,  0.0156],\n","        [-0.0312,  0.0273, -0.0273,  ...,  0.0117, -0.0137,  0.0098],\n","        ...,\n","        [ 0.0117, -0.0049,  0.0006,  ...,  0.0117, -0.0137,  0.0273],\n","        [ 0.0234, -0.0195,  0.0156,  ...,  0.0059, -0.0137,  0.0195],\n","        [ 0.0010,  0.0049, -0.0195,  ...,  0.0312,  0.0012, -0.0098]],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.weight\n","Parameter containing:\n","tensor([[-0.0014, -0.0226, -0.0189,  ..., -0.0200, -0.0068,  0.0220],\n","        [ 0.0086,  0.0007,  0.0198,  ...,  0.0250,  0.0038, -0.0009],\n","        [ 0.0010, -0.0074, -0.0139,  ..., -0.0221,  0.0087, -0.0049],\n","        ...,\n","        [-0.0157, -0.0159,  0.0214,  ...,  0.0228,  0.0173, -0.0126],\n","        [-0.0174,  0.0208,  0.0102,  ..., -0.0101,  0.0187, -0.0011],\n","        [-0.0118,  0.0135,  0.0247,  ...,  0.0206, -0.0031, -0.0079]],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear1.weight\n","Parameter containing:\n","tensor([[-0.0084,  0.0118,  0.0040,  ..., -0.0175, -0.0062, -0.0097],\n","        [ 0.0020,  0.0058, -0.0152,  ..., -0.0127,  0.0120,  0.0075],\n","        [ 0.0050, -0.0022,  0.0027,  ...,  0.0217,  0.0047, -0.0232],\n","        ...,\n","        [-0.0251, -0.0140, -0.0253,  ..., -0.0110, -0.0251,  0.0013],\n","        [ 0.0171,  0.0218,  0.0146,  ...,  0.0206, -0.0252,  0.0053],\n","        [ 0.0104, -0.0117, -0.0199,  ..., -0.0194,  0.0004,  0.0190]],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear1.bias\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear2.weight\n","Parameter containing:\n","tensor([[ 2.0869e-02, -8.5141e-03,  2.1004e-02,  ..., -1.8733e-03,\n","          1.1463e-02,  1.6535e-02],\n","        [-1.6825e-02,  1.6355e-02, -6.2599e-03,  ..., -4.5087e-05,\n","          1.2243e-02,  1.0091e-02],\n","        [ 3.3961e-04, -1.4036e-02, -6.5373e-03,  ..., -1.0413e-02,\n","         -1.9913e-03,  4.7169e-03],\n","        ...,\n","        [-2.0588e-02, -1.0654e-02,  1.2563e-02,  ...,  9.3520e-03,\n","          1.8594e-03,  7.0706e-03],\n","        [-6.6939e-03, -1.0174e-02, -5.4319e-03,  ...,  1.2738e-03,\n","          1.9165e-02, -2.0058e-02],\n","        [ 1.5700e-02, -6.7736e-03,  1.9677e-02,  ..., -8.6711e-03,\n","          4.6090e-03,  2.6161e-03]], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear2.bias\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm1.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm1.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm2.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm2.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_weight\n","Parameter containing:\n","tensor([[-0.0259,  0.0252, -0.0164,  ...,  0.0188, -0.0027,  0.0262],\n","        [-0.0071,  0.0112, -0.0260,  ..., -0.0024,  0.0040,  0.0174],\n","        [-0.0320,  0.0311, -0.0278,  ...,  0.0122, -0.0134,  0.0101],\n","        ...,\n","        [ 0.0119, -0.0051,  0.0007,  ...,  0.0123, -0.0144,  0.0256],\n","        [ 0.0249, -0.0212,  0.0166,  ...,  0.0063, -0.0140,  0.0194],\n","        [ 0.0010,  0.0051, -0.0188,  ...,  0.0316,  0.0012, -0.0100]],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.weight\n","Parameter containing:\n","tensor([[-0.0014, -0.0226, -0.0189,  ..., -0.0200, -0.0068,  0.0220],\n","        [ 0.0086,  0.0007,  0.0198,  ...,  0.0250,  0.0038, -0.0009],\n","        [ 0.0010, -0.0074, -0.0139,  ..., -0.0221,  0.0087, -0.0049],\n","        ...,\n","        [-0.0157, -0.0159,  0.0214,  ...,  0.0228,  0.0173, -0.0126],\n","        [-0.0174,  0.0208,  0.0102,  ..., -0.0101,  0.0187, -0.0011],\n","        [-0.0118,  0.0135,  0.0247,  ...,  0.0206, -0.0031, -0.0079]],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear1.weight\n","Parameter containing:\n","tensor([[-0.0084,  0.0118,  0.0040,  ..., -0.0175, -0.0062, -0.0097],\n","        [ 0.0020,  0.0058, -0.0152,  ..., -0.0127,  0.0120,  0.0075],\n","        [ 0.0050, -0.0022,  0.0027,  ...,  0.0217,  0.0047, -0.0232],\n","        ...,\n","        [-0.0251, -0.0140, -0.0253,  ..., -0.0110, -0.0251,  0.0013],\n","        [ 0.0171,  0.0218,  0.0146,  ...,  0.0206, -0.0252,  0.0053],\n","        [ 0.0104, -0.0117, -0.0199,  ..., -0.0194,  0.0004,  0.0190]],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear1.bias\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear2.weight\n","Parameter containing:\n","tensor([[ 2.0869e-02, -8.5141e-03,  2.1004e-02,  ..., -1.8733e-03,\n","          1.1463e-02,  1.6535e-02],\n","        [-1.6825e-02,  1.6355e-02, -6.2599e-03,  ..., -4.5087e-05,\n","          1.2243e-02,  1.0091e-02],\n","        [ 3.3961e-04, -1.4036e-02, -6.5373e-03,  ..., -1.0413e-02,\n","         -1.9913e-03,  4.7169e-03],\n","        ...,\n","        [-2.0588e-02, -1.0654e-02,  1.2563e-02,  ...,  9.3520e-03,\n","          1.8594e-03,  7.0706e-03],\n","        [-6.6939e-03, -1.0174e-02, -5.4319e-03,  ...,  1.2738e-03,\n","          1.9165e-02, -2.0058e-02],\n","        [ 1.5700e-02, -6.7736e-03,  1.9677e-02,  ..., -8.6711e-03,\n","          4.6090e-03,  2.6161e-03]], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear2.bias\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm1.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm1.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm2.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm2.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_out.weight\n","Parameter containing:\n","tensor([[ 2.4984e-02,  1.6558e-02, -2.6441e-02,  ..., -3.8561e-03,\n","          2.0609e-02,  1.2387e-02],\n","        [-8.8269e-03,  1.4057e-02, -1.1591e-02,  ..., -1.7771e-02,\n","         -1.2314e-02,  2.3355e-05],\n","        [ 1.8611e-02, -2.0347e-02,  6.3983e-03,  ..., -1.3365e-02,\n","          2.3725e-02,  3.1175e-03],\n","        ...,\n","        [ 1.4700e-02, -5.5198e-03,  9.9011e-03,  ..., -3.3344e-03,\n","         -2.0279e-02,  1.5662e-02],\n","        [-1.3611e-02,  2.5969e-02, -1.3062e-02,  ..., -2.4252e-02,\n","          7.9059e-03,  1.4950e-02],\n","        [ 1.8431e-02,  9.6439e-03,  2.5457e-02,  ..., -1.3059e-02,\n","          1.1863e-02,  7.4251e-03]], device='cuda:0', requires_grad=True)\n","rnn.transformer_out.bias\n","Parameter containing:\n","tensor([-0.0237, -0.0019,  0.0154, -0.0216,  0.0066, -0.0017,  0.0199,  0.0266,\n","         0.0194, -0.0110,  0.0025, -0.0085,  0.0250, -0.0166, -0.0241,  0.0258,\n","         0.0260, -0.0247, -0.0003, -0.0005,  0.0119,  0.0039, -0.0158, -0.0170,\n","        -0.0240, -0.0061,  0.0159,  0.0231,  0.0239, -0.0204,  0.0044, -0.0196,\n","         0.0142,  0.0097, -0.0032,  0.0267, -0.0169,  0.0210, -0.0201,  0.0115,\n","        -0.0181,  0.0268, -0.0008, -0.0108,  0.0223, -0.0038, -0.0031, -0.0022,\n","        -0.0057, -0.0128, -0.0033,  0.0261,  0.0150, -0.0189, -0.0142, -0.0236,\n","         0.0166, -0.0081,  0.0063,  0.0098,  0.0240, -0.0096,  0.0039,  0.0220,\n","        -0.0135, -0.0248,  0.0123,  0.0050, -0.0178, -0.0239, -0.0010,  0.0140,\n","        -0.0104,  0.0111, -0.0201, -0.0107, -0.0067, -0.0072, -0.0202,  0.0213,\n","        -0.0018, -0.0013, -0.0051, -0.0153,  0.0069,  0.0127, -0.0123, -0.0153,\n","         0.0236, -0.0034, -0.0097,  0.0066,  0.0089,  0.0014,  0.0149, -0.0040,\n","        -0.0189,  0.0242, -0.0119,  0.0069], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv1.weight\n","Parameter containing:\n","tensor([[[ 1.6582e-02, -1.3431e-01,  1.6853e-01,  ...,  1.2562e-01,\n","          -6.8343e-02,  9.3560e-02],\n","         [-2.0877e-02,  1.6033e-01,  2.8398e-02,  ...,  4.4662e-02,\n","          -8.9625e-02,  1.3199e-01],\n","         [-9.5914e-03,  1.0323e-01,  3.0253e-02,  ..., -1.9400e-03,\n","          -1.4211e-01, -3.8304e-02],\n","         ...,\n","         [ 6.5313e-02,  1.4216e-01, -9.1744e-02,  ...,  9.6574e-02,\n","          -1.1501e-01,  1.1290e-01],\n","         [-1.1431e-01,  1.0135e-01,  1.4859e-01,  ..., -2.4445e-02,\n","           1.0971e-01,  1.5096e-01],\n","         [ 1.6420e-01, -3.7805e-02, -2.6450e-02,  ...,  1.1648e-01,\n","           7.9652e-02,  1.3288e-01]],\n","\n","        [[ 1.5409e-02, -5.6110e-02, -2.0907e-02,  ...,  9.3222e-02,\n","          -5.1245e-02,  1.6460e-01],\n","         [-1.2521e-01,  1.1457e-01, -6.1809e-02,  ..., -1.2908e-01,\n","          -1.7091e-03, -6.0869e-02],\n","         [ 2.4026e-03,  7.3515e-02, -1.3289e-01,  ...,  4.3223e-02,\n","          -9.7678e-02,  7.4335e-03],\n","         ...,\n","         [-8.4151e-02, -1.0343e-01, -4.8406e-02,  ..., -5.7894e-02,\n","          -1.4149e-01,  3.5637e-02],\n","         [-1.3587e-01, -5.7538e-02, -4.1014e-02,  ...,  6.7520e-02,\n","          -2.9771e-02, -3.5700e-02],\n","         [-3.0564e-02,  4.9192e-02, -3.5899e-03,  ..., -4.2687e-02,\n","          -1.0330e-01,  1.0585e-01]],\n","\n","        [[-1.1084e-01,  7.6488e-02, -1.6731e-01,  ..., -1.5689e-01,\n","           1.6446e-01,  3.8542e-02],\n","         [ 9.8609e-02, -1.0977e-01, -1.6547e-01,  ..., -4.6237e-02,\n","          -1.7273e-01, -1.2512e-01],\n","         [ 6.5630e-02, -1.2892e-01, -1.0988e-01,  ...,  9.2844e-02,\n","           7.1886e-02,  4.0516e-02],\n","         ...,\n","         [ 1.1855e-01,  4.7659e-02,  2.5397e-06,  ..., -4.1719e-02,\n","          -8.5762e-02,  1.2041e-02],\n","         [ 1.7116e-01,  1.2255e-03,  1.3028e-01,  ...,  7.5069e-02,\n","           4.1681e-02, -3.3303e-02],\n","         [ 1.5025e-01,  8.7002e-02, -1.3950e-01,  ..., -1.6624e-01,\n","           6.5730e-02, -1.3794e-01]],\n","\n","        ...,\n","\n","        [[ 1.1076e-01, -1.1498e-03, -1.4969e-02,  ...,  2.7424e-02,\n","           1.4174e-01, -1.0429e-01],\n","         [ 1.6850e-02,  3.6850e-03,  8.4550e-02,  ..., -7.5537e-02,\n","           3.7585e-02,  8.9450e-02],\n","         [-1.6513e-02, -6.2987e-02,  3.2054e-02,  ...,  5.5465e-02,\n","          -1.5556e-01,  8.0662e-02],\n","         ...,\n","         [-7.9558e-02,  6.9347e-02, -1.1021e-01,  ..., -8.0035e-02,\n","          -1.4888e-01, -2.9130e-02],\n","         [-3.1670e-02, -7.9053e-03, -3.4559e-02,  ...,  7.9934e-02,\n","           2.3772e-02,  1.0117e-01],\n","         [ 1.7169e-01, -4.5485e-02,  8.9173e-02,  ..., -1.3702e-01,\n","          -7.0493e-02, -1.3707e-01]],\n","\n","        [[-1.7282e-01, -6.7311e-02, -4.5677e-04,  ...,  8.2353e-02,\n","           3.5404e-02, -1.6631e-01],\n","         [ 9.6810e-02,  9.6563e-02, -4.6726e-02,  ..., -1.5660e-02,\n","          -4.4498e-02,  5.5897e-02],\n","         [-2.0039e-02,  2.3450e-02, -3.1461e-02,  ..., -8.4559e-02,\n","           6.4600e-02, -5.2359e-02],\n","         ...,\n","         [ 1.3008e-01,  8.9584e-03, -1.6023e-01,  ..., -7.9813e-02,\n","          -5.7333e-03, -6.1719e-02],\n","         [-7.5051e-02, -4.8246e-02,  1.2212e-01,  ...,  1.0150e-01,\n","          -1.3183e-01, -8.4711e-02],\n","         [-9.7848e-02,  7.1510e-02,  1.6363e-01,  ..., -1.1801e-01,\n","          -1.2522e-01, -1.5734e-02]],\n","\n","        [[ 3.2423e-02,  1.1153e-01, -2.2742e-02,  ...,  1.1291e-02,\n","          -3.5621e-03, -1.6378e-01],\n","         [ 1.7007e-03, -1.5814e-02,  3.9323e-02,  ..., -1.4504e-01,\n","          -3.6988e-02, -3.0379e-02],\n","         [-5.5274e-02, -9.2263e-02,  6.0870e-02,  ...,  5.1990e-02,\n","          -1.3338e-01, -2.5550e-02],\n","         ...,\n","         [-1.4579e-01, -3.0353e-02,  1.7217e-01,  ..., -1.3854e-02,\n","          -4.1705e-02,  7.1086e-02],\n","         [ 7.5531e-02,  1.0533e-02,  1.0539e-01,  ..., -1.5635e-01,\n","          -2.0977e-02,  1.1567e-01],\n","         [-9.1419e-02,  1.3962e-01,  6.3996e-02,  ...,  9.5708e-02,\n","          -1.6083e-01, -1.2422e-01]]], device='cuda:0', requires_grad=True)\n","gcn.conv1.root\n","Parameter containing:\n","tensor([[ 0.0274, -0.0502, -0.0844,  ..., -0.0995, -0.0979, -0.1528],\n","        [-0.1539,  0.1320,  0.0259,  ..., -0.0222,  0.0257, -0.1293],\n","        [ 0.0880,  0.1243,  0.1588,  ..., -0.0705, -0.1279, -0.0586],\n","        ...,\n","        [ 0.0058, -0.0671, -0.1112,  ..., -0.0300,  0.0224,  0.0741],\n","        [ 0.0670, -0.0065, -0.0570,  ..., -0.0187,  0.0265,  0.1021],\n","        [ 0.0439,  0.1176, -0.0520,  ...,  0.0585, -0.0172, -0.0924]],\n","       device='cuda:0', requires_grad=True)\n","gcn.conv1.bias\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","gcn.conv2.lin_key.weight\n","Parameter containing:\n","tensor([[-0.0865,  0.0557,  0.0943,  ...,  0.0423, -0.0932, -0.0796],\n","        [ 0.0401,  0.0460, -0.0147,  ...,  0.0491,  0.0223,  0.0244],\n","        [ 0.0470,  0.0826, -0.0856,  ...,  0.0547,  0.0779, -0.0666],\n","        ...,\n","        [-0.0128,  0.0663, -0.0294,  ...,  0.0499,  0.0731,  0.0199],\n","        [ 0.0939, -0.0319,  0.0667,  ..., -0.0079, -0.0990, -0.0265],\n","        [ 0.0504, -0.0166,  0.0392,  ..., -0.0230,  0.0501, -0.0204]],\n","       device='cuda:0', requires_grad=True)\n","gcn.conv2.lin_key.bias\n","Parameter containing:\n","tensor([-0.0991, -0.0645,  0.0659,  0.0654, -0.0402, -0.0288,  0.0769, -0.0589,\n","        -0.0395,  0.0581, -0.0294,  0.0154, -0.0524, -0.0345, -0.0896, -0.0972,\n","         0.0742, -0.0360, -0.0624,  0.0558, -0.0155,  0.0944, -0.0256,  0.0330,\n","        -0.0339,  0.0102, -0.0313,  0.0378,  0.0945,  0.0516,  0.0905, -0.0068,\n","        -0.0480,  0.0047, -0.0101,  0.0159,  0.0123,  0.0081, -0.0227,  0.0719,\n","        -0.0500, -0.0148,  0.0014, -0.0990, -0.0476, -0.0772,  0.0749,  0.0579,\n","         0.0348,  0.0828,  0.0040, -0.0983,  0.0519,  0.0715, -0.0695,  0.0353,\n","         0.0111,  0.0414,  0.0267,  0.0704,  0.0966,  0.0561, -0.0895, -0.0112,\n","         0.0244, -0.0855,  0.0741, -0.0169,  0.0806,  0.0364, -0.0460, -0.0708,\n","        -0.0234, -0.0690,  0.0912, -0.0198,  0.0560, -0.0923, -0.0191,  0.0723,\n","        -0.0498, -0.0692, -0.0081, -0.0869, -0.0146, -0.0728, -0.0717, -0.0291,\n","         0.0041, -0.0866,  0.0837, -0.0719,  0.0169, -0.0703, -0.0148,  0.0263,\n","         0.0859, -0.0849,  0.0308,  0.0992], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_query.weight\n","Parameter containing:\n","tensor([[-0.0791,  0.0795,  0.0408,  ...,  0.0377,  0.0531, -0.0626],\n","        [-0.0050,  0.0656,  0.0530,  ...,  0.0558, -0.0417,  0.0387],\n","        [ 0.0983,  0.0689, -0.0153,  ..., -0.0122, -0.0768, -0.0312],\n","        ...,\n","        [-0.0043,  0.0522,  0.0273,  ..., -0.0355,  0.0241, -0.0647],\n","        [-0.0206, -0.0310,  0.0278,  ..., -0.0044,  0.0822,  0.0784],\n","        [ 0.0896, -0.0077,  0.0540,  ..., -0.0592,  0.0440, -0.0459]],\n","       device='cuda:0', requires_grad=True)\n","gcn.conv2.lin_query.bias\n","Parameter containing:\n","tensor([ 0.0844, -0.0540,  0.0126, -0.0950,  0.0963,  0.0158,  0.0484, -0.0252,\n","        -0.0592, -0.0308, -0.0575,  0.0020,  0.0458,  0.0818,  0.0884, -0.0058,\n","        -0.0778,  0.0817, -0.0452,  0.0860,  0.0510,  0.0915, -0.0950,  0.0601,\n","         0.0545,  0.0739, -0.0680,  0.0799,  0.0136,  0.0287, -0.0594, -0.0541,\n","         0.0699, -0.0706,  0.0047,  0.0079,  0.0449, -0.0395,  0.0789, -0.0041,\n","         0.0744, -0.0185, -0.0451,  0.0060, -0.0579,  0.0737, -0.0798, -0.0454,\n","        -0.0783,  0.0356,  0.0202, -0.0507, -0.0163, -0.0913,  0.0450, -0.0299,\n","         0.0291, -0.0776, -0.0830,  0.0933,  0.0382,  0.0338,  0.0806,  0.0377,\n","        -0.0619,  0.0079, -0.0473,  0.0775,  0.0367, -0.0272, -0.0228,  0.0356,\n","         0.0633,  0.0148, -0.0781,  0.0601, -0.0574, -0.0071,  0.0348,  0.0293,\n","        -0.0004,  0.0148, -0.0091, -0.0914,  0.0584, -0.0131,  0.0069,  0.0793,\n","         0.0437, -0.0174,  0.0669, -0.0204, -0.0894, -0.0581,  0.0307,  0.0181,\n","        -0.0044,  0.0399,  0.0194,  0.0123], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_value.weight\n","Parameter containing:\n","tensor([[ 0.0830, -0.0755,  0.0408,  ...,  0.0959,  0.0083,  0.0700],\n","        [-0.0234, -0.0279,  0.0745,  ..., -0.0575,  0.0525,  0.0360],\n","        [ 0.0344, -0.0929,  0.0970,  ..., -0.0875,  0.0350, -0.0099],\n","        ...,\n","        [-0.0051, -0.0935, -0.0476,  ..., -0.0231, -0.0791, -0.0835],\n","        [ 0.0914, -0.0294, -0.0212,  ..., -0.0998,  0.0005, -0.0455],\n","        [-0.0267, -0.0676,  0.0431,  ..., -0.0472,  0.0400,  0.0232]],\n","       device='cuda:0', requires_grad=True)\n","gcn.conv2.lin_value.bias\n","Parameter containing:\n","tensor([ 0.0306, -0.0675,  0.0779, -0.0751,  0.0946,  0.0238,  0.0302,  0.0231,\n","         0.0905, -0.0692, -0.0250, -0.0581, -0.0854,  0.0074,  0.0140, -0.0213,\n","         0.0408, -0.0691, -0.0963,  0.0497,  0.0574,  0.0611, -0.0365,  0.0188,\n","         0.0154,  0.0268, -0.0787, -0.0108,  0.0175,  0.0115,  0.0355,  0.0209,\n","         0.0909,  0.0026, -0.0055, -0.0443, -0.0840, -0.0966,  0.0668,  0.0801,\n","         0.0125,  0.0825, -0.0179,  0.0365, -0.0724,  0.0683,  0.0884, -0.0132,\n","         0.0536, -0.0181, -0.0505, -0.0995,  0.0074,  0.0134,  0.0057,  0.0421,\n","        -0.0250, -0.0813,  0.0889, -0.0230,  0.0081,  0.0937,  0.0527,  0.0064,\n","        -0.0635,  0.0295,  0.0940,  0.0128, -0.0440, -0.0997,  0.0727, -0.0642,\n","         0.0064, -0.0042,  0.0485,  0.0016, -0.0898,  0.0380, -0.0373,  0.0329,\n","        -0.0438, -0.0771,  0.0502,  0.0544,  0.0896,  0.0860,  0.0351, -0.0568,\n","        -0.0504, -0.0295,  0.0136,  0.0565,  0.0154, -0.0799,  0.0566,  0.0004,\n","        -0.0276, -0.0160,  0.0806, -0.0563], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_skip.weight\n","Parameter containing:\n","tensor([[ 0.0565, -0.0222, -0.0746,  ...,  0.0417, -0.0265, -0.0481],\n","        [-0.0166, -0.0396,  0.0173,  ..., -0.0797, -0.0762, -0.0712],\n","        [ 0.0338,  0.0527,  0.0186,  ...,  0.0390,  0.0497,  0.0731],\n","        ...,\n","        [ 0.0352,  0.0104, -0.0592,  ..., -0.0887, -0.0895, -0.0871],\n","        [ 0.0406, -0.0364, -0.0565,  ..., -0.0911,  0.0900,  0.0389],\n","        [-0.0684,  0.0821, -0.0839,  ..., -0.0797,  0.0916,  0.0085]],\n","       device='cuda:0', requires_grad=True)\n","gcn.conv2.lin_skip.bias\n","Parameter containing:\n","tensor([-0.0308,  0.0801,  0.0266, -0.0314,  0.0104,  0.0130, -0.0156,  0.0803,\n","         0.0438, -0.0490, -0.0382, -0.0941, -0.0902, -0.0199, -0.0012,  0.0091,\n","        -0.0841,  0.0825,  0.0716,  0.0114,  0.0145,  0.0292, -0.0095, -0.0523,\n","        -0.0435,  0.0970, -0.0484, -0.0765,  0.0037,  0.0982,  0.0957, -0.0860,\n","         0.0990, -0.0020,  0.0885,  0.0925, -0.0574,  0.0311,  0.0379,  0.0964,\n","         0.0221, -0.0952, -0.0198,  0.0791,  0.0117, -0.0456, -0.0678, -0.0059,\n","        -0.0833, -0.0743,  0.0641,  0.0344,  0.0156,  0.0787, -0.0277, -0.0554,\n","         0.0258,  0.0452,  0.0385, -0.0764,  0.0068, -0.0177, -0.0807,  0.0157,\n","         0.0582, -0.0685, -0.0224,  0.0935, -0.0355, -0.0810,  0.0225,  0.0638,\n","        -0.0300,  0.0542, -0.0498,  0.0452,  0.0785, -0.0273,  0.0495,  0.0386,\n","        -0.0396, -0.0357,  0.0272,  0.0535, -0.0344,  0.0526,  0.0696,  0.0649,\n","        -0.0151, -0.0117, -0.0287, -0.0673, -0.0992,  0.0611, -0.0836,  0.0084,\n","         0.0388, -0.0170, -0.0613,  0.0066], device='cuda:0',\n","       requires_grad=True)\n","gcn.bn.weight\n","Parameter containing:\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n","       requires_grad=True)\n","gcn.bn.bias\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","clf.emotion_att.lin.weight\n","Parameter containing:\n","tensor([[-0.0172,  0.0947, -0.0276,  ..., -0.0499,  0.0160, -0.0662],\n","        [ 0.0054,  0.0051, -0.0466,  ..., -0.0585, -0.0102, -0.0598],\n","        [ 0.0408, -0.0813,  0.0862,  ...,  0.0764,  0.0062, -0.0187],\n","        ...,\n","        [-0.0210,  0.0758, -0.0153,  ...,  0.0263, -0.0525, -0.0431],\n","        [-0.0590, -0.0256,  0.0882,  ..., -0.0912, -0.0024, -0.0855],\n","        [-0.0632,  0.0205, -0.0181,  ...,  0.0766,  0.0883,  0.0985]],\n","       device='cuda:0', requires_grad=True)\n","clf.emotion_att.lin.bias\n","Parameter containing:\n","tensor([ 0.0310,  0.0380, -0.0270,  0.0616,  0.0820,  0.0194,  0.0414,  0.0748,\n","         0.0330,  0.0831,  0.0034,  0.0888,  0.0091,  0.0931, -0.0020, -0.0580,\n","         0.0661, -0.0747, -0.0491,  0.0810,  0.0530,  0.0116, -0.0121,  0.0282,\n","        -0.0779,  0.0609, -0.0757, -0.0821,  0.0575,  0.0776,  0.0181, -0.0829,\n","         0.0946, -0.0726, -0.0235,  0.0449, -0.0922,  0.0536, -0.0730,  0.0249,\n","         0.0904,  0.0433, -0.0917,  0.0633,  0.0089,  0.0950,  0.0087, -0.0402,\n","        -0.0597,  0.0468,  0.0204,  0.0430,  0.0969,  0.0721, -0.0305,  0.0817,\n","        -0.0891,  0.0436,  0.0550, -0.0598,  0.0487,  0.0882, -0.0499,  0.0563,\n","        -0.0053, -0.0135,  0.0023,  0.0129,  0.0088,  0.0951,  0.0256,  0.0588,\n","         0.0467, -0.0100,  0.0629,  0.0385,  0.0327, -0.0063,  0.0411,  0.0238,\n","        -0.0555,  0.0076, -0.0277,  0.0397,  0.0540, -0.0323,  0.0654,  0.0193,\n","         0.0073, -0.0495,  0.0974,  0.0709, -0.0407,  0.0425, -0.0466, -0.0998,\n","        -0.0476,  0.0579,  0.0170, -0.0154], device='cuda:0',\n","       requires_grad=True)\n","clf.lin1.weight\n","Parameter containing:\n","tensor([[-0.0434,  0.0086, -0.0120,  ...,  0.0496,  0.0390, -0.0866],\n","        [-0.0749,  0.0350, -0.0951,  ..., -0.0706,  0.0588,  0.0021],\n","        [-0.0388,  0.0280,  0.0116,  ...,  0.0584, -0.0222, -0.0533],\n","        ...,\n","        [ 0.0911, -0.0513, -0.0338,  ...,  0.0881, -0.0520, -0.0913],\n","        [-0.0867, -0.0916,  0.0116,  ...,  0.0382, -0.0891,  0.0327],\n","        [ 0.0650,  0.0633, -0.0304,  ..., -0.0735, -0.0848,  0.0331]],\n","       device='cuda:0', requires_grad=True)\n","clf.lin1.bias\n","Parameter containing:\n","tensor([ 0.0762,  0.0880,  0.0464, -0.0047, -0.0801,  0.0563, -0.0795,  0.0890,\n","        -0.0352,  0.0643,  0.0485, -0.0053,  0.0714,  0.0026, -0.0216, -0.0704,\n","        -0.0150, -0.0501,  0.0022, -0.0042, -0.0394, -0.0176, -0.0425, -0.0123,\n","         0.0639,  0.0825,  0.0975,  0.0034, -0.0228,  0.0310, -0.0805, -0.0970,\n","         0.0286,  0.0184, -0.0883, -0.0630, -0.0171,  0.0793, -0.0963,  0.0190,\n","        -0.0941,  0.0329, -0.0340,  0.0827, -0.0255, -0.0977, -0.0589, -0.0200,\n","         0.0264,  0.0662, -0.0427, -0.0884,  0.0804, -0.0999,  0.0478, -0.0508,\n","        -0.0996, -0.0331,  0.0474, -0.0676, -0.0393,  0.0500,  0.0556, -0.0434,\n","         0.0044,  0.0449, -0.0820,  0.0411,  0.0597, -0.0488, -0.0330, -0.0831,\n","        -0.0663,  0.0483,  0.0922,  0.0776,  0.0448,  0.0970, -0.0049,  0.0961,\n","        -0.0691, -0.0696,  0.0078,  0.0822,  0.0409, -0.0339, -0.0016,  0.0115,\n","         0.0268,  0.0511, -0.0959,  0.0652, -0.0786, -0.0495,  0.0145, -0.0486,\n","        -0.0473,  0.0061, -0.0123, -0.0757], device='cuda:0',\n","       requires_grad=True)\n","clf.lin2.weight\n","Parameter containing:\n","tensor([[-0.0231,  0.0611, -0.0787,  0.0208, -0.0325, -0.0179,  0.0858,  0.0240,\n","          0.0452,  0.0141, -0.0551, -0.0677, -0.0971,  0.0159, -0.0582,  0.0989,\n","          0.0087,  0.0731,  0.0133, -0.0791,  0.0133, -0.0140, -0.0680, -0.0884,\n","          0.0878,  0.0514,  0.0080, -0.0810, -0.0717, -0.0309,  0.0464,  0.0950,\n","         -0.0992, -0.0224,  0.0128, -0.0534, -0.0526,  0.0388, -0.0183,  0.0360,\n","         -0.0100,  0.0593,  0.0493, -0.0215, -0.0399,  0.0005, -0.0545,  0.0124,\n","          0.0686,  0.0796, -0.0474,  0.0033, -0.0698, -0.0670, -0.0236,  0.0904,\n","         -0.0590,  0.0498,  0.0334, -0.0610,  0.0215, -0.0607, -0.0125, -0.0627,\n","         -0.0616, -0.0220, -0.0340,  0.0952, -0.0740, -0.0041,  0.0940, -0.0466,\n","          0.0726,  0.0101,  0.0199,  0.0670,  0.0270,  0.0532,  0.0753,  0.0052,\n","         -0.0570, -0.0499, -0.0217, -0.0514, -0.0888, -0.0517,  0.0741,  0.0367,\n","         -0.0051, -0.0141, -0.0624, -0.0814,  0.0996,  0.0777, -0.0336, -0.0545,\n","          0.0083, -0.0372, -0.0658,  0.0475],\n","        [-0.0887,  0.0061,  0.0557, -0.0997,  0.0822,  0.0523, -0.0168,  0.0312,\n","         -0.0675,  0.0925,  0.0723, -0.0089, -0.0586,  0.0305,  0.0751,  0.0910,\n","         -0.0702,  0.0365, -0.0543,  0.0682, -0.0177, -0.0043,  0.0875, -0.0217,\n","         -0.0706,  0.0450,  0.0845,  0.0509, -0.0112, -0.0370, -0.0791,  0.0290,\n","          0.0335,  0.0942,  0.0801,  0.0361, -0.0462, -0.0519, -0.0091, -0.0028,\n","          0.0286,  0.0074, -0.0334, -0.0272,  0.0954, -0.0801, -0.0716,  0.0755,\n","          0.0281,  0.0286,  0.0978, -0.0170, -0.0588, -0.0374, -0.0474,  0.0943,\n","          0.0406, -0.0713,  0.0811,  0.0846,  0.0425, -0.0403,  0.0748,  0.0964,\n","         -0.0210, -0.0854, -0.0432,  0.0674, -0.0986, -0.0366, -0.0024,  0.0736,\n","          0.0814,  0.0468,  0.0756,  0.0454,  0.0611,  0.0264, -0.0832, -0.0504,\n","          0.0090,  0.0613,  0.0328,  0.0011, -0.0781, -0.0569,  0.0580, -0.0612,\n","         -0.0112,  0.0953, -0.0890, -0.0999,  0.0757, -0.0432,  0.0427,  0.0807,\n","         -0.0198,  0.0426,  0.0032,  0.0097],\n","        [ 0.0825, -0.0316,  0.0453,  0.0068, -0.0850, -0.0506,  0.0938, -0.0513,\n","         -0.0469,  0.0407,  0.0207,  0.0267,  0.0225, -0.0345,  0.0514,  0.0943,\n","         -0.0311, -0.0429, -0.0698,  0.0349, -0.0202,  0.0334,  0.0748,  0.0123,\n","          0.0807, -0.0216,  0.0192,  0.0024, -0.0322,  0.0853,  0.0491, -0.0157,\n","         -0.0202, -0.0946,  0.0741,  0.0896,  0.0888, -0.0490, -0.0973,  0.0734,\n","         -0.0716,  0.0176, -0.0960,  0.0396,  0.0915,  0.0535, -0.0481, -0.0212,\n","          0.0518,  0.0345, -0.0641,  0.0643,  0.0553,  0.0081, -0.0131,  0.0127,\n","          0.0161, -0.0391, -0.0295, -0.0814,  0.0737, -0.0275, -0.0418, -0.0424,\n","          0.0463,  0.0891,  0.0742, -0.0046,  0.0606,  0.0959, -0.0709, -0.0815,\n","          0.0237,  0.0311,  0.0638,  0.0702, -0.0930,  0.0841, -0.0597, -0.0945,\n","          0.0463,  0.0697, -0.0951,  0.0020, -0.0887,  0.0725,  0.0481, -0.0451,\n","          0.0489,  0.0637, -0.0421, -0.0598, -0.0954,  0.0333,  0.0910,  0.0746,\n","          0.0395, -0.0464, -0.0081, -0.0824],\n","        [ 0.0778, -0.0546,  0.0047, -0.0767,  0.0650,  0.0398,  0.0628, -0.0937,\n","          0.0413, -0.0449, -0.0507, -0.0671,  0.0834,  0.0504,  0.0832, -0.0265,\n","          0.0783,  0.0608, -0.0791,  0.0599,  0.0739,  0.0311, -0.0644,  0.0349,\n","         -0.0015,  0.0565,  0.0164, -0.0660, -0.0076, -0.0227, -0.0965, -0.0106,\n","         -0.0431,  0.0682, -0.0372,  0.0505,  0.0818, -0.0070, -0.0835,  0.0195,\n","         -0.0873, -0.0902,  0.0371, -0.0529, -0.0749, -0.0305,  0.0309,  0.0817,\n","          0.0396,  0.0594, -0.0438,  0.0624,  0.0223, -0.0925, -0.0875, -0.0883,\n","          0.0504, -0.0554, -0.0019,  0.0331,  0.0189,  0.0051,  0.0196,  0.0796,\n","          0.0688,  0.0385,  0.0221, -0.0991,  0.0325,  0.0400, -0.0945,  0.0311,\n","          0.0793,  0.0572, -0.0698,  0.0879,  0.0373, -0.0683, -0.0723, -0.0222,\n","          0.0959,  0.0928,  0.0266, -0.0771, -0.0363,  0.0733,  0.0795,  0.0285,\n","         -0.0027, -0.0727,  0.0796,  0.0783,  0.0180,  0.0913, -0.0250, -0.0435,\n","         -0.0145, -0.0692,  0.0756, -0.0741]], device='cuda:0',\n","       requires_grad=True)\n","clf.lin2.bias\n","Parameter containing:\n","tensor([-0.0843,  0.0371, -0.0800, -0.0725], device='cuda:0',\n","       requires_grad=True)\n","clf.lin_7.weight\n","Parameter containing:\n","tensor([[ 0.0834, -0.0943, -0.0705,  0.0911, -0.0330, -0.0189,  0.0987,  0.0758,\n","          0.0289,  0.0720,  0.0602,  0.0332,  0.0455,  0.0811, -0.0423,  0.0805,\n","         -0.0394,  0.0671,  0.0845,  0.0420, -0.0059, -0.0127,  0.0781,  0.0794,\n","         -0.0482,  0.0572, -0.0529,  0.0534, -0.0361, -0.0407,  0.0101, -0.0319,\n","         -0.0118,  0.0230, -0.0789, -0.0331,  0.0113,  0.0227,  0.0860,  0.0705,\n","          0.0890,  0.0987,  0.0989, -0.0740, -0.0629, -0.0839, -0.0753,  0.0157,\n","         -0.0468, -0.0048, -0.0836,  0.0416, -0.0390, -0.0940, -0.0979, -0.0835,\n","         -0.0644, -0.0229, -0.0746,  0.0164, -0.0059, -0.0550, -0.0054,  0.0785,\n","         -0.0571,  0.0904, -0.0996,  0.0173, -0.0248, -0.0958, -0.0299, -0.0607,\n","          0.0070, -0.0818,  0.0665,  0.0225, -0.0498,  0.0327, -0.0248, -0.0195,\n","         -0.0613,  0.0506, -0.0522, -0.0319, -0.0972, -0.0708, -0.0468,  0.0667,\n","          0.0707, -0.0882, -0.0700,  0.0230, -0.0451,  0.0618,  0.0738, -0.0748,\n","         -0.0888,  0.0003, -0.0213, -0.0383],\n","        [ 0.0497, -0.0458,  0.0927, -0.0153,  0.0009,  0.0293,  0.0871, -0.0481,\n","          0.0630, -0.0508,  0.0252,  0.0323, -0.0280,  0.0664, -0.0858,  0.0442,\n","         -0.0731,  0.0453, -0.0157, -0.0409, -0.0930, -0.0486, -0.0395, -0.0944,\n","          0.0748,  0.0622,  0.0129, -0.0515, -0.0476,  0.0368, -0.0816,  0.0527,\n","         -0.0799,  0.0560,  0.0601, -0.0146,  0.0822,  0.0537,  0.0035, -0.0194,\n","         -0.0526, -0.0206,  0.0178,  0.0630, -0.0139,  0.0730,  0.0578, -0.0139,\n","         -0.0865, -0.0500, -0.0048, -0.0909,  0.0481,  0.0913, -0.0351, -0.0844,\n","         -0.0699,  0.0820, -0.0775,  0.0288, -0.0444, -0.0145, -0.0224, -0.0172,\n","         -0.0339,  0.0793,  0.0209, -0.0790,  0.0667,  0.0368, -0.0456,  0.0910,\n","          0.0074,  0.0121, -0.0539,  0.0283, -0.0199,  0.0225,  0.0534,  0.0749,\n","         -0.0153,  0.0936, -0.0455,  0.0848,  0.0759,  0.0415,  0.0477, -0.0499,\n","         -0.0073,  0.0589, -0.0157,  0.0777, -0.0837, -0.0231, -0.0239,  0.0670,\n","          0.0211,  0.0998, -0.0108, -0.0313],\n","        [-0.0044, -0.0766,  0.0886,  0.0985, -0.0030, -0.0609,  0.0598, -0.0406,\n","          0.0581,  0.0063, -0.0064, -0.0004, -0.0520,  0.0610, -0.0324, -0.0353,\n","          0.0076, -0.0156,  0.0271, -0.0889, -0.0285,  0.0449,  0.0864,  0.0541,\n","         -0.0959,  0.0447,  0.0733,  0.0415,  0.0349,  0.0182, -0.0116, -0.0967,\n","          0.0041,  0.0286,  0.0215, -0.0519,  0.0629, -0.0355,  0.0282,  0.0492,\n","          0.0018,  0.0136,  0.0058, -0.0089,  0.0610,  0.0892,  0.0526,  0.0336,\n","         -0.0876, -0.0336, -0.0566,  0.0631,  0.0933, -0.0117,  0.0882,  0.0115,\n","          0.0193, -0.0981, -0.0300,  0.0051,  0.0401, -0.0464, -0.0553, -0.0293,\n","          0.0426, -0.0720,  0.0768, -0.0069, -0.0725,  0.0814,  0.0939,  0.0849,\n","          0.0276,  0.0921, -0.0836,  0.0572, -0.0279,  0.0794, -0.0763, -0.0896,\n","          0.0899,  0.0730, -0.0071, -0.0560,  0.0354, -0.0346, -0.0768, -0.0906,\n","         -0.0238, -0.0126,  0.0227, -0.0536, -0.0682,  0.0545,  0.0326, -0.0374,\n","          0.0867, -0.0085, -0.0234, -0.0539],\n","        [ 0.0988, -0.0278,  0.0172,  0.0964, -0.0943, -0.0260,  0.0052, -0.0308,\n","          0.0644,  0.0345, -0.0402,  0.0902, -0.0790,  0.0657,  0.0951,  0.0436,\n","         -0.0865, -0.0450,  0.0290, -0.0203, -0.0309,  0.0625, -0.0372,  0.0942,\n","          0.0334, -0.0268, -0.0774,  0.0576, -0.0727,  0.0482,  0.0437, -0.0098,\n","          0.0723,  0.0262, -0.0801,  0.0842,  0.0108,  0.0202, -0.0788, -0.0456,\n","         -0.0515,  0.0389, -0.0465,  0.0086,  0.0035,  0.0658,  0.0625,  0.0381,\n","         -0.0832,  0.0167, -0.0885,  0.0868, -0.0384, -0.0213, -0.0223,  0.0176,\n","         -0.0634, -0.0803, -0.0502, -0.0043,  0.0372,  0.0203, -0.0668, -0.0611,\n","          0.0760, -0.0323,  0.0928,  0.0137, -0.0029, -0.0912,  0.0032, -0.0700,\n","         -0.0506,  0.0061,  0.0126,  0.0724,  0.0073,  0.0654, -0.0269, -0.0865,\n","          0.0970, -0.0166, -0.0321,  0.0384, -0.0476, -0.0943,  0.0246,  0.0782,\n","          0.0913,  0.0398,  0.0495,  0.0481,  0.0314,  0.0634,  0.0430,  0.0513,\n","          0.0203, -0.0662, -0.0516, -0.0097],\n","        [ 0.0053,  0.0321,  0.0597,  0.0981,  0.0801, -0.0124,  0.0739,  0.0257,\n","          0.0044,  0.0693, -0.0201,  0.0722, -0.0360,  0.0197,  0.0762, -0.0949,\n","         -0.0464, -0.0865,  0.0838, -0.0212,  0.0503, -0.0560,  0.0530,  0.0675,\n","         -0.0285,  0.0816,  0.0473, -0.0365, -0.0081, -0.0398, -0.0872, -0.0282,\n","          0.0220,  0.0824, -0.0558,  0.0553,  0.0835,  0.0524,  0.0593, -0.0467,\n","         -0.0999, -0.0225, -0.0604,  0.0902, -0.0133, -0.0549,  0.0590, -0.0328,\n","         -0.0773, -0.0715,  0.0832,  0.0928, -0.0181, -0.0761,  0.0081,  0.0977,\n","         -0.0420, -0.0114,  0.0421,  0.0971,  0.0026,  0.0032, -0.0531,  0.0744,\n","          0.0503, -0.0076, -0.0771,  0.0600, -0.0271,  0.0825,  0.0879, -0.0415,\n","          0.0207,  0.0258,  0.0167, -0.0342,  0.0966, -0.0766, -0.0261,  0.0056,\n","          0.0188,  0.0993, -0.0326,  0.0800,  0.0157,  0.0716, -0.0925,  0.0570,\n","          0.0349, -0.0835, -0.0458,  0.0830, -0.0727,  0.0977, -0.0981,  0.0615,\n","         -0.0933, -0.0832,  0.0037, -0.0677],\n","        [ 0.0606, -0.0847, -0.0863, -0.0942, -0.0155, -0.0866, -0.0359, -0.0417,\n","          0.0576,  0.0920,  0.0527, -0.0705,  0.0965, -0.0434, -0.0656, -0.0341,\n","         -0.0035,  0.0793, -0.0757,  0.0104,  0.0389,  0.0310,  0.0682, -0.0947,\n","         -0.0813, -0.0803, -0.0248,  0.0200, -0.0964, -0.0205, -0.0373,  0.0561,\n","          0.0146,  0.0463, -0.0118, -0.0605, -0.0317, -0.0645, -0.0037,  0.0946,\n","         -0.0662,  0.0861,  0.0470, -0.0370,  0.0128, -0.0678,  0.0611, -0.0047,\n","         -0.0314, -0.0583, -0.0399, -0.0407,  0.0028,  0.0023, -0.0588, -0.0990,\n","          0.0073, -0.0277, -0.0750,  0.0258,  0.0632,  0.0005,  0.0089, -0.0121,\n","         -0.0017,  0.0884, -0.0091,  0.0768,  0.0894,  0.0743,  0.0424, -0.0002,\n","         -0.0688,  0.0524,  0.0670,  0.0388, -0.0205,  0.0624, -0.0983, -0.0177,\n","         -0.0486,  0.0553,  0.0246,  0.0269,  0.0305, -0.0652, -0.0485,  0.0919,\n","         -0.0216, -0.0200,  0.0214,  0.0211, -0.0773,  0.0633,  0.0704,  0.0210,\n","         -0.0108,  0.0251,  0.0873,  0.0616],\n","        [-0.0254,  0.0773,  0.0265,  0.0140, -0.0605,  0.0805,  0.0552,  0.0976,\n","          0.0713, -0.0765, -0.0159,  0.0100, -0.0533, -0.0970,  0.0002, -0.0736,\n","         -0.0393,  0.0227, -0.0079, -0.0616,  0.0222, -0.0873,  0.0775, -0.0589,\n","         -0.0828,  0.0047,  0.0745,  0.0901, -0.0091, -0.0408,  0.0549,  0.0559,\n","          0.0198, -0.0997,  0.0980, -0.0453,  0.0699,  0.0590, -0.0176, -0.0028,\n","         -0.0762, -0.0339,  0.0825,  0.0282, -0.0280,  0.0690, -0.0955,  0.0282,\n","          0.0971,  0.0300, -0.0761, -0.0903, -0.0982, -0.0928,  0.0668, -0.0974,\n","         -0.0169,  0.0213, -0.0546,  0.0489, -0.0981,  0.0656,  0.0099,  0.0584,\n","          0.0716, -0.0411,  0.0817,  0.0224,  0.0323, -0.0643, -0.0453, -0.0654,\n","          0.0893,  0.0732, -0.0483,  0.0959, -0.0846,  0.0975,  0.0915, -0.0078,\n","         -0.0387,  0.0094, -0.0690, -0.0198, -0.0028, -0.0963, -0.0324, -0.0567,\n","          0.0942,  0.0600,  0.0350,  0.0691,  0.0972, -0.0835,  0.0025, -0.0361,\n","         -0.0909, -0.0528,  0.0532,  0.0739]], device='cuda:0',\n","       requires_grad=True)\n","clf.lin_7.bias\n","Parameter containing:\n","tensor([-0.0149, -0.0465,  0.0099,  0.0570,  0.0250,  0.0233,  0.0425],\n","       device='cuda:0', requires_grad=True)\n","clf.linear.weight\n","Parameter containing:\n","tensor([[-3.7008e-02,  7.9037e-02, -9.6631e-02, -7.0181e-02, -7.6220e-02,\n","          7.1087e-02, -7.5496e-02,  8.5444e-02,  8.7223e-02, -9.8911e-03,\n","         -3.8743e-02, -8.4766e-03,  2.1881e-03, -2.2703e-02, -7.0989e-02,\n","         -6.1675e-02,  9.1017e-02,  1.4013e-03,  2.3171e-02,  6.5210e-02,\n","          7.9242e-02, -9.6024e-02,  6.0686e-02,  5.0447e-02,  1.6530e-02,\n","          6.9341e-02, -7.2576e-02,  2.7377e-02, -6.3856e-02, -5.2966e-02,\n","          5.3378e-02,  7.0123e-02, -5.0479e-02, -5.2138e-02, -3.8304e-03,\n","         -8.3463e-02,  7.4907e-02,  2.8172e-02,  3.7462e-02, -7.6788e-03,\n","          1.8110e-02,  7.7666e-02, -9.6967e-02,  1.3185e-02, -2.1135e-02,\n","         -2.3898e-02, -3.2826e-02, -4.0910e-03, -7.9721e-02,  8.5199e-05,\n","          2.4464e-02,  9.9989e-02, -5.4309e-02,  7.1346e-02,  6.5091e-02,\n","          1.5353e-03, -4.1694e-02, -2.0742e-02, -3.5608e-02,  9.5540e-02,\n","          5.2335e-02,  5.4811e-02, -1.8522e-02,  9.6849e-02, -4.3480e-02,\n","          1.1354e-02, -4.5472e-02, -1.7418e-02, -4.4014e-02, -6.7276e-02,\n","          4.8936e-02, -6.7930e-02, -8.2183e-02, -5.6574e-02, -9.4692e-02,\n","          1.7621e-02, -3.1185e-02, -8.5019e-02,  9.4946e-02,  9.2544e-02,\n","         -4.0547e-02, -3.5450e-02,  8.7012e-03, -7.7085e-02,  7.3096e-02,\n","         -7.1997e-02,  3.8798e-02, -8.4740e-02, -2.8832e-02, -7.5049e-02,\n","         -6.9656e-02,  9.5774e-02, -3.8677e-02,  6.0808e-02,  9.4806e-02,\n","         -4.9833e-02, -3.1621e-02,  9.3813e-02, -6.9384e-02, -9.3193e-03],\n","        [-3.7745e-02, -7.9007e-02, -1.7935e-02,  6.8221e-02, -9.0862e-02,\n","         -6.8590e-02,  5.1396e-02,  7.7880e-02, -9.4537e-02,  6.0982e-03,\n","          2.9019e-02, -8.7506e-02,  6.8044e-02, -9.6501e-02,  4.1874e-02,\n","          2.8795e-02, -7.7057e-02, -4.1877e-02,  5.0183e-02,  6.6718e-02,\n","          2.0940e-02, -9.5209e-02, -1.9943e-02,  8.4095e-02, -9.0228e-02,\n","          3.4417e-02,  5.2373e-02, -8.8105e-04,  5.8477e-02, -6.2850e-02,\n","          8.4223e-02, -9.5687e-02, -2.4482e-02, -7.8081e-02,  7.9597e-02,\n","          7.3302e-02, -5.9369e-02, -9.9129e-02, -6.3159e-02, -3.4013e-02,\n","         -1.7812e-02,  6.3520e-02, -5.9161e-02, -1.3957e-02, -6.4666e-02,\n","         -4.7442e-04,  6.0808e-02,  3.7877e-02, -6.4255e-02, -1.6429e-02,\n","          2.5644e-02,  7.2984e-02,  6.0184e-02, -8.8059e-02, -1.7612e-04,\n","          1.4169e-02,  1.3707e-02,  4.0183e-03, -7.9349e-02,  3.1504e-02,\n","          6.0621e-02,  2.9338e-03, -2.1643e-02,  6.5091e-02,  3.2192e-02,\n","         -3.1672e-02, -6.6403e-02,  4.1171e-02, -5.7829e-02,  3.3459e-02,\n","         -8.2749e-02,  6.7642e-02, -7.0015e-02,  1.8995e-02, -2.2135e-02,\n","          6.3580e-02,  9.7481e-02, -9.5915e-02,  1.7965e-02,  7.9938e-02,\n","          8.7038e-02, -7.5593e-02,  6.1347e-02, -2.1588e-02, -8.8184e-02,\n","         -7.1365e-02,  5.0654e-02, -8.8025e-02,  5.5075e-02, -8.3050e-02,\n","          9.2819e-02, -4.7950e-02,  3.8860e-03, -9.7744e-02, -7.4342e-02,\n","          5.2791e-02, -2.1618e-02,  2.3624e-02,  7.2822e-02, -5.7874e-02],\n","        [-2.3270e-02, -1.5211e-03,  4.1247e-02,  1.9910e-02, -1.9437e-02,\n","          8.8854e-02, -9.8614e-02,  5.6692e-03,  4.9072e-02, -4.2134e-02,\n","         -7.2613e-02, -6.7751e-02,  1.4715e-03,  8.6936e-02, -5.6619e-02,\n","         -8.2791e-02,  1.9850e-02,  6.4453e-02,  7.8848e-02, -4.4176e-02,\n","         -1.6888e-03,  3.1146e-02, -4.6494e-02, -4.0280e-02, -5.5082e-02,\n","         -4.7983e-02,  1.3688e-02, -8.2617e-02, -3.1518e-02,  2.5145e-02,\n","         -2.5668e-02, -6.8683e-02, -1.3039e-02, -8.6417e-02,  8.1937e-02,\n","          6.1219e-02,  7.5593e-02,  5.3760e-02, -1.8178e-02,  7.2424e-02,\n","         -4.9915e-04,  1.8730e-02, -2.2597e-02, -1.4228e-02,  8.8367e-02,\n","         -3.0545e-02,  5.3947e-02,  8.5745e-02,  6.6053e-02, -3.2359e-02,\n","          7.6245e-02,  7.8341e-02, -2.8932e-02, -6.8282e-02, -5.8860e-02,\n","          4.4998e-02, -6.3171e-02, -8.1229e-02,  1.4758e-02,  4.3752e-02,\n","         -8.5168e-02, -3.8906e-03, -1.4217e-02,  6.2258e-02, -2.4902e-03,\n","          3.6246e-02,  5.4489e-02, -7.9997e-02, -8.1948e-02, -4.3276e-02,\n","         -7.6598e-02,  4.6952e-03,  2.6509e-02, -8.0612e-02, -7.7331e-02,\n","          4.3601e-02, -5.4205e-02, -1.4563e-02, -1.1350e-03, -4.4241e-02,\n","         -3.3826e-02, -3.9662e-02, -4.4156e-02, -8.6949e-02, -8.3765e-02,\n","          9.8169e-02, -2.1302e-02, -5.2295e-02, -7.6495e-02,  2.2235e-02,\n","          1.9128e-03, -1.6625e-02,  3.9996e-03,  1.1191e-02, -3.9572e-02,\n","          8.5813e-03,  7.1226e-02,  7.7405e-02, -8.5258e-02,  6.7660e-02],\n","        [ 7.8416e-03,  1.2034e-02,  8.2138e-02, -3.5759e-02, -2.0921e-02,\n","          7.2613e-02, -7.2832e-04, -3.1847e-03,  3.6389e-02, -9.4404e-02,\n","          9.1278e-02,  9.2122e-02, -2.1923e-02,  8.1143e-02,  4.8857e-02,\n","         -2.4481e-02,  7.3477e-03,  3.0317e-02, -8.8428e-02,  4.7145e-02,\n","          2.5772e-02,  6.5719e-02,  1.9353e-02,  3.0849e-02, -9.5636e-02,\n","          8.7274e-02, -1.8570e-02,  2.7611e-02,  5.5938e-02,  7.1570e-02,\n","          9.8848e-02,  7.0887e-02, -9.6928e-02, -6.4049e-02, -4.0442e-02,\n","          1.0175e-02, -6.8428e-02, -6.2817e-02, -8.2198e-02, -1.7435e-02,\n","         -8.0656e-02, -7.7271e-02, -1.0531e-02, -7.3998e-02,  2.5480e-02,\n","          8.6857e-02, -3.2961e-02,  9.4465e-02, -5.0641e-02,  1.0545e-02,\n","         -3.4710e-02,  5.8775e-02,  8.7024e-02,  1.0644e-02, -4.8731e-03,\n","          6.0092e-02, -9.9729e-02, -5.0344e-03,  1.2238e-02,  9.4780e-02,\n","         -5.3323e-03, -5.2668e-02,  9.1019e-02, -7.5829e-02, -5.8037e-02,\n","          7.5552e-02,  2.1613e-02,  2.8930e-03,  2.0486e-02,  2.2625e-02,\n","         -7.9617e-02,  5.8514e-02,  9.8570e-02, -4.8506e-02,  8.5897e-02,\n","         -9.6173e-02, -9.1424e-02, -2.9320e-02, -8.3531e-02,  6.1074e-02,\n","         -8.1568e-02, -4.6341e-02, -6.3764e-02, -2.3561e-02, -6.6538e-02,\n","          5.4579e-02,  6.2349e-02, -1.8254e-02,  9.6255e-02,  8.4739e-02,\n","          1.1746e-02, -1.8906e-02, -8.3243e-02, -9.6534e-02,  7.4305e-02,\n","          4.1302e-02,  4.1058e-02, -1.0615e-02,  6.3407e-02, -2.0454e-03]],\n","       device='cuda:0', requires_grad=True)\n","clf.linear.bias\n","Parameter containing:\n","tensor([ 0.0163,  0.0140, -0.0578, -0.0828], device='cuda:0',\n","       requires_grad=True)\n"]}]},{"cell_type":"code","source":["torch.save(model, '/content/drive/MyDrive/Master_2023_sept/COGMEN-main/milion_model1.pt')"],"metadata":{"id":"9AJeE_NV07ux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/milion_model1.pt')"],"metadata":{"id":"hmVDihL3_uXS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluacija modela"],"metadata":{"id":"8FWkHnklSvtX"}},{"cell_type":"code","source":["#!python preprocess.py --dataset=\"iemocap_4\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voExDuaJSya8","executionInfo":{"status":"ok","timestamp":1699722029274,"user_tz":-60,"elapsed":39104,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"8dab154b-1357-4ee5-d015-3a86ad4db950"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading (…)7f4ef/.gitattributes: 100% 391/391 [00:00<00:00, 1.91MB/s]\n","Downloading (…)_Pooling/config.json: 100% 190/190 [00:00<00:00, 473kB/s]\n","Downloading (…)f279f7f4ef/README.md: 100% 3.74k/3.74k [00:00<00:00, 20.1MB/s]\n","Downloading (…)79f7f4ef/config.json: 100% 718/718 [00:00<00:00, 4.38MB/s]\n","Downloading (…)ce_transformers.json: 100% 122/122 [00:00<00:00, 733kB/s]\n","Downloading (…)279f7f4ef/merges.txt: 100% 456k/456k [00:00<00:00, 10.6MB/s]\n","Downloading pytorch_model.bin: 100% 329M/329M [00:01<00:00, 252MB/s]\n","Downloading (…)nce_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 255kB/s]\n","Downloading (…)cial_tokens_map.json: 100% 239/239 [00:00<00:00, 1.47MB/s]\n","Downloading (…)7f4ef/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 58.5MB/s]\n","Downloading (…)okenizer_config.json: 100% 1.35k/1.35k [00:00<00:00, 8.02MB/s]\n","Downloading (…)279f7f4ef/vocab.json: 100% 798k/798k [00:00<00:00, 11.1MB/s]\n","Downloading (…)9f7f4ef/modules.json: 100% 229/229 [00:00<00:00, 1.15MB/s]\n","Seed set\n","train: 100% 108/108 [00:13<00:00,  8.19it/s]\n","dev: 100% 12/12 [00:00<00:00, 25.59it/s]\n","test: 100% 31/31 [00:01<00:00, 25.68it/s]\n","11/11/2023 05:00:25 train vids:\n","11/11/2023 05:00:25 ['Ses01F_impro01', 'Ses01F_impro02', 'Ses01F_impro04', 'Ses01F_impro05', 'Ses01F_impro06', 'Ses01F_impro07', 'Ses01F_script01_1', 'Ses01F_script01_2', 'Ses01F_script01_3', 'Ses01F_script02_1', 'Ses01F_script03_1', 'Ses01F_script03_2', 'Ses01M_impro01', 'Ses01M_impro02', 'Ses01M_impro03', 'Ses01M_impro04', 'Ses01M_impro06', 'Ses01M_impro07', 'Ses01M_script01_1', 'Ses01M_script01_2', 'Ses01M_script01_3', 'Ses01M_script02_1', 'Ses01M_script02_2', 'Ses01M_script03_1', 'Ses01M_script03_2', 'Ses02F_impro01', 'Ses02F_impro02', 'Ses02F_impro03', 'Ses02F_impro04', 'Ses02F_impro06', 'Ses02F_impro07', 'Ses02F_impro08', 'Ses02F_script01_2', 'Ses02F_script02_1', 'Ses02F_script02_2', 'Ses02F_script03_1', 'Ses02F_script03_2', 'Ses02M_impro01', 'Ses02M_impro02', 'Ses02M_impro03', 'Ses02M_impro04', 'Ses02M_impro05', 'Ses02M_impro06', 'Ses02M_impro07', 'Ses02M_impro08', 'Ses02M_script01_1', 'Ses02M_script01_2', 'Ses02M_script01_3', 'Ses02M_script02_1', 'Ses02M_script03_1', 'Ses02M_script03_2', 'Ses03F_impro01', 'Ses03F_impro02', 'Ses03F_impro03', 'Ses03F_impro04', 'Ses03F_impro05', 'Ses03F_impro06', 'Ses03F_impro07', 'Ses03F_impro08', 'Ses03F_script01_1', 'Ses03F_script01_2', 'Ses03F_script01_3', 'Ses03F_script02_1', 'Ses03F_script02_2', 'Ses03F_script03_2', 'Ses03M_impro01', 'Ses03M_impro02', 'Ses03M_impro03', 'Ses03M_impro04', 'Ses03M_impro05a', 'Ses03M_impro06', 'Ses03M_impro07', 'Ses03M_impro08a', 'Ses03M_script01_1', 'Ses03M_script01_2', 'Ses03M_script01_3', 'Ses03M_script02_1', 'Ses03M_script02_2', 'Ses03M_script03_1', 'Ses03M_script03_2', 'Ses04F_impro01', 'Ses04F_impro02', 'Ses04F_impro03', 'Ses04F_impro04', 'Ses04F_impro05', 'Ses04F_impro06', 'Ses04F_impro08', 'Ses04F_script01_1', 'Ses04F_script01_2', 'Ses04F_script01_3', 'Ses04F_script02_1', 'Ses04F_script02_2', 'Ses04F_script03_1', 'Ses04F_script03_2', 'Ses04M_impro01', 'Ses04M_impro02', 'Ses04M_impro03', 'Ses04M_impro05', 'Ses04M_impro06', 'Ses04M_impro07', 'Ses04M_impro08', 'Ses04M_script01_1', 'Ses04M_script01_2', 'Ses04M_script01_3', 'Ses04M_script02_1', 'Ses04M_script02_2', 'Ses04M_script03_1', 'Ses04M_script03_2']\n","11/11/2023 05:00:25 dev vids:\n","11/11/2023 05:00:25 ['Ses01F_impro03', 'Ses01F_script02_2', 'Ses01M_impro05', 'Ses02F_impro05', 'Ses02F_script01_1', 'Ses02F_script01_3', 'Ses02M_script02_2', 'Ses03F_script03_1', 'Ses03M_impro05b', 'Ses03M_impro08b', 'Ses04F_impro07', 'Ses04M_impro04']\n","11/11/2023 05:00:25 test vids:\n","11/11/2023 05:00:25 ['Ses05F_impro01', 'Ses05F_impro02', 'Ses05F_impro03', 'Ses05F_impro04', 'Ses05F_impro05', 'Ses05F_impro06', 'Ses05F_impro07', 'Ses05F_impro08', 'Ses05F_script01_1', 'Ses05F_script01_2', 'Ses05F_script01_3', 'Ses05F_script02_1', 'Ses05F_script02_2', 'Ses05F_script03_1', 'Ses05F_script03_2', 'Ses05M_impro01', 'Ses05M_impro02', 'Ses05M_impro03', 'Ses05M_impro04', 'Ses05M_impro05', 'Ses05M_impro06', 'Ses05M_impro07', 'Ses05M_impro08', 'Ses05M_script01_1', 'Ses05M_script01_1b', 'Ses05M_script01_2', 'Ses05M_script01_3', 'Ses05M_script02_1', 'Ses05M_script02_2', 'Ses05M_script03_1', 'Ses05M_script03_2']\n","11/11/2023 05:00:26 number of train samples: 108\n","11/11/2023 05:00:26 number of dev samples: 12\n","11/11/2023 05:00:26 number of test samples: 31\n"]}]},{"cell_type":"code","source":["#!python train.py --dataset=\"iemocap_4\" --modalities=\"atv\" --from_begin --epochs=55"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RHTs8BOVL-6","executionInfo":{"status":"ok","timestamp":1699722337929,"user_tz":-60,"elapsed":250753,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"67bc5a67-51f6-42e9-a79b-66a856f4d5b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-11 17:01:36.985536: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-11 17:01:36.985599: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-11 17:01:36.985643: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-11 17:01:38.829814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Seed set\n","11/11/2023 05:01:40 Loaded data.\n","SeqContext-> USING Transformer\n","args.drop_rate: 0.5\n","bn\n","<generator object Module.parameters at 0x7c94d9315b60>\n","gnn_nheads\n","1\n","Using Scheduler\n","11/11/2023 05:01:47 Start training...\n","Help on Coach in module cogmen.Coach object:\n","\n","class C\bCo\boa\bac\bch\bh(builtins.object)\n"," |  Coach(trainset, devset, testset, model, opt, sched, args)\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  _\b__\b_i\bin\bni\bit\bt_\b__\b_(self, trainset, devset, testset, model, opt, sched, args)\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  e\bev\bva\bal\blu\bua\bat\bte\be(self, test=False)\n"," |  \n"," |  l\blo\boa\bad\bd_\b_c\bck\bkp\bpt\bt(self, ckpt)\n"," |  \n"," |  t\btr\bra\bai\bin\bn(self)\n"," |  \n"," |  t\btr\bra\bai\bin\bn_\b_e\bep\bpo\boc\bch\bh(self, epoch)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  _\b__\b_d\bdi\bic\bct\bt_\b__\b_\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  _\b__\b_w\bwe\bea\bak\bkr\bre\bef\bf_\b__\b_\n"," |      list of weak references to the object (if defined)\n","\n","None\n","<class 'cogmen.Coach.Coach'>\n","train epoch 1: 100% 4/4 [00:02<00:00,  1.53it/s]\n","11/11/2023 05:01:50 \n","11/11/2023 05:01:50 [Epoch 1] [Loss: 5.485973] [Time: 2.613434]\n","dev: 100% 1/1 [00:00<00:00,  2.24it/s]\n","test: 100% 1/1 [00:00<00:00,  1.01it/s]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","         hap     0.0000    0.0000    0.0000       144\n","         sad     0.4615    0.7592    0.5741       245\n","         neu     0.4944    0.3438    0.4055       384\n","         ang     0.4579    0.7353    0.5643       170\n","\n","    accuracy                         0.4698       943\n","   macro avg     0.3534    0.4596    0.3860       943\n","weighted avg     0.4038    0.4698    0.4160       943\n","\n","11/11/2023 05:01:51 [Dev set] [f1 0.4467]\n","11/11/2023 05:01:54 Save the best model.\n","11/11/2023 05:01:54 [Test set] [f1 0.4160]\n","train epoch 2: 100% 4/4 [00:02<00:00,  1.55it/s]\n","11/11/2023 05:01:56 \n","11/11/2023 05:01:56 [Epoch 2] [Loss: 5.065207] [Time: 2.587517]\n","dev: 100% 1/1 [00:00<00:00,  1.67it/s]\n","test: 100% 1/1 [00:01<00:00,  1.52s/it]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","         hap     0.0000    0.0000    0.0000       144\n","         sad     0.5225    0.9020    0.6617       245\n","         neu     0.6893    0.5026    0.5813       384\n","         ang     0.5833    0.8235    0.6829       170\n","\n","    accuracy                         0.5875       943\n","   macro avg     0.4488    0.5570    0.4815       943\n","weighted avg     0.5216    0.5875    0.5317       943\n","\n","11/11/2023 05:01:58 [Dev set] [f1 0.4784]\n","11/11/2023 05:01:59 Save the best model.\n","11/11/2023 05:01:59 [Test set] [f1 0.5317]\n","train epoch 3: 100% 4/4 [00:02<00:00,  1.48it/s]\n","11/11/2023 05:02:02 \n","11/11/2023 05:02:02 [Epoch 3] [Loss: 4.722517] [Time: 2.698522]\n","dev: 100% 1/1 [00:00<00:00,  2.33it/s]\n","test: 100% 1/1 [00:00<00:00,  1.01it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8182    0.1250    0.2169       144\n","         sad     0.5882    0.8980    0.7108       245\n","         neu     0.7165    0.6120    0.6601       384\n","         ang     0.6667    0.8588    0.7506       170\n","\n","    accuracy                         0.6564       943\n","   macro avg     0.6974    0.6234    0.5846       943\n","weighted avg     0.6897    0.6564    0.6219       943\n","\n","11/11/2023 05:02:03 [Dev set] [f1 0.5342]\n","11/11/2023 05:02:03 Save the best model.\n","11/11/2023 05:02:03 [Test set] [f1 0.6219]\n","train epoch 4: 100% 4/4 [00:01<00:00,  2.08it/s]\n","11/11/2023 05:02:05 \n","11/11/2023 05:02:05 [Epoch 4] [Loss: 4.512682] [Time: 1.919396]\n","dev: 100% 1/1 [00:00<00:00,  2.49it/s]\n","test: 100% 1/1 [00:00<00:00,  1.06it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8750    0.2431    0.3804       144\n","         sad     0.6588    0.9061    0.7629       245\n","         neu     0.7713    0.6849    0.7255       384\n","         ang     0.6667    0.8824    0.7595       170\n","\n","    accuracy                         0.7105       943\n","   macro avg     0.7429    0.6791    0.6571       943\n","weighted avg     0.7390    0.7105    0.6887       943\n","\n","11/11/2023 05:02:07 [Dev set] [f1 0.5832]\n","11/11/2023 05:02:08 Save the best model.\n","11/11/2023 05:02:08 [Test set] [f1 0.6887]\n","train epoch 5: 100% 4/4 [00:02<00:00,  1.98it/s]\n","11/11/2023 05:02:10 \n","11/11/2023 05:02:10 [Epoch 5] [Loss: 4.334488] [Time: 2.017056]\n","dev: 100% 1/1 [00:00<00:00,  1.62it/s]\n","test: 100% 1/1 [00:01<00:00,  1.35s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.9057    0.3333    0.4873       144\n","         sad     0.6916    0.9061    0.7845       245\n","         neu     0.8024    0.7083    0.7524       384\n","         ang     0.6565    0.8882    0.7550       170\n","\n","    accuracy                         0.7349       943\n","   macro avg     0.7640    0.7090    0.6948       943\n","weighted avg     0.7631    0.7349    0.7207       943\n","\n","11/11/2023 05:02:12 [Dev set] [f1 0.6025]\n","11/11/2023 05:02:12 Save the best model.\n","11/11/2023 05:02:12 [Test set] [f1 0.7207]\n","train epoch 6: 100% 4/4 [00:02<00:00,  1.55it/s]\n","11/11/2023 05:02:14 \n","11/11/2023 05:02:14 [Epoch 6] [Loss: 4.251083] [Time: 2.574436]\n","dev: 100% 1/1 [00:00<00:00,  1.79it/s]\n","test: 100% 1/1 [00:01<00:00,  1.47s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.9231    0.4167    0.5742       144\n","         sad     0.6935    0.8776    0.7748       245\n","         neu     0.8302    0.7005    0.7599       384\n","         ang     0.6230    0.8941    0.7343       170\n","\n","    accuracy                         0.7381       943\n","   macro avg     0.7675    0.7222    0.7108       943\n","weighted avg     0.7715    0.7381    0.7308       943\n","\n","11/11/2023 05:02:17 [Dev set] [f1 0.6481]\n","11/11/2023 05:02:17 Save the best model.\n","11/11/2023 05:02:17 [Test set] [f1 0.7308]\n","train epoch 7: 100% 4/4 [00:02<00:00,  1.71it/s]\n","11/11/2023 05:02:19 \n","11/11/2023 05:02:19 [Epoch 7] [Loss: 4.094325] [Time: 2.338660]\n","dev: 100% 1/1 [00:00<00:00,  2.01it/s]\n","test: 100% 1/1 [00:01<00:00,  1.04s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8657    0.4028    0.5498       144\n","         sad     0.6518    0.8939    0.7539       245\n","         neu     0.8656    0.6875    0.7663       384\n","         ang     0.6426    0.8882    0.7457       170\n","\n","    accuracy                         0.7338       943\n","   macro avg     0.7564    0.7181    0.7039       943\n","weighted avg     0.7698    0.7338    0.7263       943\n","\n","11/11/2023 05:02:21 [Dev set] [f1 0.7023]\n","11/11/2023 05:02:21 Save the best model.\n","11/11/2023 05:02:21 [Test set] [f1 0.7263]\n","train epoch 8: 100% 4/4 [00:01<00:00,  2.03it/s]\n","11/11/2023 05:02:23 \n","11/11/2023 05:02:23 [Epoch 8] [Loss: 3.915380] [Time: 1.971892]\n","dev: 100% 1/1 [00:00<00:00,  2.34it/s]\n","test: 100% 1/1 [00:00<00:00,  1.06it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8750    0.5347    0.6638       144\n","         sad     0.6980    0.8490    0.7661       245\n","         neu     0.8354    0.7135    0.7697       384\n","         ang     0.6550    0.8824    0.7519       170\n","\n","    accuracy                         0.7519       943\n","   macro avg     0.7658    0.7449    0.7379       943\n","weighted avg     0.7732    0.7519    0.7494       943\n","\n","11/11/2023 05:02:25 [Dev set] [f1 0.7061]\n","11/11/2023 05:02:25 Save the best model.\n","11/11/2023 05:02:25 [Test set] [f1 0.7494]\n","train epoch 9: 100% 4/4 [00:02<00:00,  1.79it/s]\n","11/11/2023 05:02:27 \n","11/11/2023 05:02:27 [Epoch 9] [Loss: 3.958485] [Time: 2.236028]\n","dev: 100% 1/1 [00:00<00:00,  2.39it/s]\n","test: 100% 1/1 [00:01<00:00,  1.08s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8452    0.4931    0.6228       144\n","         sad     0.6806    0.8612    0.7604       245\n","         neu     0.8318    0.7214    0.7727       384\n","         ang     0.6898    0.8765    0.7720       170\n","\n","    accuracy                         0.7508       943\n","   macro avg     0.7619    0.7380    0.7320       943\n","weighted avg     0.7690    0.7508    0.7465       943\n","\n","11/11/2023 05:02:29 [Dev set] [f1 0.7109]\n","11/11/2023 05:02:29 Save the best model.\n","11/11/2023 05:02:29 [Test set] [f1 0.7465]\n","train epoch 10: 100% 4/4 [00:02<00:00,  1.56it/s]\n","11/11/2023 05:02:31 \n","11/11/2023 05:02:31 [Epoch 10] [Loss: 3.638738] [Time: 2.569547]\n","dev: 100% 1/1 [00:00<00:00,  1.76it/s]\n","test: 100% 1/1 [00:01<00:00,  1.36s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8837    0.5278    0.6609       144\n","         sad     0.6964    0.8612    0.7701       245\n","         neu     0.8338    0.7448    0.7868       384\n","         ang     0.7014    0.8706    0.7769       170\n","\n","    accuracy                         0.7646       943\n","   macro avg     0.7788    0.7511    0.7487       943\n","weighted avg     0.7819    0.7646    0.7614       943\n","\n","11/11/2023 05:02:33 [Dev set] [f1 0.7259]\n","11/11/2023 05:02:34 Save the best model.\n","11/11/2023 05:02:34 [Test set] [f1 0.7614]\n","train epoch 11: 100% 4/4 [00:02<00:00,  1.44it/s]\n","11/11/2023 05:02:37 \n","11/11/2023 05:02:37 [Epoch 11] [Loss: 3.575553] [Time: 2.786900]\n","dev: 100% 1/1 [00:00<00:00,  2.06it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8681    0.5486    0.6723       144\n","         sad     0.7074    0.8980    0.7914       245\n","         neu     0.8503    0.7396    0.7911       384\n","         ang     0.7198    0.8765    0.7905       170\n","\n","    accuracy                         0.7762       943\n","   macro avg     0.7864    0.7657    0.7613       943\n","weighted avg     0.7924    0.7762    0.7729       943\n","\n","11/11/2023 05:02:38 [Dev set] [f1 0.7591]\n","11/11/2023 05:02:38 Save the best model.\n","11/11/2023 05:02:38 [Test set] [f1 0.7729]\n","train epoch 12: 100% 4/4 [00:01<00:00,  2.04it/s]\n","11/11/2023 05:02:40 \n","11/11/2023 05:02:40 [Epoch 12] [Loss: 3.470903] [Time: 1.965569]\n","dev: 100% 1/1 [00:00<00:00,  2.46it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8587    0.5486    0.6695       144\n","         sad     0.7112    0.9347    0.8078       245\n","         neu     0.8797    0.7240    0.7943       384\n","         ang     0.7136    0.8941    0.7937       170\n","\n","    accuracy                         0.7826       943\n","   macro avg     0.7908    0.7753    0.7663       943\n","weighted avg     0.8028    0.7826    0.7786       943\n","\n","11/11/2023 05:02:42 [Dev set] [f1 0.7422]\n","11/11/2023 05:02:42 [Test set] [f1 0.7786]\n","train epoch 13: 100% 4/4 [00:01<00:00,  2.12it/s]\n","11/11/2023 05:02:44 \n","11/11/2023 05:02:44 [Epoch 13] [Loss: 3.349003] [Time: 1.885692]\n","dev: 100% 1/1 [00:00<00:00,  2.41it/s]\n","test: 100% 1/1 [00:00<00:00,  1.05it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8602    0.5556    0.6751       144\n","         sad     0.7166    0.8980    0.7971       245\n","         neu     0.8567    0.7318    0.7893       384\n","         ang     0.7023    0.8882    0.7844       170\n","\n","    accuracy                         0.7762       943\n","   macro avg     0.7840    0.7684    0.7615       943\n","weighted avg     0.7930    0.7762    0.7730       943\n","\n","11/11/2023 05:02:45 [Dev set] [f1 0.7667]\n","11/11/2023 05:02:45 Save the best model.\n","11/11/2023 05:02:45 [Test set] [f1 0.7730]\n","train epoch 14: 100% 4/4 [00:02<00:00,  1.62it/s]\n","11/11/2023 05:02:48 \n","11/11/2023 05:02:48 [Epoch 14] [Loss: 3.342704] [Time: 2.473897]\n","dev: 100% 1/1 [00:00<00:00,  1.54it/s]\n","test: 100% 1/1 [00:01<00:00,  1.43s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8017    0.6736    0.7321       144\n","         sad     0.7517    0.8898    0.8150       245\n","         neu     0.8638    0.7266    0.7893       384\n","         ang     0.7273    0.8941    0.8021       170\n","\n","    accuracy                         0.7911       943\n","   macro avg     0.7861    0.7960    0.7846       943\n","weighted avg     0.8006    0.7911    0.7895       943\n","\n","11/11/2023 05:02:50 [Dev set] [f1 0.7874]\n","11/11/2023 05:02:50 Save the best model.\n","11/11/2023 05:02:50 [Test set] [f1 0.7895]\n","train epoch 15: 100% 4/4 [00:02<00:00,  1.57it/s]\n","11/11/2023 05:02:53 \n","11/11/2023 05:02:53 [Epoch 15] [Loss: 3.071852] [Time: 2.547486]\n","dev: 100% 1/1 [00:00<00:00,  1.57it/s]\n","test: 100% 1/1 [00:01<00:00,  1.44s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8241    0.6181    0.7063       144\n","         sad     0.7244    0.9224    0.8115       245\n","         neu     0.8840    0.7344    0.8023       384\n","         ang     0.7549    0.9059    0.8235       170\n","\n","    accuracy                         0.7964       943\n","   macro avg     0.7968    0.7952    0.7859       943\n","weighted avg     0.8101    0.7964    0.7939       943\n","\n","11/11/2023 05:02:55 [Dev set] [f1 0.7826]\n","11/11/2023 05:02:55 [Test set] [f1 0.7939]\n","train epoch 16: 100% 4/4 [00:02<00:00,  1.85it/s]\n","11/11/2023 05:02:57 \n","11/11/2023 05:02:57 [Epoch 16] [Loss: 3.003471] [Time: 2.164175]\n","dev: 100% 1/1 [00:00<00:00,  2.31it/s]\n","test: 100% 1/1 [00:01<00:00,  1.01s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8641    0.6181    0.7206       144\n","         sad     0.7200    0.9551    0.8211       245\n","         neu     0.9082    0.7214    0.8041       384\n","         ang     0.7429    0.9176    0.8211       170\n","\n","    accuracy                         0.8017       943\n","   macro avg     0.8088    0.8030    0.7917       943\n","weighted avg     0.8228    0.8017    0.7988       943\n","\n","11/11/2023 05:02:59 [Dev set] [f1 0.7761]\n","11/11/2023 05:02:59 [Test set] [f1 0.7988]\n","train epoch 17: 100% 4/4 [00:02<00:00,  1.76it/s]\n","11/11/2023 05:03:01 \n","11/11/2023 05:03:01 [Epoch 17] [Loss: 2.892804] [Time: 2.267382]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7761    0.7222    0.7482       144\n","         sad     0.7608    0.9347    0.8388       245\n","         neu     0.8974    0.7057    0.7901       384\n","         ang     0.7476    0.9059    0.8191       170\n","\n","    accuracy                         0.8038       943\n","   macro avg     0.7955    0.8171    0.7991       943\n","weighted avg     0.8164    0.8038    0.8016       943\n","\n","11/11/2023 05:03:02 [Dev set] [f1 0.7960]\n","11/11/2023 05:03:02 Save the best model.\n","11/11/2023 05:03:02 [Test set] [f1 0.8016]\n","train epoch 18: 100% 4/4 [00:01<00:00,  2.01it/s]\n","11/11/2023 05:03:04 \n","11/11/2023 05:03:04 [Epoch 18] [Loss: 2.847181] [Time: 1.991513]\n","dev: 100% 1/1 [00:00<00:00,  2.29it/s]\n","test: 100% 1/1 [00:01<00:00,  1.11s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8374    0.7153    0.7715       144\n","         sad     0.8087    0.9143    0.8582       245\n","         neu     0.8866    0.7943    0.8379       384\n","         ang     0.7990    0.9353    0.8618       170\n","\n","    accuracy                         0.8388       943\n","   macro avg     0.8329    0.8398    0.8324       943\n","weighted avg     0.8431    0.8388    0.8374       943\n","\n","11/11/2023 05:03:06 [Dev set] [f1 0.7601]\n","11/11/2023 05:03:06 [Test set] [f1 0.8374]\n","train epoch 19: 100% 4/4 [00:02<00:00,  1.60it/s]\n","11/11/2023 05:03:09 \n","11/11/2023 05:03:09 [Epoch 19] [Loss: 2.713134] [Time: 2.496303]\n","dev: 100% 1/1 [00:00<00:00,  1.84it/s]\n","test: 100% 1/1 [00:01<00:00,  1.28s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7482    0.7222    0.7350       144\n","         sad     0.7897    0.9347    0.8561       245\n","         neu     0.9018    0.6693    0.7683       384\n","         ang     0.7031    0.9471    0.8070       170\n","\n","    accuracy                         0.7964       943\n","   macro avg     0.7857    0.8183    0.7916       943\n","weighted avg     0.8134    0.7964    0.7930       943\n","\n","11/11/2023 05:03:10 [Dev set] [f1 0.7650]\n","11/11/2023 05:03:10 [Test set] [f1 0.7930]\n","train epoch 20: 100% 4/4 [00:03<00:00,  1.16it/s]\n","11/11/2023 05:03:14 \n","11/11/2023 05:03:14 [Epoch 20] [Loss: 2.699278] [Time: 3.446706]\n","dev: 100% 1/1 [00:00<00:00,  1.65it/s]\n","test: 100% 1/1 [00:01<00:00,  1.00s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7778    0.7292    0.7527       144\n","         sad     0.7902    0.9224    0.8512       245\n","         neu     0.8879    0.7630    0.8207       384\n","         ang     0.8073    0.9118    0.8564       170\n","\n","    accuracy                         0.8261       943\n","   macro avg     0.8158    0.8316    0.8202       943\n","weighted avg     0.8312    0.8261    0.8247       943\n","\n","11/11/2023 05:03:15 [Dev set] [f1 0.7778]\n","11/11/2023 05:03:15 [Test set] [f1 0.8247]\n","train epoch 21: 100% 4/4 [00:01<00:00,  2.10it/s]\n","11/11/2023 05:03:17 \n","11/11/2023 05:03:17 [Epoch 21] [Loss: 2.590569] [Time: 1.904749]\n","dev: 100% 1/1 [00:00<00:00,  2.44it/s]\n","test: 100% 1/1 [00:00<00:00,  1.07it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8462    0.6875    0.7586       144\n","         sad     0.8271    0.8980    0.8611       245\n","         neu     0.8743    0.7604    0.8134       384\n","         ang     0.7168    0.9529    0.8182       170\n","\n","    accuracy                         0.8197       943\n","   macro avg     0.8161    0.8247    0.8128       943\n","weighted avg     0.8293    0.8197    0.8183       943\n","\n","11/11/2023 05:03:19 [Dev set] [f1 0.7347]\n","11/11/2023 05:03:19 [Test set] [f1 0.8183]\n","train epoch 22: 100% 4/4 [00:01<00:00,  2.13it/s]\n","11/11/2023 05:03:21 \n","11/11/2023 05:03:21 [Epoch 22] [Loss: 2.378600] [Time: 1.878000]\n","dev: 100% 1/1 [00:00<00:00,  2.52it/s]\n","test: 100% 1/1 [00:00<00:00,  1.07it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7315    0.7569    0.7440       144\n","         sad     0.8021    0.9429    0.8668       245\n","         neu     0.9132    0.6849    0.7827       384\n","         ang     0.7339    0.9412    0.8247       170\n","\n","    accuracy                         0.8091       943\n","   macro avg     0.7952    0.8315    0.8046       943\n","weighted avg     0.8243    0.8091    0.8062       943\n","\n","11/11/2023 05:03:22 [Dev set] [f1 0.7954]\n","11/11/2023 05:03:22 [Test set] [f1 0.8062]\n","train epoch 23: 100% 4/4 [00:01<00:00,  2.10it/s]\n","11/11/2023 05:03:24 \n","11/11/2023 05:03:24 [Epoch 23] [Loss: 2.216722] [Time: 1.905062]\n","dev: 100% 1/1 [00:00<00:00,  2.43it/s]\n","test: 100% 1/1 [00:01<00:00,  1.26s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7639    0.7639    0.7639       144\n","         sad     0.8675    0.8816    0.8745       245\n","         neu     0.8595    0.8125    0.8353       384\n","         ang     0.8342    0.9176    0.8739       170\n","\n","    accuracy                         0.8420       943\n","   macro avg     0.8313    0.8439    0.8369       943\n","weighted avg     0.8424    0.8420    0.8416       943\n","\n","11/11/2023 05:03:26 [Dev set] [f1 0.7754]\n","11/11/2023 05:03:26 [Test set] [f1 0.8416]\n","train epoch 24: 100% 4/4 [00:02<00:00,  1.61it/s]\n","11/11/2023 05:03:28 \n","11/11/2023 05:03:28 [Epoch 24] [Loss: 2.216195] [Time: 2.487823]\n","dev: 100% 1/1 [00:00<00:00,  1.70it/s]\n","test: 100% 1/1 [00:01<00:00,  1.29s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7823    0.6736    0.7239       144\n","         sad     0.7645    0.9673    0.8541       245\n","         neu     0.9234    0.6276    0.7473       384\n","         ang     0.6411    0.9353    0.7608       170\n","\n","    accuracy                         0.7784       943\n","   macro avg     0.7778    0.8010    0.7715       943\n","weighted avg     0.8097    0.7784    0.7739       943\n","\n","11/11/2023 05:03:30 [Dev set] [f1 0.7233]\n","11/11/2023 05:03:30 [Test set] [f1 0.7739]\n","train epoch 25: 100% 4/4 [00:02<00:00,  1.50it/s]\n","11/11/2023 05:03:33 \n","11/11/2023 05:03:33 [Epoch 25] [Loss: 2.065095] [Time: 2.672955]\n","dev: 100% 1/1 [00:00<00:00,  2.38it/s]\n","test: 100% 1/1 [00:01<00:00,  1.24s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7616    0.7986    0.7797       144\n","         sad     0.8653    0.8653    0.8653       245\n","         neu     0.8697    0.7995    0.8331       384\n","         ang     0.7990    0.9118    0.8516       170\n","\n","    accuracy                         0.8367       943\n","   macro avg     0.8239    0.8438    0.8324       943\n","weighted avg     0.8393    0.8367    0.8367       943\n","\n","11/11/2023 05:03:34 [Dev set] [f1 0.8104]\n","11/11/2023 05:03:35 Save the best model.\n","11/11/2023 05:03:35 [Test set] [f1 0.8367]\n","train epoch 26: 100% 4/4 [00:01<00:00,  2.06it/s]\n","11/11/2023 05:03:36 \n","11/11/2023 05:03:36 [Epoch 26] [Loss: 2.079982] [Time: 1.940005]\n","dev: 100% 1/1 [00:00<00:00,  2.39it/s]\n","test: 100% 1/1 [00:01<00:00,  1.00s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7329    0.8194    0.7738       144\n","         sad     0.8309    0.9224    0.8743       245\n","         neu     0.9194    0.6536    0.7641       384\n","         ang     0.6751    0.9412    0.7862       170\n","\n","    accuracy                         0.8006       943\n","   macro avg     0.7896    0.8342    0.7996       943\n","weighted avg     0.8239    0.8006    0.7982       943\n","\n","11/11/2023 05:03:38 [Dev set] [f1 0.7840]\n","11/11/2023 05:03:38 [Test set] [f1 0.7982]\n","train epoch 27: 100% 4/4 [00:01<00:00,  2.08it/s]\n","11/11/2023 05:03:40 \n","11/11/2023 05:03:40 [Epoch 27] [Loss: 1.879983] [Time: 1.921678]\n","dev: 100% 1/1 [00:00<00:00,  2.27it/s]\n","test: 100% 1/1 [00:00<00:00,  1.05it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7874    0.6944    0.7380       144\n","         sad     0.8543    0.8857    0.8697       245\n","         neu     0.8366    0.7734    0.8038       384\n","         ang     0.7633    0.9294    0.8382       170\n","\n","    accuracy                         0.8187       943\n","   macro avg     0.8104    0.8208    0.8124       943\n","weighted avg     0.8205    0.8187    0.8171       943\n","\n","11/11/2023 05:03:41 [Dev set] [f1 0.7444]\n","11/11/2023 05:03:41 [Test set] [f1 0.8171]\n","train epoch 28: 100% 4/4 [00:02<00:00,  1.82it/s]\n","11/11/2023 05:03:43 \n","11/11/2023 05:03:43 [Epoch 28] [Loss: 1.814943] [Time: 2.194109]\n","dev: 100% 1/1 [00:00<00:00,  1.80it/s]\n","test: 100% 1/1 [00:01<00:00,  1.60s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7687    0.7153    0.7410       144\n","         sad     0.8225    0.9265    0.8714       245\n","         neu     0.8635    0.7083    0.7783       384\n","         ang     0.7202    0.9235    0.8093       170\n","\n","    accuracy                         0.8049       943\n","   macro avg     0.7937    0.8184    0.8000       943\n","weighted avg     0.8125    0.8049    0.8024       943\n","\n","11/11/2023 05:03:46 [Dev set] [f1 0.7601]\n","11/11/2023 05:03:46 [Test set] [f1 0.8024]\n","train epoch 29: 100% 4/4 [00:02<00:00,  1.57it/s]\n","11/11/2023 05:03:48 \n","11/11/2023 05:03:48 [Epoch 29] [Loss: 1.797056] [Time: 2.547380]\n","dev: 100% 1/1 [00:00<00:00,  1.73it/s]\n","test: 100% 1/1 [00:01<00:00,  1.48s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7517    0.7778    0.7645       144\n","         sad     0.8795    0.8939    0.8866       245\n","         neu     0.8559    0.7578    0.8039       384\n","         ang     0.7659    0.9235    0.8373       170\n","\n","    accuracy                         0.8261       943\n","   macro avg     0.8132    0.8382    0.8231       943\n","weighted avg     0.8299    0.8261    0.8254       943\n","\n","11/11/2023 05:03:50 [Dev set] [f1 0.7893]\n","11/11/2023 05:03:50 [Test set] [f1 0.8254]\n","train epoch 30: 100% 4/4 [00:02<00:00,  1.85it/s]\n","11/11/2023 05:03:52 \n","11/11/2023 05:03:52 [Epoch 30] [Loss: 1.738944] [Time: 2.161309]\n","dev: 100% 1/1 [00:00<00:00,  2.44it/s]\n","test: 100% 1/1 [00:00<00:00,  1.04it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7740    0.7847    0.7793       144\n","         sad     0.8496    0.9224    0.8845       245\n","         neu     0.8814    0.7161    0.7902       384\n","         ang     0.7260    0.9353    0.8175       170\n","\n","    accuracy                         0.8197       943\n","   macro avg     0.8078    0.8397    0.8179       943\n","weighted avg     0.8287    0.8197    0.8180       943\n","\n","11/11/2023 05:03:54 [Dev set] [f1 0.8001]\n","11/11/2023 05:03:54 [Test set] [f1 0.8180]\n","train epoch 31: 100% 4/4 [00:01<00:00,  2.03it/s]\n","11/11/2023 05:03:56 \n","11/11/2023 05:03:56 [Epoch 31] [Loss: 1.669185] [Time: 1.972583]\n","dev: 100% 1/1 [00:00<00:00,  2.33it/s]\n","test: 100% 1/1 [00:01<00:00,  1.01s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8130    0.6944    0.7491       144\n","         sad     0.8397    0.8980    0.8679       245\n","         neu     0.8329    0.7526    0.7907       384\n","         ang     0.7393    0.9176    0.8189       170\n","\n","    accuracy                         0.8112       943\n","   macro avg     0.8062    0.8157    0.8066       943\n","weighted avg     0.8147    0.8112    0.8095       943\n","\n","11/11/2023 05:03:57 [Dev set] [f1 0.7857]\n","11/11/2023 05:03:57 [Test set] [f1 0.8095]\n","train epoch 32: 100% 4/4 [00:02<00:00,  1.79it/s]\n","11/11/2023 05:03:59 \n","11/11/2023 05:03:59 [Epoch 32] [Loss: 1.447028] [Time: 2.229970]\n","dev: 100% 1/1 [00:00<00:00,  2.39it/s]\n","test: 100% 1/1 [00:00<00:00,  1.04it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7640    0.8542    0.8066       144\n","         sad     0.8750    0.9143    0.8942       245\n","         neu     0.8848    0.7604    0.8179       384\n","         ang     0.7857    0.9059    0.8415       170\n","\n","    accuracy                         0.8409       943\n","   macro avg     0.8274    0.8587    0.8401       943\n","weighted avg     0.8460    0.8409    0.8403       943\n","\n","11/11/2023 05:04:01 [Dev set] [f1 0.8253]\n","11/11/2023 05:04:01 Save the best model.\n","11/11/2023 05:04:01 [Test set] [f1 0.8403]\n","train epoch 33: 100% 4/4 [00:02<00:00,  1.57it/s]\n","11/11/2023 05:04:04 \n","11/11/2023 05:04:04 [Epoch 33] [Loss: 1.437038] [Time: 2.554428]\n","dev: 100% 1/1 [00:00<00:00,  1.79it/s]\n","test: 100% 1/1 [00:01<00:00,  1.30s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7970    0.7361    0.7653       144\n","         sad     0.8871    0.8980    0.8925       245\n","         neu     0.8311    0.8073    0.8190       384\n","         ang     0.8095    0.9000    0.8524       170\n","\n","    accuracy                         0.8367       943\n","   macro avg     0.8312    0.8353    0.8323       943\n","weighted avg     0.8366    0.8367    0.8359       943\n","\n","11/11/2023 05:04:06 [Dev set] [f1 0.8171]\n","11/11/2023 05:04:06 [Test set] [f1 0.8359]\n","train epoch 34: 100% 4/4 [00:02<00:00,  1.53it/s]\n","11/11/2023 05:04:08 \n","11/11/2023 05:04:08 [Epoch 34] [Loss: 1.376333] [Time: 2.611815]\n","dev: 100% 1/1 [00:00<00:00,  1.58it/s]\n","test: 100% 1/1 [00:01<00:00,  1.15s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7169    0.8264    0.7677       144\n","         sad     0.8014    0.9388    0.8647       245\n","         neu     0.8980    0.5964    0.7167       384\n","         ang     0.6681    0.9235    0.7753       170\n","\n","    accuracy                         0.7794       943\n","   macro avg     0.7711    0.8213    0.7811       943\n","weighted avg     0.8038    0.7794    0.7735       943\n","\n","11/11/2023 05:04:10 [Dev set] [f1 0.7533]\n","11/11/2023 05:04:10 [Test set] [f1 0.7735]\n","train epoch 35: 100% 4/4 [00:02<00:00,  1.86it/s]\n","11/11/2023 05:04:12 \n","11/11/2023 05:04:12 [Epoch 35] [Loss: 1.555119] [Time: 2.153407]\n","dev: 100% 1/1 [00:00<00:00,  1.81it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7757    0.5764    0.6614       144\n","         sad     0.9137    0.7347    0.8145       245\n","         neu     0.7489    0.8542    0.7981       384\n","         ang     0.7761    0.9176    0.8410       170\n","\n","    accuracy                         0.7922       943\n","   macro avg     0.8036    0.7707    0.7787       943\n","weighted avg     0.8007    0.7922    0.7892       943\n","\n","11/11/2023 05:04:14 [Dev set] [f1 0.7923]\n","11/11/2023 05:04:14 [Test set] [f1 0.7892]\n","train epoch 36: 100% 4/4 [00:01<00:00,  2.11it/s]\n","11/11/2023 05:04:16 \n","11/11/2023 05:04:16 [Epoch 36] [Loss: 1.296164] [Time: 1.899163]\n","dev: 100% 1/1 [00:00<00:00,  2.37it/s]\n","test: 100% 1/1 [00:00<00:00,  1.06it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7326    0.8750    0.7975       144\n","         sad     0.8121    0.9347    0.8691       245\n","         neu     0.9344    0.5938    0.7261       384\n","         ang     0.6571    0.9471    0.7759       170\n","\n","    accuracy                         0.7890       943\n","   macro avg     0.7840    0.8376    0.7921       943\n","weighted avg     0.8218    0.7890    0.7831       943\n","\n","11/11/2023 05:04:17 [Dev set] [f1 0.7829]\n","11/11/2023 05:04:17 [Test set] [f1 0.7831]\n","train epoch 37: 100% 4/4 [00:01<00:00,  2.10it/s]\n","11/11/2023 05:04:19 \n","11/11/2023 05:04:19 [Epoch 37] [Loss: 1.337798] [Time: 1.901437]\n","dev: 100% 1/1 [00:00<00:00,  2.51it/s]\n","test: 100% 1/1 [00:01<00:00,  1.21s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7500    0.8750    0.8077       144\n","         sad     0.8513    0.9347    0.8911       245\n","         neu     0.9032    0.7292    0.8069       384\n","         ang     0.7857    0.9059    0.8415       170\n","\n","    accuracy                         0.8367       943\n","   macro avg     0.8226    0.8612    0.8368       943\n","weighted avg     0.8452    0.8367    0.8351       943\n","\n","11/11/2023 05:04:20 [Dev set] [f1 0.8185]\n","11/11/2023 05:04:20 [Test set] [f1 0.8351]\n","train epoch 38: 100% 4/4 [00:02<00:00,  1.38it/s]\n","11/11/2023 05:04:23 \n","11/11/2023 05:04:23 [Epoch 38] [Loss: 1.135769] [Time: 2.902704]\n","dev: 100% 1/1 [00:00<00:00,  1.75it/s]\n","test: 100% 1/1 [00:01<00:00,  1.31s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8505    0.6319    0.7251       144\n","         sad     0.9091    0.8163    0.8602       245\n","         neu     0.7703    0.8385    0.8030       384\n","         ang     0.7778    0.9059    0.8370       170\n","\n","    accuracy                         0.8134       943\n","   macro avg     0.8269    0.7982    0.8063       943\n","weighted avg     0.8200    0.8134    0.8121       943\n","\n","11/11/2023 05:04:25 [Dev set] [f1 0.8126]\n","11/11/2023 05:04:25 [Test set] [f1 0.8121]\n","train epoch 39: 100% 4/4 [00:02<00:00,  1.49it/s]\n","11/11/2023 05:04:28 \n","11/11/2023 05:04:28 [Epoch 39] [Loss: 1.107769] [Time: 2.686740]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7415    0.7569    0.7491       144\n","         sad     0.8527    0.8980    0.8748       245\n","         neu     0.8374    0.7109    0.7690       384\n","         ang     0.7358    0.9176    0.8168       170\n","\n","    accuracy                         0.8038       943\n","   macro avg     0.7919    0.8209    0.8024       943\n","weighted avg     0.8084    0.8038    0.8021       943\n","\n","11/11/2023 05:04:29 [Dev set] [f1 0.8084]\n","11/11/2023 05:04:29 [Test set] [f1 0.8021]\n","train epoch 40: 100% 4/4 [00:01<00:00,  2.08it/s]\n","11/11/2023 05:04:31 \n","11/11/2023 05:04:31 [Epoch 40] [Loss: 1.183840] [Time: 1.921611]\n","dev: 100% 1/1 [00:00<00:00,  2.32it/s]\n","test: 100% 1/1 [00:00<00:00,  1.05it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7516    0.8403    0.7934       144\n","         sad     0.8922    0.8449    0.8679       245\n","         neu     0.8494    0.7344    0.7877       384\n","         ang     0.7202    0.9235    0.8093       170\n","\n","    accuracy                         0.8134       943\n","   macro avg     0.8033    0.8358    0.8146       943\n","weighted avg     0.8223    0.8134    0.8133       943\n","\n","11/11/2023 05:04:33 [Dev set] [f1 0.8365]\n","11/11/2023 05:04:33 Save the best model.\n","11/11/2023 05:04:33 [Test set] [f1 0.8133]\n","train epoch 41: 100% 4/4 [00:01<00:00,  2.02it/s]\n","11/11/2023 05:04:35 \n","11/11/2023 05:04:35 [Epoch 41] [Loss: 1.137180] [Time: 1.985329]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.04it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7450    0.7708    0.7577       144\n","         sad     0.8541    0.8122    0.8326       245\n","         neu     0.8312    0.6797    0.7479       384\n","         ang     0.6559    0.9529    0.7770       170\n","\n","    accuracy                         0.7773       943\n","   macro avg     0.7715    0.8039    0.7788       943\n","weighted avg     0.7924    0.7773    0.7766       943\n","\n","11/11/2023 05:04:36 [Dev set] [f1 0.7876]\n","11/11/2023 05:04:36 [Test set] [f1 0.7766]\n","train epoch 42: 100% 4/4 [00:02<00:00,  1.84it/s]\n","11/11/2023 05:04:38 \n","11/11/2023 05:04:38 [Epoch 42] [Loss: 0.934782] [Time: 2.176009]\n","dev: 100% 1/1 [00:00<00:00,  1.84it/s]\n","test: 100% 1/1 [00:01<00:00,  1.31s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7847    0.7847    0.7847       144\n","         sad     0.7705    0.9184    0.8380       245\n","         neu     0.8625    0.7188    0.7841       384\n","         ang     0.8021    0.8824    0.8403       170\n","\n","    accuracy                         0.8102       943\n","   macro avg     0.8050    0.8260    0.8118       943\n","weighted avg     0.8159    0.8102    0.8083       943\n","\n","11/11/2023 05:04:40 [Dev set] [f1 0.8347]\n","11/11/2023 05:04:40 [Test set] [f1 0.8083]\n","train epoch 43: 100% 4/4 [00:02<00:00,  1.59it/s]\n","11/11/2023 05:04:43 \n","11/11/2023 05:04:43 [Epoch 43] [Loss: 0.884032] [Time: 2.523892]\n","dev: 100% 1/1 [00:00<00:00,  1.50it/s]\n","test: 100% 1/1 [00:01<00:00,  1.68s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7794    0.7361    0.7571       144\n","         sad     0.8327    0.8531    0.8427       245\n","         neu     0.8421    0.6667    0.7442       384\n","         ang     0.6310    0.9353    0.7536       170\n","\n","    accuracy                         0.7741       943\n","   macro avg     0.7713    0.7978    0.7744       943\n","weighted avg     0.7920    0.7741    0.7735       943\n","\n","11/11/2023 05:04:45 [Dev set] [f1 0.7657]\n","11/11/2023 05:04:45 [Test set] [f1 0.7735]\n","train epoch 44: 100% 4/4 [00:02<00:00,  1.60it/s]\n","11/11/2023 05:04:48 \n","11/11/2023 05:04:48 [Epoch 44] [Loss: 0.931268] [Time: 2.496720]\n","dev: 100% 1/1 [00:00<00:00,  2.42it/s]\n","test: 100% 1/1 [00:00<00:00,  1.07it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7840    0.6806    0.7286       144\n","         sad     0.8502    0.8571    0.8537       245\n","         neu     0.8149    0.7682    0.7909       384\n","         ang     0.7560    0.9294    0.8338       170\n","\n","    accuracy                         0.8070       943\n","   macro avg     0.8013    0.8088    0.8017       943\n","weighted avg     0.8087    0.8070    0.8054       943\n","\n","11/11/2023 05:04:49 [Dev set] [f1 0.8009]\n","11/11/2023 05:04:49 [Test set] [f1 0.8054]\n","train epoch 45: 100% 4/4 [00:01<00:00,  2.13it/s]\n","11/11/2023 05:04:51 \n","11/11/2023 05:04:51 [Epoch 45] [Loss: 0.864365] [Time: 1.877083]\n","dev: 100% 1/1 [00:00<00:00,  2.51it/s]\n","test: 100% 1/1 [00:00<00:00,  1.09it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7032    0.7569    0.7291       144\n","         sad     0.8589    0.8449    0.8519       245\n","         neu     0.8162    0.7865    0.8011       384\n","         ang     0.8305    0.8647    0.8473       170\n","\n","    accuracy                         0.8112       943\n","   macro avg     0.8022    0.8133    0.8073       943\n","weighted avg     0.8126    0.8112    0.8116       943\n","\n","11/11/2023 05:04:52 [Dev set] [f1 0.8420]\n","11/11/2023 05:04:53 Save the best model.\n","11/11/2023 05:04:53 [Test set] [f1 0.8116]\n","train epoch 46: 100% 4/4 [00:01<00:00,  2.06it/s]\n","11/11/2023 05:04:55 \n","11/11/2023 05:04:55 [Epoch 46] [Loss: 0.783761] [Time: 1.944694]\n","dev: 100% 1/1 [00:00<00:00,  2.39it/s]\n","test: 100% 1/1 [00:00<00:00,  1.07it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7101    0.8333    0.7668       144\n","         sad     0.8372    0.8816    0.8588       245\n","         neu     0.8796    0.6276    0.7325       384\n","         ang     0.6694    0.9529    0.7864       170\n","\n","    accuracy                         0.7837       943\n","   macro avg     0.7741    0.8239    0.7861       943\n","weighted avg     0.8048    0.7837    0.7803       943\n","\n","11/11/2023 05:04:56 [Dev set] [f1 0.7990]\n","11/11/2023 05:04:56 [Test set] [f1 0.7803]\n","train epoch 47: 100% 4/4 [00:02<00:00,  1.61it/s]\n","11/11/2023 05:04:58 \n","11/11/2023 05:04:58 [Epoch 47] [Loss: 0.785506] [Time: 2.483015]\n","dev: 100% 1/1 [00:00<00:00,  1.76it/s]\n","test: 100% 1/1 [00:01<00:00,  1.31s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8000    0.6944    0.7435       144\n","         sad     0.8129    0.9224    0.8642       245\n","         neu     0.8376    0.7656    0.8000       384\n","         ang     0.8095    0.9000    0.8524       170\n","\n","    accuracy                         0.8197       943\n","   macro avg     0.8150    0.8206    0.8150       943\n","weighted avg     0.8204    0.8197    0.8175       943\n","\n","11/11/2023 05:05:00 [Dev set] [f1 0.8156]\n","11/11/2023 05:05:00 [Test set] [f1 0.8175]\n","train epoch 48: 100% 4/4 [00:02<00:00,  1.39it/s]\n","11/11/2023 05:05:03 \n","11/11/2023 05:05:03 [Epoch 48] [Loss: 0.859415] [Time: 2.876295]\n","dev: 100% 1/1 [00:00<00:00,  1.31it/s]\n","test: 100% 1/1 [00:01<00:00,  1.34s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7869    0.6667    0.7218       144\n","         sad     0.8777    0.8204    0.8481       245\n","         neu     0.7974    0.8099    0.8036       384\n","         ang     0.7673    0.9118    0.8333       170\n","\n","    accuracy                         0.8091       943\n","   macro avg     0.8073    0.8022    0.8017       943\n","weighted avg     0.8113    0.8091    0.8080       943\n","\n","11/11/2023 05:05:05 [Dev set] [f1 0.8255]\n","11/11/2023 05:05:05 [Test set] [f1 0.8080]\n","train epoch 49: 100% 4/4 [00:01<00:00,  2.08it/s]\n","11/11/2023 05:05:07 \n","11/11/2023 05:05:07 [Epoch 49] [Loss: 0.732193] [Time: 1.925000]\n","dev: 100% 1/1 [00:00<00:00,  2.31it/s]\n","test: 100% 1/1 [00:01<00:00,  1.20s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.6902    0.8819    0.7744       144\n","         sad     0.8732    0.7592    0.8122       245\n","         neu     0.8642    0.6797    0.7609       384\n","         ang     0.6680    0.9588    0.7874       170\n","\n","    accuracy                         0.7815       943\n","   macro avg     0.7739    0.8199    0.7837       943\n","weighted avg     0.8046    0.7815    0.7811       943\n","\n","11/11/2023 05:05:09 [Dev set] [f1 0.8067]\n","11/11/2023 05:05:09 [Test set] [f1 0.7811]\n","train epoch 50: 100% 4/4 [00:01<00:00,  2.07it/s]\n","11/11/2023 05:05:11 \n","11/11/2023 05:05:11 [Epoch 50] [Loss: 0.656037] [Time: 1.930440]\n","dev: 100% 1/1 [00:00<00:00,  2.43it/s]\n","test: 100% 1/1 [00:00<00:00,  1.06it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7438    0.8264    0.7829       144\n","         sad     0.8571    0.8816    0.8692       245\n","         neu     0.8631    0.7552    0.8056       384\n","         ang     0.7897    0.9059    0.8438       170\n","\n","    accuracy                         0.8261       943\n","   macro avg     0.8134    0.8423    0.8254       943\n","weighted avg     0.8301    0.8261    0.8255       943\n","\n","11/11/2023 05:05:12 [Dev set] [f1 0.8336]\n","11/11/2023 05:05:12 [Test set] [f1 0.8255]\n","train epoch 51: 100% 4/4 [00:01<00:00,  2.09it/s]\n","11/11/2023 05:05:14 \n","11/11/2023 05:05:14 [Epoch 51] [Loss: 0.593296] [Time: 1.912767]\n","dev: 100% 1/1 [00:00<00:00,  2.38it/s]\n","test: 100% 1/1 [00:01<00:00,  1.12s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7569    0.7569    0.7569       144\n","         sad     0.8233    0.8939    0.8571       245\n","         neu     0.8610    0.6615    0.7482       384\n","         ang     0.6765    0.9471    0.7892       170\n","\n","    accuracy                         0.7879       943\n","   macro avg     0.7794    0.8148    0.7879       943\n","weighted avg     0.8021    0.7879    0.7852       943\n","\n","11/11/2023 05:05:16 [Dev set] [f1 0.8069]\n","11/11/2023 05:05:16 [Test set] [f1 0.7852]\n","train epoch 52: 100% 4/4 [00:02<00:00,  1.61it/s]\n","11/11/2023 05:05:18 \n","11/11/2023 05:05:18 [Epoch 52] [Loss: 0.637074] [Time: 2.488958]\n","dev: 100% 1/1 [00:00<00:00,  1.81it/s]\n","test: 100% 1/1 [00:01<00:00,  1.32s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7692    0.7639    0.7666       144\n","         sad     0.8365    0.8980    0.8661       245\n","         neu     0.8660    0.6901    0.7681       384\n","         ang     0.6970    0.9471    0.8030       170\n","\n","    accuracy                         0.8017       943\n","   macro avg     0.7922    0.8248    0.8010       943\n","weighted avg     0.8131    0.8017    0.7996       943\n","\n","11/11/2023 05:05:20 [Dev set] [f1 0.8117]\n","11/11/2023 05:05:20 [Test set] [f1 0.7996]\n","train epoch 53: 100% 4/4 [00:02<00:00,  1.49it/s]\n","11/11/2023 05:05:23 \n","11/11/2023 05:05:23 [Epoch 53] [Loss: 0.640528] [Time: 2.693553]\n","dev: 100% 1/1 [00:00<00:00,  1.58it/s]\n","test: 100% 1/1 [00:00<00:00,  1.00it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7852    0.7361    0.7599       144\n","         sad     0.8444    0.8857    0.8645       245\n","         neu     0.8466    0.7188    0.7775       384\n","         ang     0.7156    0.9471    0.8152       170\n","\n","    accuracy                         0.8059       943\n","   macro avg     0.7979    0.8219    0.8043       943\n","weighted avg     0.8130    0.8059    0.8042       943\n","\n","11/11/2023 05:05:24 [Dev set] [f1 0.8156]\n","11/11/2023 05:05:24 [Test set] [f1 0.8042]\n","train epoch 54: 100% 4/4 [00:01<00:00,  2.08it/s]\n","11/11/2023 05:05:26 \n","11/11/2023 05:05:26 [Epoch 54] [Loss: 0.588646] [Time: 1.924575]\n","dev: 100% 1/1 [00:00<00:00,  2.34it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7923    0.7153    0.7518       144\n","         sad     0.8391    0.8939    0.8656       245\n","         neu     0.8402    0.7396    0.7867       384\n","         ang     0.7430    0.9353    0.8281       170\n","\n","    accuracy                         0.8112       943\n","   macro avg     0.8037    0.8210    0.8081       943\n","weighted avg     0.8151    0.8112    0.8093       943\n","\n","11/11/2023 05:05:28 [Dev set] [f1 0.8340]\n","11/11/2023 05:05:28 [Test set] [f1 0.8093]\n","train epoch 55: 100% 4/4 [00:02<00:00,  1.83it/s]\n","11/11/2023 05:05:30 \n","11/11/2023 05:05:30 [Epoch 55] [Loss: 0.585312] [Time: 2.191618]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7939    0.7222    0.7564       144\n","         sad     0.8467    0.9020    0.8735       245\n","         neu     0.8401    0.7526    0.7940       384\n","         ang     0.7585    0.9235    0.8329       170\n","\n","    accuracy                         0.8176       943\n","   macro avg     0.8098    0.8251    0.8142       943\n","weighted avg     0.8201    0.8176    0.8159       943\n","\n","11/11/2023 05:05:31 [Dev set] [f1 0.8310]\n","11/11/2023 05:05:31 [Test set] [f1 0.8159]\n","11/11/2023 05:05:31 \n","11/11/2023 05:05:31 Best in epoch 45:\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","11/11/2023 05:05:32 [Dev set] [f1 0.8420]\n","test: 100% 1/1 [00:01<00:00,  1.00s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7032    0.7569    0.7291       144\n","         sad     0.8589    0.8449    0.8519       245\n","         neu     0.8162    0.7865    0.8011       384\n","         ang     0.8305    0.8647    0.8473       170\n","\n","    accuracy                         0.8112       943\n","   macro avg     0.8022    0.8133    0.8073       943\n","weighted avg     0.8126    0.8112    0.8116       943\n","\n","11/11/2023 05:05:33 [Test set] f1 0.811596690824131\n"]}]},{"cell_type":"code","source":["!python eval.py --dataset=\"iemocap_4\" --modalities=\"atv\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khPEunyYWVLx","executionInfo":{"status":"ok","timestamp":1700605515684,"user_tz":-60,"elapsed":18541,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"981db0a6-d856-427c-b486-ba2a25a7d371"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(dataset='iemocap_4', transformers=False, data_dir_path='./data', from_begin=True, model_ckpt=None, device='cuda', epochs=55, batch_size=32, optimizer='adam', scheduler='reduceLR', learning_rate=0.0001, weight_decay=1e-08, max_grad_value=-1, drop_rate=0.5, wp=5, wf=5, n_speakers=2, hidden_size=100, rnn='transformer', class_weight=False, encoding=None, trans_encoding=False, modalities='atv', emotion=None, concat_gin_gout=False, seqcontext_nlayer=2, gnn_nheads=1, num_bases=7, use_highway=False, seed=24, log_in_comet=False, comet_api_key=None, comet_workspace=None, use_pe_in_seqcontext=False, tuning=False, tag='hyperparameters_opt', dataset_embedding_dims={'iemocap': {'a': 100, 't': 768, 'v': 512, 'at': 868, 'tv': 1280, 'av': 612, 'atv': 1380}, 'iemocap_4': {'a': 100, 't': 768, 'v': 512, 'at': 868, 'tv': 1280, 'av': 612, 'atv': 1380}, 'mosei': {'a': 80, 't': 768, 'v': 35, 'at': 848, 'tv': 803, 'av': 115, 'atv': 883}}, data='./data/iemocap_4/data_iemocap_4.pkl')\n","test: 100% 1/1 [00:00<00:00,  1.04it/s]\n","              precision    recall  f1-score   support\n","\n","           0     0.2609    0.0417    0.0719       144\n","           1     0.2674    0.7388    0.3926       245\n","           2     0.3700    0.0964    0.1529       384\n","           3     0.2378    0.2000    0.2173       170\n","\n","    accuracy                         0.2736       943\n","   macro avg     0.2840    0.2692    0.2087       943\n","weighted avg     0.3028    0.2736    0.2144       943\n","\n","F1 Score: 0.21440510615848035\n"]}]},{"cell_type":"code","source":["# import pickle as pkl\n","\n","# from sklearn.metrics import classification_report, confusion_matrix\n","# model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/new_model.pt')\n","\n","# with open(\"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/testset.pkl\", \"rb\") as f:\n","#     test_dataset = pkl.load(f)\n","# Y_pred = model(test_dataset)\n","\n","# y_pred = np.argmax(Y_pred, axis=1)\n","\n","# print('                     ')\n","# print('Confusion Matrix')\n","# print('                     ')\n","# print(confusion_matrix(test_dataset.classes, y_pred))\n","# print('------------------------------------------------')\n","# print('Classification Report')\n","# print('                     ')\n","# target_names = ['0', '1', '2','3']\n","# print(classification_report(test_dataset.classes, y_pred, target_names=target_names))"],"metadata":{"id":"TMBRc-31Yd2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle as pkl\n","from sklearn import metrics\n","with open(\"/content/drive/MyDrive/Master_2023_sept/COGMEN-main/testset.pkl\", \"rb\") as f:\n","    testset = pkl.load(f)\n","\n","from tqdm import tqdm\n","test = True\n","with torch.no_grad():\n","    golds = []\n","    preds = []\n","    for idx in tqdm(range(len(testset)), desc=\"test\" if test else \"dev\"):\n","        data = testset[idx]\n","        golds.append(data[\"label_tensor\"])\n","        for k, v in data.items():\n","            if not k == \"utterance_texts\":\n","                data[k] = v.to('cuda')\n","        y_hat = model(data)\n","        preds.append(y_hat.detach().to(\"cpu\"))\n","\n","\n","        golds = torch.cat(golds, dim=-1).numpy()\n","        preds = torch.cat(preds, dim=-1).numpy()\n","        f1 = metrics.f1_score(golds, preds, average=\"weighted\")\n","\n","    if test:\n","        print(metrics.classification_report(golds, preds, digits=4))\n","\n","        # if stored_args.dataset == \"mosei\" and stored_args.emotion == \"multilabel\":\n","        #     happy = metrics.f1_score(golds[:, 0], preds[:, 0], average=\"weighted\")\n","        #     sad = metrics.f1_score(golds[:, 1], preds[:, 1], average=\"weighted\")\n","        #     anger = metrics.f1_score(golds[:, 2], preds[:, 2], average=\"weighted\")\n","        #     surprise = metrics.f1_score(\n","        #         golds[:, 3], preds[:, 3], average=\"weighted\"\n","        #     )\n","        #     disgust = metrics.f1_score(golds[:, 4], preds[:, 4], average=\"weighted\")\n","        #     fear = metrics.f1_score(golds[:, 5], preds[:, 5], average=\"weighted\")\n","\n","        #     f1 = {\n","        #         \"happy\": happy,\n","        #         \"sad\": sad,\n","        #         \"anger\": anger,\n","        #         \"surprise\": surprise,\n","        #         \"disgust\": disgust,\n","        #         \"fear\": fear,\n","        #     }\n","\n","        print(f\"F1 Score: {f1}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDWs4x0lemba","executionInfo":{"status":"ok","timestamp":1699726352987,"user_tz":-60,"elapsed":5142,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"37a865c0-5dd4-4bbf-8734-63c79eb95025"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["test: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.1351    0.0347    0.0552       144\n","           1     0.2481    0.6653    0.3614       245\n","           2     0.2267    0.0443    0.0741       384\n","           3     0.1839    0.1882    0.1860       170\n","\n","    accuracy                         0.2301       943\n","   macro avg     0.1985    0.2331    0.1692       943\n","weighted avg     0.2105    0.2301    0.1660       943\n","\n","F1 Score: 0.16604011067499025\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}