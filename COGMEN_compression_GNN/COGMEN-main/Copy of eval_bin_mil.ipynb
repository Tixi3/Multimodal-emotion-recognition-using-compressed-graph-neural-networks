import pickle
import os
import argparse
import torch
import os

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import metrics
from tqdm import tqdm

import cogmen

log = cogmen.utils.get_logger()


def load_pkl(file):
    with open(file, "rb") as f:
        return pickle.load(f)



def get_wb(model):
    weights1=[]
    bias1=[]
    for name, param in model.named_parameters():
        if 'weight' in name:
            print(f'Weight matrix for {name}:')
            print(param)
            weights1.append(param.view(-1))
        elif 'bias' in name:
            print(f'Bias vector for {name}:')
            print(param)
            bias1.append(param.view(-1))
    # print(weights_and_biases_vector)
    weights_vec=torch.cat(weights1)
    bias_vec=torch.cat(bias1)
    #print('weights vector')
    #print(weights_vec)
    #print('bias vector')
    return weights1, weights_vec, bias_vec

def main(args):
    
    data = load_pkl(f"data/{args.dataset}/data_{args.dataset}.pkl")

    model_dict = torch.load(
         "model_checkpoints/"
        + str(args.dataset)
        + "_best_dev_f1_model_"
        + str(args.modalities)
        + ".pt",
        #'/content/drive/MyDrive/Master_2023_sept/COGMEN-main/milion_model.pt'
    )
    stored_args = model_dict["args"]
    print(stored_args)
    model = model_dict["state_dict"]
    
    weights1, weights_vec, bias_vec = get_wb(model)
    novi_param = []
    poz = []
    for i in range(len(weights1)):
      if int(weights1[i].numel()) >1000000:
        print(weights1[i].size)
        novi = torch.where(weights1[i] > 0, torch.tensor(1), torch.tensor(-1))
        a = novi.cpu()
        novi_np = a.detach().numpy()

        novi_np = np.asarray(novi_np).astype(np.float32)
        print(novi_np.shape)
        #novi = np.asarray(novi).astype(np.float32)
        print(novi_np)
        #print(int(novi_np.numel()))
        poz.append(i)
        novi_param.append(novi_np)
    i=0
    for name, params in model.named_parameters():
        print(name)
        print(params.shape)
        if 'weight' in name:
          if params.numel()>1000000:
            print(i)
            velicina = params.shape
            novi_param[i] = np.asarray(novi_param[i]).astype(np.float32)
            print(novi_param[i].dtype)
            novi_reshaped = np.reshape(novi_param[i], velicina)
            tenzor = torch.from_numpy(novi_reshaped)
            tenzor.requires_grad_(True)
            tenzor.to('cuda:0')
            params.data.copy_(tenzor)
            i=i+1
    

    # for name, params in model.named_parameters():
    #   print(name)
    #   print(params)
    #model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/milion_model1.pt')
    testset = cogmen.Dataset(data["test"], stored_args)
    import pickle as pkl
    model.eval()

    #to save it
    with open("testset.pkl", "wb") as f:
        pkl.dump(testset, f)

    test = True
    with torch.no_grad():
        golds = []
        preds = []
        for idx in tqdm(range(len(testset)), desc="test" if test else "dev"):
            data = testset[idx]
            golds.append(data["label_tensor"])
            for k, v in data.items():
                if not k == "utterance_texts":
                    data[k] = v.to(stored_args.device)
            y_hat = model(data)
            preds.append(y_hat.detach().to("cpu"))

        if stored_args.dataset == "mosei" and stored_args.emotion == "multilabel":
            golds = torch.cat(golds, dim=0).numpy()
            preds = torch.cat(preds, dim=0).numpy()
            f1 = metrics.f1_score(golds, preds, average="weighted")
            acc = metrics.accuracy_score(golds, preds)
        else:
            golds = torch.cat(golds, dim=-1).numpy()
            preds = torch.cat(preds, dim=-1).numpy()
            f1 = metrics.f1_score(golds, preds, average="weighted")

        if test:
            print(metrics.classification_report(golds, preds, digits=4))

            if stored_args.dataset == "mosei" and stored_args.emotion == "multilabel":
                happy = metrics.f1_score(golds[:, 0], preds[:, 0], average="weighted")
                sad = metrics.f1_score(golds[:, 1], preds[:, 1], average="weighted")
                anger = metrics.f1_score(golds[:, 2], preds[:, 2], average="weighted")
                surprise = metrics.f1_score(
                    golds[:, 3], preds[:, 3], average="weighted"
                )
                disgust = metrics.f1_score(golds[:, 4], preds[:, 4], average="weighted")
                fear = metrics.f1_score(golds[:, 5], preds[:, 5], average="weighted")

                f1 = {
                    "happy": happy,
                    "sad": sad,
                    "anger": anger,
                    "surprise": surprise,
                    "disgust": disgust,
                    "fear": fear,
                }

            print(f"F1 Score: {f1}")
            


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description="eval.py")
    parser.add_argument(
        "--dataset",
        type=str,
        required=True,
        default="iemocap_4",
        choices=["iemocap", "iemocap_4", "mosei"],
        help="Dataset name.",
    )

   

    parser.add_argument(
        "--data_dir_path", type=str, help="Dataset directory path", default="./data"
    )

    parser.add_argument("--device", type=str, default="cpu", help="Computing device.")

    # Modalities
    """ Modalities effects:
        -> dimentions of input vectors in dataset.py
        -> number of heads in transformer_conv in seqcontext.py"""
    parser.add_argument(
        "--modalities",
        type=str,
        default="atv",
        # required=True,
        choices=["a", "at", "atv"],
        help="Modalities",
    )

    # emotion
    parser.add_argument(
        "--emotion", type=str, default=None, help="emotion class for mosei"
    )


    

    args = parser.parse_args()
    main(args)
