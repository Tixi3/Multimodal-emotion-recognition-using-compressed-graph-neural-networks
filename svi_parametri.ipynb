{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bc7ff3035cb94fd3934e4b535bf47372":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f17bd5abdf634316bd6e482d92b64c07","IPY_MODEL_26c93aceb5e74544bd98e89597747611","IPY_MODEL_b8adcf893b83472390a255a60505356e"],"layout":"IPY_MODEL_55eefad3a8274821ae4389accd7c4fb2"}},"f17bd5abdf634316bd6e482d92b64c07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4bbbc3e2a974d9a992f94ccf0a78a5a","placeholder":"​","style":"IPY_MODEL_67d01a55319e4c04ab44c64ee3f63f39","value":"modules.json: 100%"}},"26c93aceb5e74544bd98e89597747611":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49b7d61cb61b45eabd3c15f083fca750","max":229,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cd298a0de194c99955be2ae2d12ffd7","value":229}},"b8adcf893b83472390a255a60505356e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db575f20d6f3411685741e4d924eb402","placeholder":"​","style":"IPY_MODEL_1b97df1349704b5f9074c18ce3e6be4f","value":" 229/229 [00:00&lt;00:00, 16.3kB/s]"}},"55eefad3a8274821ae4389accd7c4fb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4bbbc3e2a974d9a992f94ccf0a78a5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67d01a55319e4c04ab44c64ee3f63f39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49b7d61cb61b45eabd3c15f083fca750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cd298a0de194c99955be2ae2d12ffd7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db575f20d6f3411685741e4d924eb402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b97df1349704b5f9074c18ce3e6be4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6453733d215d420d9a48c0cb5a0cb42b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0b40493bff642f6832bd6ce5907d4cd","IPY_MODEL_06f6b3f9c6ea40cb8d2244b665fb4a68","IPY_MODEL_798e413e2ca54d78bf10e56bfac6b522"],"layout":"IPY_MODEL_88b776ba1c624bef9395791715fcd375"}},"c0b40493bff642f6832bd6ce5907d4cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a8718f5e59b452c898d2b4b7b71f8bd","placeholder":"​","style":"IPY_MODEL_5a08f4f894bb4c36ae8aad5c56f2d304","value":"config_sentence_transformers.json: 100%"}},"06f6b3f9c6ea40cb8d2244b665fb4a68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbb6f8ba445e4897b3860355c895b894","max":122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e09dc75196b4443990053e3353c8a018","value":122}},"798e413e2ca54d78bf10e56bfac6b522":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfc2626065c043e19e8b531bb3ef0e41","placeholder":"​","style":"IPY_MODEL_bb211d47769347e8ba33c9bc5e0de27b","value":" 122/122 [00:00&lt;00:00, 9.50kB/s]"}},"88b776ba1c624bef9395791715fcd375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a8718f5e59b452c898d2b4b7b71f8bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a08f4f894bb4c36ae8aad5c56f2d304":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbb6f8ba445e4897b3860355c895b894":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e09dc75196b4443990053e3353c8a018":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfc2626065c043e19e8b531bb3ef0e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb211d47769347e8ba33c9bc5e0de27b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b0df0fa884f479ca281b367f4cd6ee7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4b4201071b24b15a77ca26c0739489f","IPY_MODEL_7596e1dff23a45f0ae7c3b981e6a6307","IPY_MODEL_a1a2fb42ade140cb823f080843c08b7a"],"layout":"IPY_MODEL_770bfd9778ae4400b65ab95b5ce8dee8"}},"b4b4201071b24b15a77ca26c0739489f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44e7e68b3ac141d2959d8f89f4aa9230","placeholder":"​","style":"IPY_MODEL_7697b3fb48e64a73ac57036b1bbed406","value":"README.md: 100%"}},"7596e1dff23a45f0ae7c3b981e6a6307":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79e1d037f8d14cc48a15211f12490bf8","max":3777,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2485779004804019921401e7c564160a","value":3777}},"a1a2fb42ade140cb823f080843c08b7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4ff6a31f55044f7bf8be469bb534af0","placeholder":"​","style":"IPY_MODEL_515ecebb242346e380ab1405639cefa7","value":" 3.78k/3.78k [00:00&lt;00:00, 308kB/s]"}},"770bfd9778ae4400b65ab95b5ce8dee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44e7e68b3ac141d2959d8f89f4aa9230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7697b3fb48e64a73ac57036b1bbed406":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79e1d037f8d14cc48a15211f12490bf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2485779004804019921401e7c564160a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4ff6a31f55044f7bf8be469bb534af0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"515ecebb242346e380ab1405639cefa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1ed120de8994e04be9e8df2a4b180bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36c28f19b1e145b78650c85b1348df83","IPY_MODEL_5fbe64543ed84f96ae6afc569dbcebdc","IPY_MODEL_9213825380b54ab486d39c3b4eaec984"],"layout":"IPY_MODEL_346a0eac12be44d4bcbfc99d56528aa7"}},"36c28f19b1e145b78650c85b1348df83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ef0aa431ebf4eaea40ce9a1dba2a55d","placeholder":"​","style":"IPY_MODEL_62304b9782364417bfa4b0530de3251c","value":"sentence_bert_config.json: 100%"}},"5fbe64543ed84f96ae6afc569dbcebdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8e87eae12dd4fdfb1a458bc892f107f","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce8ae45678bd4c33b20b7ff0a43c62ed","value":53}},"9213825380b54ab486d39c3b4eaec984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45be499e2e43496496859d4659ecea11","placeholder":"​","style":"IPY_MODEL_98515da7b6ac4b6db441005f9ecb7715","value":" 53.0/53.0 [00:00&lt;00:00, 1.99kB/s]"}},"346a0eac12be44d4bcbfc99d56528aa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ef0aa431ebf4eaea40ce9a1dba2a55d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62304b9782364417bfa4b0530de3251c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8e87eae12dd4fdfb1a458bc892f107f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce8ae45678bd4c33b20b7ff0a43c62ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45be499e2e43496496859d4659ecea11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98515da7b6ac4b6db441005f9ecb7715":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fafecc7765442d5928a99c775f8bef7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99f75c4874034433b6c2bb0a9edc30f2","IPY_MODEL_0496f837e4f9499aa9eaba529fd60084","IPY_MODEL_031414190c1b41c08c682eb7b6ebea34"],"layout":"IPY_MODEL_0cb2319516b34d5c8ff33a185d3ee40b"}},"99f75c4874034433b6c2bb0a9edc30f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_770d09548bc044288f44a4c1d8bef01c","placeholder":"​","style":"IPY_MODEL_c33614634edb438a8dd7e9315e4327c3","value":"config.json: 100%"}},"0496f837e4f9499aa9eaba529fd60084":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84f23ba9bb97498f8ffce0debbae912e","max":718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93236b85a4ed4eb9805d765b96ac5898","value":718}},"031414190c1b41c08c682eb7b6ebea34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c255e70502d47abb0885adaf048fb47","placeholder":"​","style":"IPY_MODEL_28fbb965fc68452b80d4266f35ac6f2c","value":" 718/718 [00:00&lt;00:00, 44.6kB/s]"}},"0cb2319516b34d5c8ff33a185d3ee40b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"770d09548bc044288f44a4c1d8bef01c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c33614634edb438a8dd7e9315e4327c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84f23ba9bb97498f8ffce0debbae912e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93236b85a4ed4eb9805d765b96ac5898":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c255e70502d47abb0885adaf048fb47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28fbb965fc68452b80d4266f35ac6f2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8b39f60423741cb879928a1d40a70c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33deea579c2d491fb89e6a35433f9699","IPY_MODEL_5d07cbdc9b6046d4be0fff987976a3e7","IPY_MODEL_bbb269eebb614c53bf3bddbe38670a71"],"layout":"IPY_MODEL_d5cc8437b52e4a3fa206d2554842765b"}},"33deea579c2d491fb89e6a35433f9699":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f960e2e7c5643418a8c9092b61db6ae","placeholder":"​","style":"IPY_MODEL_1509c0c87ad049c58ed98e97dafee316","value":"model.safetensors: 100%"}},"5d07cbdc9b6046d4be0fff987976a3e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b96aa4f6646a4ff48302c4b5faa5566b","max":328489328,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27e6256ea831493ca5f665864d1d81c3","value":328489328}},"bbb269eebb614c53bf3bddbe38670a71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bdb5c335645471f9c060fa5f4641a31","placeholder":"​","style":"IPY_MODEL_ce9e5d48d8794d09a2a2b18110decc32","value":" 328M/328M [00:01&lt;00:00, 275MB/s]"}},"d5cc8437b52e4a3fa206d2554842765b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f960e2e7c5643418a8c9092b61db6ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1509c0c87ad049c58ed98e97dafee316":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b96aa4f6646a4ff48302c4b5faa5566b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27e6256ea831493ca5f665864d1d81c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3bdb5c335645471f9c060fa5f4641a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce9e5d48d8794d09a2a2b18110decc32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b035ee7675b24c70a401cc1e88e84a8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49ebbb5105d748719438b0a3153e8be6","IPY_MODEL_aaa458568d764ba2a0361891a19c008c","IPY_MODEL_c9e34adc2532490aa7c550946508a08f"],"layout":"IPY_MODEL_19ef4f468d724ca28055a5f5b9daab93"}},"49ebbb5105d748719438b0a3153e8be6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_880157d886684d418fb8eb58c245085c","placeholder":"​","style":"IPY_MODEL_0d1ce6c20af34d409575e34bae072615","value":"tokenizer_config.json: 100%"}},"aaa458568d764ba2a0361891a19c008c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b36aedfde30c44ff940ba4b843979f7f","max":1323,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a9c4b7a158947eca51025ad112a90b2","value":1323}},"c9e34adc2532490aa7c550946508a08f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80bc4563f24e4a3a9fe32765d6101ed3","placeholder":"​","style":"IPY_MODEL_fc3f18ab05a542999b5457a217737016","value":" 1.32k/1.32k [00:00&lt;00:00, 78.0kB/s]"}},"19ef4f468d724ca28055a5f5b9daab93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"880157d886684d418fb8eb58c245085c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d1ce6c20af34d409575e34bae072615":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b36aedfde30c44ff940ba4b843979f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a9c4b7a158947eca51025ad112a90b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80bc4563f24e4a3a9fe32765d6101ed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc3f18ab05a542999b5457a217737016":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fcb420e5c994e2d9b3461bb79744095":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03547fe1043c4596acb859467577b297","IPY_MODEL_0fdca819e9b5466ba54c484bae6b31fe","IPY_MODEL_82ea663f86e149678a99aea6ec018c1d"],"layout":"IPY_MODEL_ae6502a253f24caf9beaa1c4bd6a7190"}},"03547fe1043c4596acb859467577b297":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7f529e657814276835f42774d7e6950","placeholder":"​","style":"IPY_MODEL_5db58a239f4b4a35937530e9ed134633","value":"vocab.json: 100%"}},"0fdca819e9b5466ba54c484bae6b31fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45a38de80fe143e5ad55e2339ca282a5","max":798293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8a5a718f2644df3be34aab0a634885e","value":798293}},"82ea663f86e149678a99aea6ec018c1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad83bdeef88f496c9b6221032c7cda9d","placeholder":"​","style":"IPY_MODEL_b2b0ac98775240a6adf5f08d96058bb8","value":" 798k/798k [00:00&lt;00:00, 2.43MB/s]"}},"ae6502a253f24caf9beaa1c4bd6a7190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7f529e657814276835f42774d7e6950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db58a239f4b4a35937530e9ed134633":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45a38de80fe143e5ad55e2339ca282a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a5a718f2644df3be34aab0a634885e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad83bdeef88f496c9b6221032c7cda9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2b0ac98775240a6adf5f08d96058bb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"416c1e1699fd468594b092f6aaae0ac5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3a039d14a3241588f9b5869e7fd31fe","IPY_MODEL_16d8d5c2599a455484a3c9ff2f3d25a3","IPY_MODEL_e369ab697dfa4e73867b0dbf8ae23983"],"layout":"IPY_MODEL_fd5f09cfa1da48f79a5d7616a84aa67e"}},"f3a039d14a3241588f9b5869e7fd31fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e233496643984fa49157863000447e77","placeholder":"​","style":"IPY_MODEL_af47580d477c4aa08fb6d0a6c0267adb","value":"merges.txt: 100%"}},"16d8d5c2599a455484a3c9ff2f3d25a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_188e1271a1834d548e991cf005532067","max":456356,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae227a208ee74a5cb4a6ad5819f9e009","value":456356}},"e369ab697dfa4e73867b0dbf8ae23983":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e7e969f77e64b66b6a9137cb84ba77f","placeholder":"​","style":"IPY_MODEL_829cc19a513845458bfb5f75c4020b76","value":" 456k/456k [00:00&lt;00:00, 1.85MB/s]"}},"fd5f09cfa1da48f79a5d7616a84aa67e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e233496643984fa49157863000447e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af47580d477c4aa08fb6d0a6c0267adb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"188e1271a1834d548e991cf005532067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae227a208ee74a5cb4a6ad5819f9e009":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e7e969f77e64b66b6a9137cb84ba77f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"829cc19a513845458bfb5f75c4020b76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8190949780d43e4849a8d3227f67f03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f293d4076c348cb958dcad8fecc5dcc","IPY_MODEL_76d7bd6d1add4a5a903f8fbb74eab573","IPY_MODEL_a7fe8d6d259f40739677daf3895aad90"],"layout":"IPY_MODEL_2a4d19bb07f847d6be5a03933198f076"}},"3f293d4076c348cb958dcad8fecc5dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42e1222b7be1412aa7b2e61b13b5417e","placeholder":"​","style":"IPY_MODEL_005dbb67f7ca465caf3a28f4ac95952d","value":"tokenizer.json: 100%"}},"76d7bd6d1add4a5a903f8fbb74eab573":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40f1ba2c79ee47bb8adf8e2e15c47c12","max":1355881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58df148be32a41ea86666d5cecc82f36","value":1355881}},"a7fe8d6d259f40739677daf3895aad90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd9127cd42aa4267a16ab09a5e96acfd","placeholder":"​","style":"IPY_MODEL_6ba2a4aed48c414daf2494408a16b40c","value":" 1.36M/1.36M [00:00&lt;00:00, 3.27MB/s]"}},"2a4d19bb07f847d6be5a03933198f076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42e1222b7be1412aa7b2e61b13b5417e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"005dbb67f7ca465caf3a28f4ac95952d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40f1ba2c79ee47bb8adf8e2e15c47c12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58df148be32a41ea86666d5cecc82f36":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd9127cd42aa4267a16ab09a5e96acfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ba2a4aed48c414daf2494408a16b40c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d9ddddfa76c44b885e470d27371064b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40d727495bdd422c852ff971ab93e356","IPY_MODEL_fc66448bf8b84e25905f4f47ae5384f8","IPY_MODEL_17bf405f949649a8b0bc2db9d985fa5d"],"layout":"IPY_MODEL_a26f4b5b42e04af99449731789d1c5d1"}},"40d727495bdd422c852ff971ab93e356":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5bd8c3e71934ea7af3e19d9e18028c5","placeholder":"​","style":"IPY_MODEL_d06ea01a951848b3a977ebb19bb765b8","value":"special_tokens_map.json: 100%"}},"fc66448bf8b84e25905f4f47ae5384f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47389ab33afb4149be503a004dcebbb5","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17026c24ccf040f2826265df7159b3bc","value":239}},"17bf405f949649a8b0bc2db9d985fa5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49f84cff8a1244cfa0bc3c3a44128d31","placeholder":"​","style":"IPY_MODEL_308aa196d36b4cd78652a0c783db7a9b","value":" 239/239 [00:00&lt;00:00, 17.8kB/s]"}},"a26f4b5b42e04af99449731789d1c5d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5bd8c3e71934ea7af3e19d9e18028c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d06ea01a951848b3a977ebb19bb765b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47389ab33afb4149be503a004dcebbb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17026c24ccf040f2826265df7159b3bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49f84cff8a1244cfa0bc3c3a44128d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"308aa196d36b4cd78652a0c783db7a9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91937de9cf25481892561465c45fa9f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14816bd2ea044fa0871e76e879cd9ddf","IPY_MODEL_752e7b73e7ea40018d5a8c989e27eb99","IPY_MODEL_56a2246133ee4073b2a4d4c8b25d0280"],"layout":"IPY_MODEL_05b8c7f7d8024f78883045779bb993d3"}},"14816bd2ea044fa0871e76e879cd9ddf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a971da1f455441a1bc332d29661852a6","placeholder":"​","style":"IPY_MODEL_fc9c491a2f934f70ad99125c027532c3","value":"1_Pooling/config.json: 100%"}},"752e7b73e7ea40018d5a8c989e27eb99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e34af12bab874f0aabfb61d9cdb96b21","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c95378f122714a2f91494881724e1ff8","value":190}},"56a2246133ee4073b2a4d4c8b25d0280":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c634b4550af94738bcd136a925d581f4","placeholder":"​","style":"IPY_MODEL_a0074874acfc4b1e9f145006d70f52d8","value":" 190/190 [00:00&lt;00:00, 7.68kB/s]"}},"05b8c7f7d8024f78883045779bb993d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a971da1f455441a1bc332d29661852a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc9c491a2f934f70ad99125c027532c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e34af12bab874f0aabfb61d9cdb96b21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c95378f122714a2f91494881724e1ff8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c634b4550af94738bcd136a925d581f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0074874acfc4b1e9f145006d70f52d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpQlkd_ExQnl","executionInfo":{"status":"ok","timestamp":1725024736966,"user_tz":-120,"elapsed":51558,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"4e5342cf-dd50-4014-e3f8-d88d1bdd8c61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Master_2023_sept/COGMEN-main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hv04BJa93Zlc","executionInfo":{"status":"ok","timestamp":1725024781831,"user_tz":-120,"elapsed":661,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"38bed901-c259-4128-aba4-00765e6e56bf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Master_2023_sept/COGMEN-main\n"]}]},{"cell_type":"code","source":["\n","!pip3 install torch torchvision #--use-deprecated=legacy-resolver\n","!pip3 install torchaudio #--use-deprecated=legacy-resolver\n","!pip3 install torch_geometric #--use-deprecated=legacy-resolver\n","!pip3 install comet_ml #--upgrade --quiet --use-deprecated=legacy-resolver\n","!pip3 install -U sentence-transformers #--use-deprecated=legacy-resolver"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vpxzES0g3cl4","executionInfo":{"status":"ok","timestamp":1725024801696,"user_tz":-120,"elapsed":17874,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"3ead9c86-b74a-4ee5-9f1e-c30dd08679df"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchaudio) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchaudio) (1.3.0)\n","Collecting torch_geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n","Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.5.3\n","Collecting comet_ml\n","  Downloading comet_ml-3.45.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.23.0)\n","Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n","Collecting python-box<7.0.0 (from comet_ml)\n","  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n","Collecting requests-toolbelt>=0.8.0 (from comet_ml)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.32.3)\n","Collecting semantic-version>=2.8.0 (from comet_ml)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting sentry-sdk>=1.1.0 (from comet_ml)\n","  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting simplejson (from comet_ml)\n","  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.0.7)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n","Collecting wurlitzer>=1.0.2 (from comet_ml)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n","  Downloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.8.0)\n","Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Downloading configobj-5.0.8-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.20.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.7.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet_ml) (1.16.0)\n","Downloading comet_ml-3.45.0-py3-none-any.whl (687 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m687.3/687.3 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (979 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n","Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n","Installing collected packages: everett, wurlitzer, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n","  Attempting uninstall: python-box\n","    Found existing installation: python-box 7.2.0\n","    Uninstalling python-box-7.2.0:\n","      Successfully uninstalled python-box-7.2.0\n","Successfully installed comet_ml-3.45.0 configobj-5.0.8 dulwich-0.22.1 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-2.13.0 simplejson-3.19.3 wurlitzer-3.1.1\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","Successfully installed sentence-transformers-3.0.1\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np"],"metadata":{"id":"qzEady9y3cyW","executionInfo":{"status":"ok","timestamp":1725024830341,"user_tz":-120,"elapsed":3392,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!python preprocess.py --dataset=\"iemocap_4\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKLjJ9xSA2EY","executionInfo":{"status":"ok","timestamp":1698925401131,"user_tz":-60,"elapsed":40067,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"07c66da2-aecc-44fd-adb1-f5c9f8a5eea9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\rDownloading (…)7f4ef/.gitattributes:   0% 0.00/391 [00:00<?, ?B/s]\rDownloading (…)7f4ef/.gitattributes: 100% 391/391 [00:00<00:00, 1.96MB/s]\n","Downloading (…)_Pooling/config.json: 100% 190/190 [00:00<00:00, 1.35MB/s]\n","Downloading (…)f279f7f4ef/README.md: 100% 3.74k/3.74k [00:00<00:00, 25.5MB/s]\n","Downloading (…)79f7f4ef/config.json: 100% 718/718 [00:00<00:00, 5.13MB/s]\n","Downloading (…)ce_transformers.json: 100% 122/122 [00:00<00:00, 629kB/s]\n","Downloading (…)279f7f4ef/merges.txt: 100% 456k/456k [00:00<00:00, 3.44MB/s]\n","Downloading pytorch_model.bin: 100% 329M/329M [00:01<00:00, 255MB/s]\n","Downloading (…)nce_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 327kB/s]\n","Downloading (…)cial_tokens_map.json: 100% 239/239 [00:00<00:00, 1.72MB/s]\n","Downloading (…)7f4ef/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 4.10MB/s]\n","Downloading (…)okenizer_config.json: 100% 1.35k/1.35k [00:00<00:00, 7.90MB/s]\n","Downloading (…)279f7f4ef/vocab.json: 100% 798k/798k [00:00<00:00, 4.03MB/s]\n","Downloading (…)9f7f4ef/modules.json: 100% 229/229 [00:00<00:00, 1.19MB/s]\n","Seed set\n","train: 100% 108/108 [00:12<00:00,  8.82it/s]\n","dev: 100% 12/12 [00:00<00:00, 25.19it/s]\n","test: 100% 31/31 [00:01<00:00, 24.45it/s]\n","11/02/2023 11:43:15 train vids:\n","11/02/2023 11:43:15 ['Ses01F_impro01', 'Ses01F_impro02', 'Ses01F_impro04', 'Ses01F_impro05', 'Ses01F_impro06', 'Ses01F_impro07', 'Ses01F_script01_1', 'Ses01F_script01_2', 'Ses01F_script01_3', 'Ses01F_script02_1', 'Ses01F_script03_1', 'Ses01F_script03_2', 'Ses01M_impro01', 'Ses01M_impro02', 'Ses01M_impro03', 'Ses01M_impro04', 'Ses01M_impro06', 'Ses01M_impro07', 'Ses01M_script01_1', 'Ses01M_script01_2', 'Ses01M_script01_3', 'Ses01M_script02_1', 'Ses01M_script02_2', 'Ses01M_script03_1', 'Ses01M_script03_2', 'Ses02F_impro01', 'Ses02F_impro02', 'Ses02F_impro03', 'Ses02F_impro04', 'Ses02F_impro06', 'Ses02F_impro07', 'Ses02F_impro08', 'Ses02F_script01_2', 'Ses02F_script02_1', 'Ses02F_script02_2', 'Ses02F_script03_1', 'Ses02F_script03_2', 'Ses02M_impro01', 'Ses02M_impro02', 'Ses02M_impro03', 'Ses02M_impro04', 'Ses02M_impro05', 'Ses02M_impro06', 'Ses02M_impro07', 'Ses02M_impro08', 'Ses02M_script01_1', 'Ses02M_script01_2', 'Ses02M_script01_3', 'Ses02M_script02_1', 'Ses02M_script03_1', 'Ses02M_script03_2', 'Ses03F_impro01', 'Ses03F_impro02', 'Ses03F_impro03', 'Ses03F_impro04', 'Ses03F_impro05', 'Ses03F_impro06', 'Ses03F_impro07', 'Ses03F_impro08', 'Ses03F_script01_1', 'Ses03F_script01_2', 'Ses03F_script01_3', 'Ses03F_script02_1', 'Ses03F_script02_2', 'Ses03F_script03_2', 'Ses03M_impro01', 'Ses03M_impro02', 'Ses03M_impro03', 'Ses03M_impro04', 'Ses03M_impro05a', 'Ses03M_impro06', 'Ses03M_impro07', 'Ses03M_impro08a', 'Ses03M_script01_1', 'Ses03M_script01_2', 'Ses03M_script01_3', 'Ses03M_script02_1', 'Ses03M_script02_2', 'Ses03M_script03_1', 'Ses03M_script03_2', 'Ses04F_impro01', 'Ses04F_impro02', 'Ses04F_impro03', 'Ses04F_impro04', 'Ses04F_impro05', 'Ses04F_impro06', 'Ses04F_impro08', 'Ses04F_script01_1', 'Ses04F_script01_2', 'Ses04F_script01_3', 'Ses04F_script02_1', 'Ses04F_script02_2', 'Ses04F_script03_1', 'Ses04F_script03_2', 'Ses04M_impro01', 'Ses04M_impro02', 'Ses04M_impro03', 'Ses04M_impro05', 'Ses04M_impro06', 'Ses04M_impro07', 'Ses04M_impro08', 'Ses04M_script01_1', 'Ses04M_script01_2', 'Ses04M_script01_3', 'Ses04M_script02_1', 'Ses04M_script02_2', 'Ses04M_script03_1', 'Ses04M_script03_2']\n","11/02/2023 11:43:15 dev vids:\n","11/02/2023 11:43:15 ['Ses01F_impro03', 'Ses01F_script02_2', 'Ses01M_impro05', 'Ses02F_impro05', 'Ses02F_script01_1', 'Ses02F_script01_3', 'Ses02M_script02_2', 'Ses03F_script03_1', 'Ses03M_impro05b', 'Ses03M_impro08b', 'Ses04F_impro07', 'Ses04M_impro04']\n","11/02/2023 11:43:15 test vids:\n","11/02/2023 11:43:15 ['Ses05F_impro01', 'Ses05F_impro02', 'Ses05F_impro03', 'Ses05F_impro04', 'Ses05F_impro05', 'Ses05F_impro06', 'Ses05F_impro07', 'Ses05F_impro08', 'Ses05F_script01_1', 'Ses05F_script01_2', 'Ses05F_script01_3', 'Ses05F_script02_1', 'Ses05F_script02_2', 'Ses05F_script03_1', 'Ses05F_script03_2', 'Ses05M_impro01', 'Ses05M_impro02', 'Ses05M_impro03', 'Ses05M_impro04', 'Ses05M_impro05', 'Ses05M_impro06', 'Ses05M_impro07', 'Ses05M_impro08', 'Ses05M_script01_1', 'Ses05M_script01_1b', 'Ses05M_script01_2', 'Ses05M_script01_3', 'Ses05M_script02_1', 'Ses05M_script02_2', 'Ses05M_script03_1', 'Ses05M_script03_2']\n","11/02/2023 11:43:17 number of train samples: 108\n","11/02/2023 11:43:17 number of dev samples: 12\n","11/02/2023 11:43:17 number of test samples: 31\n"]}]},{"cell_type":"code","source":["!python train.py --dataset=\"iemocap_4\" --modalities=\"atv\" --from_begin --epochs=55"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwMvoDUzA25y","executionInfo":{"status":"ok","timestamp":1698744289010,"user_tz":-60,"elapsed":256264,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"57d0036d-a8bd-4fde-85c3-6a1e0bf1439c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-31 09:20:40.029595: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-31 09:20:40.029668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-31 09:20:40.029716: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-10-31 09:20:41.099111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Seed set\n","10/31/2023 09:20:42 Loaded data.\n","SeqContext-> USING Transformer\n","args.drop_rate: 0.5\n","bn\n","<generator object Module.parameters at 0x78503685c510>\n","gnn_nheads\n","1\n","Using Scheduler\n","10/31/2023 09:20:46 Start training...\n","Help on Coach in module cogmen.Coach object:\n","\n","class C\bCo\boa\bac\bch\bh(builtins.object)\n"," |  Coach(trainset, devset, testset, model, opt, sched, args)\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  _\b__\b_i\bin\bni\bit\bt_\b__\b_(self, trainset, devset, testset, model, opt, sched, args)\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  e\bev\bva\bal\blu\bua\bat\bte\be(self, test=False)\n"," |  \n"," |  l\blo\boa\bad\bd_\b_c\bck\bkp\bpt\bt(self, ckpt)\n"," |  \n"," |  t\btr\bra\bai\bin\bn(self)\n"," |  \n"," |  t\btr\bra\bai\bin\bn_\b_e\bep\bpo\boc\bch\bh(self, epoch)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  _\b__\b_d\bdi\bic\bct\bt_\b__\b_\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  _\b__\b_w\bwe\bea\bak\bkr\bre\bef\bf_\b__\b_\n"," |      list of weak references to the object (if defined)\n","\n","None\n","<class 'cogmen.Coach.Coach'>\n","train epoch 1: 100% 4/4 [00:03<00:00,  1.07it/s]\n","10/31/2023 09:20:51 \n","10/31/2023 09:20:51 [Epoch 1] [Loss: 5.485973] [Time: 3.745893]\n","dev: 100% 1/1 [00:00<00:00,  1.58it/s]\n","test: 100% 1/1 [00:01<00:00,  1.34s/it]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","         hap     0.0000    0.0000    0.0000       144\n","         sad     0.4615    0.7592    0.5741       245\n","         neu     0.4944    0.3438    0.4055       384\n","         ang     0.4579    0.7353    0.5643       170\n","\n","    accuracy                         0.4698       943\n","   macro avg     0.3534    0.4596    0.3860       943\n","weighted avg     0.4038    0.4698    0.4160       943\n","\n","10/31/2023 09:20:53 [Dev set] [f1 0.4467]\n","10/31/2023 09:20:55 Save the best model.\n","10/31/2023 09:20:55 [Test set] [f1 0.4160]\n","train epoch 2: 100% 4/4 [00:02<00:00,  1.98it/s]\n","10/31/2023 09:20:57 \n","10/31/2023 09:20:57 [Epoch 2] [Loss: 5.065208] [Time: 2.026025]\n","dev: 100% 1/1 [00:00<00:00,  1.85it/s]\n","test: 100% 1/1 [00:01<00:00,  1.12s/it]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","              precision    recall  f1-score   support\n","\n","         hap     0.0000    0.0000    0.0000       144\n","         sad     0.5225    0.9020    0.6617       245\n","         neu     0.6893    0.5026    0.5813       384\n","         ang     0.5833    0.8235    0.6829       170\n","\n","    accuracy                         0.5875       943\n","   macro avg     0.4488    0.5570    0.4815       943\n","weighted avg     0.5216    0.5875    0.5317       943\n","\n","10/31/2023 09:20:58 [Dev set] [f1 0.4783]\n","10/31/2023 09:20:59 Save the best model.\n","10/31/2023 09:20:59 [Test set] [f1 0.5317]\n","train epoch 3: 100% 4/4 [00:02<00:00,  1.70it/s]\n","10/31/2023 09:21:01 \n","10/31/2023 09:21:01 [Epoch 3] [Loss: 4.722545] [Time: 2.348708]\n","dev: 100% 1/1 [00:00<00:00,  2.21it/s]\n","test: 100% 1/1 [00:01<00:00,  1.02s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8095    0.1181    0.2061       144\n","         sad     0.5882    0.8980    0.7108       245\n","         neu     0.7143    0.6120    0.6592       384\n","         ang     0.6667    0.8588    0.7506       170\n","\n","    accuracy                         0.6554       943\n","   macro avg     0.6947    0.6217    0.5817       943\n","weighted avg     0.6875    0.6554    0.6199       943\n","\n","10/31/2023 09:21:03 [Dev set] [f1 0.5342]\n","10/31/2023 09:21:03 Save the best model.\n","10/31/2023 09:21:03 [Test set] [f1 0.6199]\n","train epoch 4: 100% 4/4 [00:02<00:00,  1.48it/s]\n","10/31/2023 09:21:06 \n","10/31/2023 09:21:06 [Epoch 4] [Loss: 4.512614] [Time: 2.706495]\n","dev: 100% 1/1 [00:00<00:00,  1.70it/s]\n","test: 100% 1/1 [00:01<00:00,  1.53s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8750    0.2431    0.3804       144\n","         sad     0.6588    0.9061    0.7629       245\n","         neu     0.7713    0.6849    0.7255       384\n","         ang     0.6667    0.8824    0.7595       170\n","\n","    accuracy                         0.7105       943\n","   macro avg     0.7429    0.6791    0.6571       943\n","weighted avg     0.7390    0.7105    0.6887       943\n","\n","10/31/2023 09:21:08 [Dev set] [f1 0.5831]\n","10/31/2023 09:21:08 Save the best model.\n","10/31/2023 09:21:08 [Test set] [f1 0.6887]\n","train epoch 5: 100% 4/4 [00:02<00:00,  1.77it/s]\n","10/31/2023 09:21:10 \n","10/31/2023 09:21:10 [Epoch 5] [Loss: 4.334744] [Time: 2.263045]\n","dev: 100% 1/1 [00:00<00:00,  2.33it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.9057    0.3333    0.4873       144\n","         sad     0.6873    0.9061    0.7817       245\n","         neu     0.8042    0.7057    0.7517       384\n","         ang     0.6565    0.8882    0.7550       170\n","\n","    accuracy                         0.7338       943\n","   macro avg     0.7634    0.7084    0.6939       943\n","weighted avg     0.7627    0.7338    0.7197       943\n","\n","10/31/2023 09:21:12 [Dev set] [f1 0.6025]\n","10/31/2023 09:21:12 Save the best model.\n","10/31/2023 09:21:12 [Test set] [f1 0.7197]\n","train epoch 6: 100% 4/4 [00:01<00:00,  2.00it/s]\n","10/31/2023 09:21:14 \n","10/31/2023 09:21:14 [Epoch 6] [Loss: 4.250768] [Time: 1.999842]\n","dev: 100% 1/1 [00:00<00:00,  2.37it/s]\n","test: 100% 1/1 [00:00<00:00,  1.00it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.9254    0.4306    0.5877       144\n","         sad     0.6981    0.8776    0.7776       245\n","         neu     0.8328    0.7005    0.7610       384\n","         ang     0.6204    0.8941    0.7325       170\n","\n","    accuracy                         0.7402       943\n","   macro avg     0.7692    0.7257    0.7147       943\n","weighted avg     0.7736    0.7402    0.7337       943\n","\n","10/31/2023 09:21:16 [Dev set] [f1 0.6501]\n","10/31/2023 09:21:16 Save the best model.\n","10/31/2023 09:21:16 [Test set] [f1 0.7337]\n","train epoch 7: 100% 4/4 [00:02<00:00,  1.97it/s]\n","10/31/2023 09:21:18 \n","10/31/2023 09:21:18 [Epoch 7] [Loss: 4.094480] [Time: 2.028975]\n","dev: 100% 1/1 [00:00<00:00,  2.31it/s]\n","test: 100% 1/1 [00:01<00:00,  1.10s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8714    0.4236    0.5701       144\n","         sad     0.6636    0.8939    0.7617       245\n","         neu     0.8669    0.6953    0.7717       384\n","         ang     0.6426    0.8882    0.7457       170\n","\n","    accuracy                         0.7402       943\n","   macro avg     0.7611    0.7253    0.7123       943\n","weighted avg     0.7743    0.7402    0.7336       943\n","\n","10/31/2023 09:21:20 [Dev set] [f1 0.7043]\n","10/31/2023 09:21:20 Save the best model.\n","10/31/2023 09:21:20 [Test set] [f1 0.7336]\n","train epoch 8: 100% 4/4 [00:03<00:00,  1.17it/s]\n","10/31/2023 09:21:23 \n","10/31/2023 09:21:23 [Epoch 8] [Loss: 3.915373] [Time: 3.408597]\n","dev: 100% 1/1 [00:00<00:00,  1.03it/s]\n","test: 100% 1/1 [00:01<00:00,  1.56s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8750    0.5347    0.6638       144\n","         sad     0.6980    0.8490    0.7661       245\n","         neu     0.8374    0.7109    0.7690       384\n","         ang     0.6494    0.8824    0.7481       170\n","\n","    accuracy                         0.7508       943\n","   macro avg     0.7649    0.7442    0.7368       943\n","weighted avg     0.7730    0.7508    0.7484       943\n","\n","10/31/2023 09:21:26 [Dev set] [f1 0.7039]\n","10/31/2023 09:21:26 [Test set] [f1 0.7484]\n","train epoch 9: 100% 4/4 [00:02<00:00,  1.60it/s]\n","10/31/2023 09:21:28 \n","10/31/2023 09:21:28 [Epoch 9] [Loss: 3.958775] [Time: 2.507077]\n","dev: 100% 1/1 [00:00<00:00,  2.09it/s]\n","test: 100% 1/1 [00:00<00:00,  1.01it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8434    0.4861    0.6167       144\n","         sad     0.6785    0.8612    0.7590       245\n","         neu     0.8323    0.7240    0.7744       384\n","         ang     0.6930    0.8765    0.7740       170\n","\n","    accuracy                         0.7508       943\n","   macro avg     0.7618    0.7369    0.7310       943\n","weighted avg     0.7689    0.7508    0.7462       943\n","\n","10/31/2023 09:21:30 [Dev set] [f1 0.7083]\n","10/31/2023 09:21:30 Save the best model.\n","10/31/2023 09:21:30 [Test set] [f1 0.7462]\n","train epoch 10: 100% 4/4 [00:02<00:00,  1.93it/s]\n","10/31/2023 09:21:32 \n","10/31/2023 09:21:32 [Epoch 10] [Loss: 3.638844] [Time: 2.068248]\n","dev: 100% 1/1 [00:00<00:00,  2.31it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8837    0.5278    0.6609       144\n","         sad     0.6964    0.8612    0.7701       245\n","         neu     0.8338    0.7448    0.7868       384\n","         ang     0.7014    0.8706    0.7769       170\n","\n","    accuracy                         0.7646       943\n","   macro avg     0.7788    0.7511    0.7487       943\n","weighted avg     0.7819    0.7646    0.7614       943\n","\n","10/31/2023 09:21:34 [Dev set] [f1 0.7220]\n","10/31/2023 09:21:34 Save the best model.\n","10/31/2023 09:21:34 [Test set] [f1 0.7614]\n","train epoch 11: 100% 4/4 [00:02<00:00,  1.96it/s]\n","10/31/2023 09:21:36 \n","10/31/2023 09:21:36 [Epoch 11] [Loss: 3.575672] [Time: 2.045111]\n","dev: 100% 1/1 [00:00<00:00,  1.68it/s]\n","test: 100% 1/1 [00:01<00:00,  1.39s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8681    0.5486    0.6723       144\n","         sad     0.7061    0.9020    0.7921       245\n","         neu     0.8550    0.7370    0.7916       384\n","         ang     0.7163    0.8765    0.7884       170\n","\n","    accuracy                         0.7762       943\n","   macro avg     0.7864    0.7660    0.7611       943\n","weighted avg     0.7933    0.7762    0.7729       943\n","\n","10/31/2023 09:21:38 [Dev set] [f1 0.7538]\n","10/31/2023 09:21:38 Save the best model.\n","10/31/2023 09:21:38 [Test set] [f1 0.7729]\n","train epoch 12: 100% 4/4 [00:02<00:00,  1.44it/s]\n","10/31/2023 09:21:41 \n","10/31/2023 09:21:41 [Epoch 12] [Loss: 3.471027] [Time: 2.780745]\n","dev: 100% 1/1 [00:00<00:00,  1.57it/s]\n","test: 100% 1/1 [00:01<00:00,  1.15s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8587    0.5486    0.6695       144\n","         sad     0.7094    0.9265    0.8035       245\n","         neu     0.8742    0.7240    0.7920       384\n","         ang     0.7089    0.8882    0.7885       170\n","\n","    accuracy                         0.7794       943\n","   macro avg     0.7878    0.7718    0.7634       943\n","weighted avg     0.7992    0.7794    0.7757       943\n","\n","10/31/2023 09:21:43 [Dev set] [f1 0.7470]\n","10/31/2023 09:21:43 [Test set] [f1 0.7757]\n","train epoch 13: 100% 4/4 [00:01<00:00,  2.02it/s]\n","10/31/2023 09:21:45 \n","10/31/2023 09:21:45 [Epoch 13] [Loss: 3.348835] [Time: 1.978822]\n","dev: 100% 1/1 [00:00<00:00,  2.38it/s]\n","test: 100% 1/1 [00:01<00:00,  1.10s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8602    0.5556    0.6751       144\n","         sad     0.7166    0.8980    0.7971       245\n","         neu     0.8571    0.7344    0.7910       384\n","         ang     0.7056    0.8882    0.7865       170\n","\n","    accuracy                         0.7773       943\n","   macro avg     0.7849    0.7690    0.7624       943\n","weighted avg     0.7938    0.7773    0.7741       943\n","\n","10/31/2023 09:21:47 [Dev set] [f1 0.7639]\n","10/31/2023 09:21:47 Save the best model.\n","10/31/2023 09:21:47 [Test set] [f1 0.7741]\n","train epoch 14: 100% 4/4 [00:02<00:00,  1.81it/s]\n","10/31/2023 09:21:49 \n","10/31/2023 09:21:49 [Epoch 14] [Loss: 3.342065] [Time: 2.214014]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7851    0.6597    0.7170       144\n","         sad     0.7474    0.8939    0.8141       245\n","         neu     0.8629    0.7214    0.7858       384\n","         ang     0.7260    0.8882    0.7989       170\n","\n","    accuracy                         0.7869       943\n","   macro avg     0.7804    0.7908    0.7790       943\n","weighted avg     0.7964    0.7869    0.7850       943\n","\n","10/31/2023 09:21:50 [Dev set] [f1 0.7851]\n","10/31/2023 09:21:51 Save the best model.\n","10/31/2023 09:21:51 [Test set] [f1 0.7850]\n","train epoch 15: 100% 4/4 [00:02<00:00,  1.60it/s]\n","10/31/2023 09:21:53 \n","10/31/2023 09:21:53 [Epoch 15] [Loss: 3.071570] [Time: 2.504369]\n","dev: 100% 1/1 [00:00<00:00,  1.66it/s]\n","test: 100% 1/1 [00:01<00:00,  1.47s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8182    0.6250    0.7087       144\n","         sad     0.7244    0.9224    0.8115       245\n","         neu     0.8861    0.7292    0.8000       384\n","         ang     0.7512    0.9059    0.8213       170\n","\n","    accuracy                         0.7953       943\n","   macro avg     0.7950    0.7956    0.7854       943\n","weighted avg     0.8094    0.7953    0.7929       943\n","\n","10/31/2023 09:21:55 [Dev set] [f1 0.7861]\n","10/31/2023 09:21:56 Save the best model.\n","10/31/2023 09:21:56 [Test set] [f1 0.7929]\n","train epoch 16: 100% 4/4 [00:02<00:00,  1.38it/s]\n","10/31/2023 09:21:59 \n","10/31/2023 09:21:59 [Epoch 16] [Loss: 3.002695] [Time: 2.902447]\n","dev: 100% 1/1 [00:00<00:00,  2.21it/s]\n","test: 100% 1/1 [00:01<00:00,  1.02s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8571    0.6250    0.7229       144\n","         sad     0.7278    0.9388    0.8200       245\n","         neu     0.8907    0.7214    0.7971       384\n","         ang     0.7346    0.9118    0.8136       170\n","\n","    accuracy                         0.7975       943\n","   macro avg     0.8026    0.7992    0.7884       943\n","weighted avg     0.8151    0.7975    0.7947       943\n","\n","10/31/2023 09:22:00 [Dev set] [f1 0.7761]\n","10/31/2023 09:22:00 [Test set] [f1 0.7947]\n","train epoch 17: 100% 4/4 [00:02<00:00,  1.98it/s]\n","10/31/2023 09:22:02 \n","10/31/2023 09:22:02 [Epoch 17] [Loss: 2.893081] [Time: 2.019169]\n","dev: 100% 1/1 [00:00<00:00,  1.83it/s]\n","test: 100% 1/1 [00:01<00:00,  1.24s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7744    0.7153    0.7437       144\n","         sad     0.7524    0.9429    0.8370       245\n","         neu     0.8960    0.6953    0.7830       384\n","         ang     0.7463    0.9000    0.8160       170\n","\n","    accuracy                         0.7996       943\n","   macro avg     0.7923    0.8134    0.7949       943\n","weighted avg     0.8131    0.7996    0.7970       943\n","\n","10/31/2023 09:22:04 [Dev set] [f1 0.7961]\n","10/31/2023 09:22:04 Save the best model.\n","10/31/2023 09:22:04 [Test set] [f1 0.7970]\n","train epoch 18: 100% 4/4 [00:01<00:00,  2.03it/s]\n","10/31/2023 09:22:06 \n","10/31/2023 09:22:06 [Epoch 18] [Loss: 2.847215] [Time: 1.975584]\n","dev: 100% 1/1 [00:00<00:00,  2.17it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8361    0.7083    0.7669       144\n","         sad     0.8080    0.9102    0.8560       245\n","         neu     0.8815    0.7943    0.8356       384\n","         ang     0.7990    0.9353    0.8618       170\n","\n","    accuracy                         0.8367       943\n","   macro avg     0.8311    0.8370    0.8301       943\n","weighted avg     0.8406    0.8367    0.8352       943\n","\n","10/31/2023 09:22:08 [Dev set] [f1 0.7694]\n","10/31/2023 09:22:08 [Test set] [f1 0.8352]\n","train epoch 19: 100% 4/4 [00:02<00:00,  1.74it/s]\n","10/31/2023 09:22:10 \n","10/31/2023 09:22:10 [Epoch 19] [Loss: 2.712572] [Time: 2.300108]\n","dev: 100% 1/1 [00:00<00:00,  1.68it/s]\n","test: 100% 1/1 [00:01<00:00,  1.39s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7482    0.7222    0.7350       144\n","         sad     0.7897    0.9347    0.8561       245\n","         neu     0.9014    0.6667    0.7665       384\n","         ang     0.7000    0.9471    0.8050       170\n","\n","    accuracy                         0.7953       943\n","   macro avg     0.7848    0.8177    0.7906       943\n","weighted avg     0.8127    0.7953    0.7919       943\n","\n","10/31/2023 09:22:12 [Dev set] [f1 0.7650]\n","10/31/2023 09:22:12 [Test set] [f1 0.7919]\n","train epoch 20: 100% 4/4 [00:02<00:00,  1.42it/s]\n","10/31/2023 09:22:15 \n","10/31/2023 09:22:15 [Epoch 20] [Loss: 2.700839] [Time: 2.811180]\n","dev: 100% 1/1 [00:00<00:00,  1.52it/s]\n","test: 100% 1/1 [00:01<00:00,  1.12s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7721    0.7292    0.7500       144\n","         sad     0.7917    0.9306    0.8555       245\n","         neu     0.8926    0.7578    0.8197       384\n","         ang     0.8031    0.9118    0.8540       170\n","\n","    accuracy                         0.8261       943\n","   macro avg     0.8149    0.8323    0.8198       943\n","weighted avg     0.8319    0.8261    0.8246       943\n","\n","10/31/2023 09:22:17 [Dev set] [f1 0.7781]\n","10/31/2023 09:22:17 [Test set] [f1 0.8246]\n","train epoch 21: 100% 4/4 [00:02<00:00,  1.78it/s]\n","10/31/2023 09:22:19 \n","10/31/2023 09:22:19 [Epoch 21] [Loss: 2.589568] [Time: 2.250434]\n","dev: 100% 1/1 [00:00<00:00,  2.37it/s]\n","test: 100% 1/1 [00:01<00:00,  1.11s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8305    0.6806    0.7481       144\n","         sad     0.8295    0.8939    0.8605       245\n","         neu     0.8687    0.7578    0.8095       384\n","         ang     0.7168    0.9529    0.8182       170\n","\n","    accuracy                         0.8165       943\n","   macro avg     0.8114    0.8213    0.8091       943\n","weighted avg     0.8253    0.8165    0.8149       943\n","\n","10/31/2023 09:22:20 [Dev set] [f1 0.7368]\n","10/31/2023 09:22:20 [Test set] [f1 0.8149]\n","train epoch 22: 100% 4/4 [00:02<00:00,  1.76it/s]\n","10/31/2023 09:22:23 \n","10/31/2023 09:22:23 [Epoch 22] [Loss: 2.378282] [Time: 2.268680]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7297    0.7500    0.7397       144\n","         sad     0.7973    0.9469    0.8657       245\n","         neu     0.9158    0.6797    0.7803       384\n","         ang     0.7306    0.9412    0.8226       170\n","\n","    accuracy                         0.8070       943\n","   macro avg     0.7933    0.8295    0.8021       943\n","weighted avg     0.8232    0.8070    0.8039       943\n","\n","10/31/2023 09:22:24 [Dev set] [f1 0.7987]\n","10/31/2023 09:22:24 Save the best model.\n","10/31/2023 09:22:24 [Test set] [f1 0.8039]\n","train epoch 23: 100% 4/4 [00:02<00:00,  1.58it/s]\n","10/31/2023 09:22:27 \n","10/31/2023 09:22:27 [Epoch 23] [Loss: 2.215518] [Time: 2.527370]\n","dev: 100% 1/1 [00:00<00:00,  1.70it/s]\n","test: 100% 1/1 [00:01<00:00,  1.43s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7639    0.7639    0.7639       144\n","         sad     0.8675    0.8816    0.8745       245\n","         neu     0.8595    0.8125    0.8353       384\n","         ang     0.8342    0.9176    0.8739       170\n","\n","    accuracy                         0.8420       943\n","   macro avg     0.8313    0.8439    0.8369       943\n","weighted avg     0.8424    0.8420    0.8416       943\n","\n","10/31/2023 09:22:29 [Dev set] [f1 0.7796]\n","10/31/2023 09:22:29 [Test set] [f1 0.8416]\n","train epoch 24: 100% 4/4 [00:02<00:00,  1.46it/s]\n","10/31/2023 09:22:32 \n","10/31/2023 09:22:32 [Epoch 24] [Loss: 2.215110] [Time: 2.744878]\n","dev: 100% 1/1 [00:00<00:00,  1.96it/s]\n","test: 100% 1/1 [00:01<00:00,  1.19s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7698    0.6736    0.7185       144\n","         sad     0.7662    0.9633    0.8535       245\n","         neu     0.9234    0.6276    0.7473       384\n","         ang     0.6452    0.9412    0.7656       170\n","\n","    accuracy                         0.7784       943\n","   macro avg     0.7762    0.8014    0.7712       943\n","weighted avg     0.8089    0.7784    0.7738       943\n","\n","10/31/2023 09:22:33 [Dev set] [f1 0.7230]\n","10/31/2023 09:22:33 [Test set] [f1 0.7738]\n","train epoch 25: 100% 4/4 [00:02<00:00,  1.94it/s]\n","10/31/2023 09:22:36 \n","10/31/2023 09:22:36 [Epoch 25] [Loss: 2.063399] [Time: 2.057311]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.04it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7616    0.7986    0.7797       144\n","         sad     0.8659    0.8694    0.8676       245\n","         neu     0.8693    0.7969    0.8315       384\n","         ang     0.7990    0.9118    0.8516       170\n","\n","    accuracy                         0.8367       943\n","   macro avg     0.8239    0.8442    0.8326       943\n","weighted avg     0.8393    0.8367    0.8366       943\n","\n","10/31/2023 09:22:37 [Dev set] [f1 0.8184]\n","10/31/2023 09:22:37 Save the best model.\n","10/31/2023 09:22:37 [Test set] [f1 0.8366]\n","train epoch 26: 100% 4/4 [00:02<00:00,  1.75it/s]\n","10/31/2023 09:22:40 \n","10/31/2023 09:22:40 [Epoch 26] [Loss: 2.080642] [Time: 2.290724]\n","dev: 100% 1/1 [00:00<00:00,  2.36it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7267    0.8125    0.7672       144\n","         sad     0.8255    0.9265    0.8731       245\n","         neu     0.9198    0.6276    0.7461       384\n","         ang     0.6531    0.9412    0.7711       170\n","\n","    accuracy                         0.7900       943\n","   macro avg     0.7813    0.8270    0.7894       943\n","weighted avg     0.8177    0.7900    0.7868       943\n","\n","10/31/2023 09:22:41 [Dev set] [f1 0.7815]\n","10/31/2023 09:22:41 [Test set] [f1 0.7868]\n","train epoch 27: 100% 4/4 [00:02<00:00,  1.62it/s]\n","10/31/2023 09:22:43 \n","10/31/2023 09:22:43 [Epoch 27] [Loss: 1.879795] [Time: 2.463485]\n","dev: 100% 1/1 [00:00<00:00,  1.66it/s]\n","test: 100% 1/1 [00:01<00:00,  1.46s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8049    0.6875    0.7416       144\n","         sad     0.8510    0.8857    0.8680       245\n","         neu     0.8338    0.7839    0.8081       384\n","         ang     0.7647    0.9176    0.8342       170\n","\n","    accuracy                         0.8197       943\n","   macro avg     0.8136    0.8187    0.8130       943\n","weighted avg     0.8214    0.8197    0.8182       943\n","\n","10/31/2023 09:22:45 [Dev set] [f1 0.7532]\n","10/31/2023 09:22:45 [Test set] [f1 0.8182]\n","train epoch 28: 100% 4/4 [00:02<00:00,  1.38it/s]\n","10/31/2023 09:22:48 \n","10/31/2023 09:22:48 [Epoch 28] [Loss: 1.816667] [Time: 2.901697]\n","dev: 100% 1/1 [00:00<00:00,  2.02it/s]\n","test: 100% 1/1 [00:01<00:00,  1.14s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7769    0.7014    0.7372       144\n","         sad     0.8084    0.9469    0.8722       245\n","         neu     0.8795    0.7031    0.7815       384\n","         ang     0.7169    0.9235    0.8072       170\n","\n","    accuracy                         0.8059       943\n","   macro avg     0.7954    0.8187    0.7995       943\n","weighted avg     0.8160    0.8059    0.8029       943\n","\n","10/31/2023 09:22:50 [Dev set] [f1 0.7580]\n","10/31/2023 09:22:50 [Test set] [f1 0.8029]\n","train epoch 29: 100% 4/4 [00:02<00:00,  1.95it/s]\n","10/31/2023 09:22:52 \n","10/31/2023 09:22:52 [Epoch 29] [Loss: 1.796508] [Time: 2.054499]\n","dev: 100% 1/1 [00:00<00:00,  2.29it/s]\n","test: 100% 1/1 [00:01<00:00,  1.01s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7584    0.7847    0.7713       144\n","         sad     0.8852    0.8816    0.8834       245\n","         neu     0.8514    0.7760    0.8120       384\n","         ang     0.7800    0.9176    0.8432       170\n","\n","    accuracy                         0.8303       943\n","   macro avg     0.8188    0.8400    0.8275       943\n","weighted avg     0.8331    0.8303    0.8300       943\n","\n","10/31/2023 09:22:54 [Dev set] [f1 0.7963]\n","10/31/2023 09:22:54 [Test set] [f1 0.8300]\n","train epoch 30: 100% 4/4 [00:01<00:00,  2.01it/s]\n","10/31/2023 09:22:55 \n","10/31/2023 09:22:55 [Epoch 30] [Loss: 1.742404] [Time: 1.987719]\n","dev: 100% 1/1 [00:00<00:00,  2.31it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7823    0.7986    0.7904       144\n","         sad     0.8534    0.9265    0.8885       245\n","         neu     0.8875    0.7188    0.7942       384\n","         ang     0.7260    0.9353    0.8175       170\n","\n","    accuracy                         0.8240       943\n","   macro avg     0.8123    0.8448    0.8226       943\n","weighted avg     0.8334    0.8240    0.8223       943\n","\n","10/31/2023 09:22:57 [Dev set] [f1 0.7886]\n","10/31/2023 09:22:57 [Test set] [f1 0.8223]\n","train epoch 31: 100% 4/4 [00:02<00:00,  1.47it/s]\n","10/31/2023 09:23:00 \n","10/31/2023 09:23:00 [Epoch 31] [Loss: 1.670415] [Time: 2.722475]\n","dev: 100% 1/1 [00:00<00:00,  1.66it/s]\n","test: 100% 1/1 [00:01<00:00,  1.42s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8264    0.6944    0.7547       144\n","         sad     0.8340    0.9020    0.8667       245\n","         neu     0.8387    0.7448    0.7890       384\n","         ang     0.7315    0.9294    0.8187       170\n","\n","    accuracy                         0.8112       943\n","   macro avg     0.8076    0.8177    0.8073       943\n","weighted avg     0.8163    0.8112    0.8093       943\n","\n","10/31/2023 09:23:02 [Dev set] [f1 0.7935]\n","10/31/2023 09:23:02 [Test set] [f1 0.8093]\n","train epoch 32: 100% 4/4 [00:02<00:00,  1.43it/s]\n","10/31/2023 09:23:04 \n","10/31/2023 09:23:04 [Epoch 32] [Loss: 1.445690] [Time: 2.804863]\n","dev: 100% 1/1 [00:00<00:00,  2.29it/s]\n","test: 100% 1/1 [00:01<00:00,  1.06s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7736    0.8542    0.8119       144\n","         sad     0.8824    0.9184    0.9000       245\n","         neu     0.8862    0.7708    0.8245       384\n","         ang     0.7897    0.9059    0.8438       170\n","\n","    accuracy                         0.8462       943\n","   macro avg     0.8330    0.8623    0.8451       943\n","weighted avg     0.8506    0.8462    0.8457       943\n","\n","10/31/2023 09:23:06 [Dev set] [f1 0.8208]\n","10/31/2023 09:23:06 Save the best model.\n","10/31/2023 09:23:06 [Test set] [f1 0.8457]\n","train epoch 33: 100% 4/4 [00:02<00:00,  1.96it/s]\n","10/31/2023 09:23:08 \n","10/31/2023 09:23:08 [Epoch 33] [Loss: 1.439714] [Time: 2.045932]\n","dev: 100% 1/1 [00:00<00:00,  2.40it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8015    0.7569    0.7786       144\n","         sad     0.8814    0.9102    0.8956       245\n","         neu     0.8512    0.8047    0.8273       384\n","         ang     0.8063    0.9059    0.8532       170\n","\n","    accuracy                         0.8431       943\n","   macro avg     0.8351    0.8444    0.8387       943\n","weighted avg     0.8434    0.8431    0.8423       943\n","\n","10/31/2023 09:23:10 [Dev set] [f1 0.8204]\n","10/31/2023 09:23:10 [Test set] [f1 0.8423]\n","train epoch 34: 100% 4/4 [00:02<00:00,  1.97it/s]\n","10/31/2023 09:23:12 \n","10/31/2023 09:23:12 [Epoch 34] [Loss: 1.376472] [Time: 2.032723]\n","dev: 100% 1/1 [00:00<00:00,  2.35it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7296    0.8056    0.7657       144\n","         sad     0.7911    0.9429    0.8603       245\n","         neu     0.8863    0.5885    0.7074       384\n","         ang     0.6624    0.9235    0.7715       170\n","\n","    accuracy                         0.7741       943\n","   macro avg     0.7673    0.8151    0.7762       943\n","weighted avg     0.7973    0.7741    0.7676       943\n","\n","10/31/2023 09:23:13 [Dev set] [f1 0.7598]\n","10/31/2023 09:23:13 [Test set] [f1 0.7676]\n","train epoch 35: 100% 4/4 [00:02<00:00,  1.71it/s]\n","10/31/2023 09:23:16 \n","10/31/2023 09:23:16 [Epoch 35] [Loss: 1.553746] [Time: 2.334206]\n","dev: 100% 1/1 [00:00<00:00,  1.67it/s]\n","test: 100% 1/1 [00:01<00:00,  1.65s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7664    0.5694    0.6534       144\n","         sad     0.9255    0.7102    0.8037       245\n","         neu     0.7432    0.8516    0.7937       384\n","         ang     0.7500    0.9176    0.8254       170\n","\n","    accuracy                         0.7837       943\n","   macro avg     0.7963    0.7622    0.7690       943\n","weighted avg     0.7953    0.7837    0.7806       943\n","\n","10/31/2023 09:23:18 [Dev set] [f1 0.7905]\n","10/31/2023 09:23:18 [Test set] [f1 0.7806]\n","train epoch 36: 100% 4/4 [00:02<00:00,  1.34it/s]\n","10/31/2023 09:23:21 \n","10/31/2023 09:23:21 [Epoch 36] [Loss: 1.306985] [Time: 2.996627]\n","dev: 100% 1/1 [00:00<00:00,  2.28it/s]\n","test: 100% 1/1 [00:01<00:00,  1.27s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7427    0.8819    0.8063       144\n","         sad     0.8185    0.9388    0.8745       245\n","         neu     0.9347    0.5964    0.7281       384\n","         ang     0.6585    0.9529    0.7788       170\n","\n","    accuracy                         0.7932       943\n","   macro avg     0.7886    0.8425    0.7970       943\n","weighted avg     0.8254    0.7932    0.7873       943\n","\n","10/31/2023 09:23:23 [Dev set] [f1 0.7857]\n","10/31/2023 09:23:23 [Test set] [f1 0.7873]\n","train epoch 37: 100% 4/4 [00:02<00:00,  1.99it/s]\n","10/31/2023 09:23:25 \n","10/31/2023 09:23:25 [Epoch 37] [Loss: 1.339264] [Time: 2.008094]\n","dev: 100% 1/1 [00:00<00:00,  2.37it/s]\n","test: 100% 1/1 [00:00<00:00,  1.05it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7595    0.8333    0.7947       144\n","         sad     0.8077    0.9429    0.8701       245\n","         neu     0.8991    0.7422    0.8131       384\n","         ang     0.8187    0.8765    0.8466       170\n","\n","    accuracy                         0.8324       943\n","   macro avg     0.8212    0.8487    0.8311       943\n","weighted avg     0.8395    0.8324    0.8311       943\n","\n","10/31/2023 09:23:26 [Dev set] [f1 0.8126]\n","10/31/2023 09:23:26 [Test set] [f1 0.8311]\n","train epoch 38: 100% 4/4 [00:02<00:00,  2.00it/s]\n","10/31/2023 09:23:28 \n","10/31/2023 09:23:28 [Epoch 38] [Loss: 1.134376] [Time: 2.004397]\n","dev: 100% 1/1 [00:00<00:00,  2.34it/s]\n","test: 100% 1/1 [00:00<00:00,  1.03it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8364    0.6389    0.7244       144\n","         sad     0.9171    0.8122    0.8615       245\n","         neu     0.7786    0.8151    0.7964       384\n","         ang     0.7383    0.9294    0.8229       170\n","\n","    accuracy                         0.8081       943\n","   macro avg     0.8176    0.7989    0.8013       943\n","weighted avg     0.8161    0.8081    0.8071       943\n","\n","10/31/2023 09:23:29 [Dev set] [f1 0.8002]\n","10/31/2023 09:23:29 [Test set] [f1 0.8071]\n","train epoch 39: 100% 4/4 [00:02<00:00,  1.82it/s]\n","10/31/2023 09:23:32 \n","10/31/2023 09:23:32 [Epoch 39] [Loss: 1.108405] [Time: 2.196074]\n","dev: 100% 1/1 [00:00<00:00,  1.66it/s]\n","test: 100% 1/1 [00:01<00:00,  1.41s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7400    0.7708    0.7551       144\n","         sad     0.8543    0.8857    0.8697       245\n","         neu     0.8421    0.7083    0.7694       384\n","         ang     0.7269    0.9235    0.8135       170\n","\n","    accuracy                         0.8028       943\n","   macro avg     0.7908    0.8221    0.8019       943\n","weighted avg     0.8089    0.8028    0.8013       943\n","\n","10/31/2023 09:23:34 [Dev set] [f1 0.8146]\n","10/31/2023 09:23:34 [Test set] [f1 0.8013]\n","train epoch 40: 100% 4/4 [00:02<00:00,  1.41it/s]\n","10/31/2023 09:23:36 \n","10/31/2023 09:23:36 [Epoch 40] [Loss: 1.186089] [Time: 2.839572]\n","dev: 100% 1/1 [00:00<00:00,  1.52it/s]\n","test: 100% 1/1 [00:01<00:00,  1.05s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7593    0.8542    0.8039       144\n","         sad     0.8605    0.9061    0.8827       245\n","         neu     0.8875    0.7188    0.7942       384\n","         ang     0.7547    0.9412    0.8377       170\n","\n","    accuracy                         0.8282       943\n","   macro avg     0.8155    0.8551    0.8296       943\n","weighted avg     0.8369    0.8282    0.8265       943\n","\n","10/31/2023 09:23:38 [Dev set] [f1 0.8384]\n","10/31/2023 09:23:38 Save the best model.\n","10/31/2023 09:23:38 [Test set] [f1 0.8265]\n","train epoch 41: 100% 4/4 [00:02<00:00,  1.96it/s]\n","10/31/2023 09:23:40 \n","10/31/2023 09:23:40 [Epoch 41] [Loss: 1.141781] [Time: 2.038670]\n","dev: 100% 1/1 [00:00<00:00,  2.30it/s]\n","test: 100% 1/1 [00:01<00:00,  1.03s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7044    0.7778    0.7393       144\n","         sad     0.8783    0.8245    0.8505       245\n","         neu     0.8302    0.6875    0.7521       384\n","         ang     0.6907    0.9588    0.8030       170\n","\n","    accuracy                         0.7858       943\n","   macro avg     0.7759    0.8121    0.7862       943\n","weighted avg     0.7983    0.7858    0.7849       943\n","\n","10/31/2023 09:23:42 [Dev set] [f1 0.8043]\n","10/31/2023 09:23:42 [Test set] [f1 0.7849]\n","train epoch 42: 100% 4/4 [00:01<00:00,  2.01it/s]\n","10/31/2023 09:23:44 \n","10/31/2023 09:23:44 [Epoch 42] [Loss: 0.949338] [Time: 1.991472]\n","dev: 100% 1/1 [00:00<00:00,  2.29it/s]\n","test: 100% 1/1 [00:01<00:00,  1.24s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7718    0.7986    0.7850       144\n","         sad     0.7797    0.9102    0.8399       245\n","         neu     0.8684    0.6875    0.7674       384\n","         ang     0.7647    0.9176    0.8342       170\n","\n","    accuracy                         0.8038       943\n","   macro avg     0.7962    0.8285    0.8066       943\n","weighted avg     0.8119    0.8038    0.8010       943\n","\n","10/31/2023 09:23:46 [Dev set] [f1 0.8317]\n","10/31/2023 09:23:46 [Test set] [f1 0.8010]\n","train epoch 43: 100% 4/4 [00:02<00:00,  1.85it/s]\n","10/31/2023 09:23:48 \n","10/31/2023 09:23:48 [Epoch 43] [Loss: 0.897477] [Time: 2.167611]\n","dev: 100% 1/1 [00:00<00:00,  1.63it/s]\n","test: 100% 1/1 [00:01<00:00,  1.57s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7537    0.7014    0.7266       144\n","         sad     0.8063    0.8327    0.8193       245\n","         neu     0.8276    0.6250    0.7122       384\n","         ang     0.5977    0.9353    0.7294       170\n","\n","    accuracy                         0.7466       943\n","   macro avg     0.7463    0.7736    0.7469       943\n","weighted avg     0.7693    0.7466    0.7453       943\n","\n","10/31/2023 09:23:50 [Dev set] [f1 0.7706]\n","10/31/2023 09:23:50 [Test set] [f1 0.7453]\n","train epoch 44: 100% 4/4 [00:02<00:00,  1.34it/s]\n","10/31/2023 09:23:53 \n","10/31/2023 09:23:53 [Epoch 44] [Loss: 0.924314] [Time: 2.989008]\n","dev: 100% 1/1 [00:00<00:00,  1.52it/s]\n","test: 100% 1/1 [00:01<00:00,  1.09s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7385    0.6667    0.7007       144\n","         sad     0.8400    0.8571    0.8485       245\n","         neu     0.8059    0.7891    0.7974       384\n","         ang     0.8075    0.8882    0.8459       170\n","\n","    accuracy                         0.8059       943\n","   macro avg     0.7979    0.8003    0.7981       943\n","weighted avg     0.8047    0.8059    0.8046       943\n","\n","10/31/2023 09:23:55 [Dev set] [f1 0.8216]\n","10/31/2023 09:23:55 [Test set] [f1 0.8046]\n","train epoch 45: 100% 4/4 [00:02<00:00,  1.95it/s]\n","10/31/2023 09:23:57 \n","10/31/2023 09:23:57 [Epoch 45] [Loss: 0.872854] [Time: 2.056636]\n","dev: 100% 1/1 [00:00<00:00,  2.26it/s]\n","test: 100% 1/1 [00:01<00:00,  1.00s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.6404    0.7917    0.7081       144\n","         sad     0.8295    0.8735    0.8509       245\n","         neu     0.8451    0.6536    0.7372       384\n","         ang     0.7381    0.9118    0.8158       170\n","\n","    accuracy                         0.7784       943\n","   macro avg     0.7633    0.8076    0.7780       943\n","weighted avg     0.7905    0.7784    0.7764       943\n","\n","10/31/2023 09:23:58 [Dev set] [f1 0.7923]\n","10/31/2023 09:23:58 [Test set] [f1 0.7764]\n","train epoch 46: 100% 4/4 [00:01<00:00,  2.02it/s]\n","10/31/2023 09:24:00 \n","10/31/2023 09:24:00 [Epoch 46] [Loss: 0.784774] [Time: 1.980136]\n","dev: 100% 1/1 [00:00<00:00,  2.39it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7481    0.6806    0.7127       144\n","         sad     0.8333    0.8980    0.8644       245\n","         neu     0.8156    0.7370    0.7743       384\n","         ang     0.7662    0.9059    0.8302       170\n","\n","    accuracy                         0.8006       943\n","   macro avg     0.7908    0.8053    0.7954       943\n","weighted avg     0.8010    0.8006    0.7984       943\n","\n","10/31/2023 09:24:02 [Dev set] [f1 0.8081]\n","10/31/2023 09:24:02 [Test set] [f1 0.7984]\n","train epoch 47: 100% 4/4 [00:02<00:00,  2.00it/s]\n","10/31/2023 09:24:04 \n","10/31/2023 09:24:04 [Epoch 47] [Loss: 0.796525] [Time: 2.002015]\n","dev: 100% 1/1 [00:00<00:00,  1.95it/s]\n","test: 100% 1/1 [00:01<00:00,  1.37s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7770    0.7500    0.7633       144\n","         sad     0.8014    0.9388    0.8647       245\n","         neu     0.8602    0.7370    0.7938       384\n","         ang     0.7926    0.8765    0.8324       170\n","\n","    accuracy                         0.8165       943\n","   macro avg     0.8078    0.8256    0.8135       943\n","weighted avg     0.8200    0.8165    0.8145       943\n","\n","10/31/2023 09:24:06 [Dev set] [f1 0.8237]\n","10/31/2023 09:24:06 [Test set] [f1 0.8145]\n","train epoch 48: 100% 4/4 [00:02<00:00,  1.47it/s]\n","10/31/2023 09:24:08 \n","10/31/2023 09:24:08 [Epoch 48] [Loss: 0.862161] [Time: 2.717036]\n","dev: 100% 1/1 [00:00<00:00,  1.54it/s]\n","test: 100% 1/1 [00:01<00:00,  1.70s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7517    0.7778    0.7645       144\n","         sad     0.8783    0.8245    0.8505       245\n","         neu     0.8234    0.7891    0.8059       384\n","         ang     0.7755    0.8941    0.8306       170\n","\n","    accuracy                         0.8155       943\n","   macro avg     0.8072    0.8214    0.8129       943\n","weighted avg     0.8181    0.8155    0.8156       943\n","\n","10/31/2023 09:24:11 [Dev set] [f1 0.8496]\n","10/31/2023 09:24:11 Save the best model.\n","10/31/2023 09:24:11 [Test set] [f1 0.8156]\n","train epoch 49: 100% 4/4 [00:02<00:00,  1.93it/s]\n","10/31/2023 09:24:13 \n","10/31/2023 09:24:13 [Epoch 49] [Loss: 0.736406] [Time: 2.079085]\n","dev: 100% 1/1 [00:00<00:00,  2.29it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7294    0.8611    0.7898       144\n","         sad     0.8857    0.7592    0.8176       245\n","         neu     0.8439    0.6901    0.7593       384\n","         ang     0.6506    0.9529    0.7733       170\n","\n","    accuracy                         0.7815       943\n","   macro avg     0.7774    0.8158    0.7850       943\n","weighted avg     0.8025    0.7815    0.7816       943\n","\n","10/31/2023 09:24:14 [Dev set] [f1 0.8104]\n","10/31/2023 09:24:14 [Test set] [f1 0.7816]\n","train epoch 50: 100% 4/4 [00:02<00:00,  1.95it/s]\n","10/31/2023 09:24:17 \n","10/31/2023 09:24:17 [Epoch 50] [Loss: 0.646915] [Time: 2.048513]\n","dev: 100% 1/1 [00:00<00:00,  2.19it/s]\n","test: 100% 1/1 [00:01<00:00,  1.03s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7793    0.7847    0.7820       144\n","         sad     0.8465    0.8776    0.8617       245\n","         neu     0.8632    0.7396    0.7966       384\n","         ang     0.7442    0.9412    0.8312       170\n","\n","    accuracy                         0.8187       943\n","   macro avg     0.8083    0.8358    0.8179       943\n","weighted avg     0.8246    0.8187    0.8175       943\n","\n","10/31/2023 09:24:18 [Dev set] [f1 0.8182]\n","10/31/2023 09:24:18 [Test set] [f1 0.8175]\n","train epoch 51: 100% 4/4 [00:02<00:00,  1.98it/s]\n","10/31/2023 09:24:20 \n","10/31/2023 09:24:20 [Epoch 51] [Loss: 0.603729] [Time: 2.017393]\n","dev: 100% 1/1 [00:00<00:00,  2.02it/s]\n","test: 100% 1/1 [00:01<00:00,  1.68s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8014    0.7847    0.7930       144\n","         sad     0.8248    0.9224    0.8709       245\n","         neu     0.8818    0.6797    0.7676       384\n","         ang     0.6897    0.9412    0.7960       170\n","\n","    accuracy                         0.8059       943\n","   macro avg     0.7994    0.8320    0.8069       943\n","weighted avg     0.8201    0.8059    0.8035       943\n","\n","10/31/2023 09:24:22 [Dev set] [f1 0.8062]\n","10/31/2023 09:24:22 [Test set] [f1 0.8035]\n","train epoch 52: 100% 4/4 [00:02<00:00,  1.36it/s]\n","10/31/2023 09:24:25 \n","10/31/2023 09:24:25 [Epoch 52] [Loss: 0.621943] [Time: 2.945045]\n","dev: 100% 1/1 [00:00<00:00,  1.58it/s]\n","test: 100% 1/1 [00:01<00:00,  1.40s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.8099    0.6806    0.7396       144\n","         sad     0.8401    0.9224    0.8794       245\n","         neu     0.8290    0.7448    0.7846       384\n","         ang     0.7500    0.9176    0.8254       170\n","\n","    accuracy                         0.8123       943\n","   macro avg     0.8073    0.8164    0.8073       943\n","weighted avg     0.8147    0.8123    0.8097       943\n","\n","10/31/2023 09:24:27 [Dev set] [f1 0.8183]\n","10/31/2023 09:24:27 [Test set] [f1 0.8097]\n","train epoch 53: 100% 4/4 [00:01<00:00,  2.02it/s]\n","10/31/2023 09:24:29 \n","10/31/2023 09:24:29 [Epoch 53] [Loss: 0.600954] [Time: 1.984421]\n","dev: 100% 1/1 [00:00<00:00,  2.33it/s]\n","test: 100% 1/1 [00:00<00:00,  1.02it/s]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7212    0.8264    0.7702       144\n","         sad     0.8250    0.9429    0.8800       245\n","         neu     0.8741    0.6510    0.7463       384\n","         ang     0.7217    0.9000    0.8010       170\n","\n","    accuracy                         0.7985       943\n","   macro avg     0.7855    0.8301    0.7994       943\n","weighted avg     0.8105    0.7985    0.7945       943\n","\n","10/31/2023 09:24:31 [Dev set] [f1 0.8104]\n","10/31/2023 09:24:31 [Test set] [f1 0.7945]\n","train epoch 54: 100% 4/4 [00:01<00:00,  2.05it/s]\n","10/31/2023 09:24:33 \n","10/31/2023 09:24:33 [Epoch 54] [Loss: 0.528030] [Time: 1.955520]\n","dev: 100% 1/1 [00:00<00:00,  1.43it/s]\n","test: 100% 1/1 [00:01<00:00,  1.01s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7516    0.8403    0.7934       144\n","         sad     0.8333    0.9184    0.8738       245\n","         neu     0.8594    0.7161    0.7812       384\n","         ang     0.7760    0.8765    0.8232       170\n","\n","    accuracy                         0.8165       943\n","   macro avg     0.8051    0.8378    0.8179       943\n","weighted avg     0.8211    0.8165    0.8147       943\n","\n","10/31/2023 09:24:34 [Dev set] [f1 0.8153]\n","10/31/2023 09:24:34 [Test set] [f1 0.8147]\n","train epoch 55: 100% 4/4 [00:01<00:00,  2.01it/s]\n","10/31/2023 09:24:36 \n","10/31/2023 09:24:36 [Epoch 55] [Loss: 0.505878] [Time: 1.992935]\n","dev: 100% 1/1 [00:00<00:00,  2.35it/s]\n","test: 100% 1/1 [00:01<00:00,  1.28s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7500    0.7917    0.7703       144\n","         sad     0.8692    0.8408    0.8548       245\n","         neu     0.8309    0.7422    0.7840       384\n","         ang     0.7346    0.9118    0.8136       170\n","\n","    accuracy                         0.8059       943\n","   macro avg     0.7962    0.8216    0.8057       943\n","weighted avg     0.8111    0.8059    0.8057       943\n","\n","10/31/2023 09:24:38 [Dev set] [f1 0.8156]\n","10/31/2023 09:24:38 [Test set] [f1 0.8057]\n","10/31/2023 09:24:38 \n","10/31/2023 09:24:38 Best in epoch 48:\n","dev: 100% 1/1 [00:00<00:00,  1.58it/s]\n","10/31/2023 09:24:39 [Dev set] [f1 0.8496]\n","test: 100% 1/1 [00:01<00:00,  1.42s/it]\n","              precision    recall  f1-score   support\n","\n","         hap     0.7517    0.7778    0.7645       144\n","         sad     0.8783    0.8245    0.8505       245\n","         neu     0.8234    0.7891    0.8059       384\n","         ang     0.7755    0.8941    0.8306       170\n","\n","    accuracy                         0.8155       943\n","   macro avg     0.8072    0.8214    0.8129       943\n","weighted avg     0.8181    0.8155    0.8156       943\n","\n","10/31/2023 09:24:40 [Test set] f1 0.8156062342235146\n"]}]},{"cell_type":"code","source":["!python eval.py --dataset=\"iemocap_4\" --modalities=\"atv\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGWlmpfOA5PK","executionInfo":{"status":"ok","timestamp":1698744307176,"user_tz":-60,"elapsed":14663,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"930e275c-78c3-4c1f-88c5-b9ca17ad952e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test: 100% 1/1 [00:01<00:00,  1.12s/it]\n","              precision    recall  f1-score   support\n","\n","           0     0.7517    0.7778    0.7645       144\n","           1     0.8783    0.8245    0.8505       245\n","           2     0.8234    0.7891    0.8059       384\n","           3     0.7755    0.8941    0.8306       170\n","\n","    accuracy                         0.8155       943\n","   macro avg     0.8072    0.8214    0.8129       943\n","weighted avg     0.8181    0.8155    0.8156       943\n","\n","F1 Score: 0.8156062342235146\n"]}]},{"cell_type":"code","source":["model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/trained_model3.pt')"],"metadata":{"id":"B9IoxvYF3sug","executionInfo":{"status":"error","timestamp":1725024875417,"user_tz":-120,"elapsed":36569,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bc7ff3035cb94fd3934e4b535bf47372","f17bd5abdf634316bd6e482d92b64c07","26c93aceb5e74544bd98e89597747611","b8adcf893b83472390a255a60505356e","55eefad3a8274821ae4389accd7c4fb2","f4bbbc3e2a974d9a992f94ccf0a78a5a","67d01a55319e4c04ab44c64ee3f63f39","49b7d61cb61b45eabd3c15f083fca750","7cd298a0de194c99955be2ae2d12ffd7","db575f20d6f3411685741e4d924eb402","1b97df1349704b5f9074c18ce3e6be4f","6453733d215d420d9a48c0cb5a0cb42b","c0b40493bff642f6832bd6ce5907d4cd","06f6b3f9c6ea40cb8d2244b665fb4a68","798e413e2ca54d78bf10e56bfac6b522","88b776ba1c624bef9395791715fcd375","2a8718f5e59b452c898d2b4b7b71f8bd","5a08f4f894bb4c36ae8aad5c56f2d304","bbb6f8ba445e4897b3860355c895b894","e09dc75196b4443990053e3353c8a018","dfc2626065c043e19e8b531bb3ef0e41","bb211d47769347e8ba33c9bc5e0de27b","7b0df0fa884f479ca281b367f4cd6ee7","b4b4201071b24b15a77ca26c0739489f","7596e1dff23a45f0ae7c3b981e6a6307","a1a2fb42ade140cb823f080843c08b7a","770bfd9778ae4400b65ab95b5ce8dee8","44e7e68b3ac141d2959d8f89f4aa9230","7697b3fb48e64a73ac57036b1bbed406","79e1d037f8d14cc48a15211f12490bf8","2485779004804019921401e7c564160a","c4ff6a31f55044f7bf8be469bb534af0","515ecebb242346e380ab1405639cefa7","d1ed120de8994e04be9e8df2a4b180bd","36c28f19b1e145b78650c85b1348df83","5fbe64543ed84f96ae6afc569dbcebdc","9213825380b54ab486d39c3b4eaec984","346a0eac12be44d4bcbfc99d56528aa7","8ef0aa431ebf4eaea40ce9a1dba2a55d","62304b9782364417bfa4b0530de3251c","a8e87eae12dd4fdfb1a458bc892f107f","ce8ae45678bd4c33b20b7ff0a43c62ed","45be499e2e43496496859d4659ecea11","98515da7b6ac4b6db441005f9ecb7715","1fafecc7765442d5928a99c775f8bef7","99f75c4874034433b6c2bb0a9edc30f2","0496f837e4f9499aa9eaba529fd60084","031414190c1b41c08c682eb7b6ebea34","0cb2319516b34d5c8ff33a185d3ee40b","770d09548bc044288f44a4c1d8bef01c","c33614634edb438a8dd7e9315e4327c3","84f23ba9bb97498f8ffce0debbae912e","93236b85a4ed4eb9805d765b96ac5898","4c255e70502d47abb0885adaf048fb47","28fbb965fc68452b80d4266f35ac6f2c","b8b39f60423741cb879928a1d40a70c9","33deea579c2d491fb89e6a35433f9699","5d07cbdc9b6046d4be0fff987976a3e7","bbb269eebb614c53bf3bddbe38670a71","d5cc8437b52e4a3fa206d2554842765b","4f960e2e7c5643418a8c9092b61db6ae","1509c0c87ad049c58ed98e97dafee316","b96aa4f6646a4ff48302c4b5faa5566b","27e6256ea831493ca5f665864d1d81c3","3bdb5c335645471f9c060fa5f4641a31","ce9e5d48d8794d09a2a2b18110decc32","b035ee7675b24c70a401cc1e88e84a8a","49ebbb5105d748719438b0a3153e8be6","aaa458568d764ba2a0361891a19c008c","c9e34adc2532490aa7c550946508a08f","19ef4f468d724ca28055a5f5b9daab93","880157d886684d418fb8eb58c245085c","0d1ce6c20af34d409575e34bae072615","b36aedfde30c44ff940ba4b843979f7f","2a9c4b7a158947eca51025ad112a90b2","80bc4563f24e4a3a9fe32765d6101ed3","fc3f18ab05a542999b5457a217737016","8fcb420e5c994e2d9b3461bb79744095","03547fe1043c4596acb859467577b297","0fdca819e9b5466ba54c484bae6b31fe","82ea663f86e149678a99aea6ec018c1d","ae6502a253f24caf9beaa1c4bd6a7190","f7f529e657814276835f42774d7e6950","5db58a239f4b4a35937530e9ed134633","45a38de80fe143e5ad55e2339ca282a5","d8a5a718f2644df3be34aab0a634885e","ad83bdeef88f496c9b6221032c7cda9d","b2b0ac98775240a6adf5f08d96058bb8","416c1e1699fd468594b092f6aaae0ac5","f3a039d14a3241588f9b5869e7fd31fe","16d8d5c2599a455484a3c9ff2f3d25a3","e369ab697dfa4e73867b0dbf8ae23983","fd5f09cfa1da48f79a5d7616a84aa67e","e233496643984fa49157863000447e77","af47580d477c4aa08fb6d0a6c0267adb","188e1271a1834d548e991cf005532067","ae227a208ee74a5cb4a6ad5819f9e009","5e7e969f77e64b66b6a9137cb84ba77f","829cc19a513845458bfb5f75c4020b76","f8190949780d43e4849a8d3227f67f03","3f293d4076c348cb958dcad8fecc5dcc","76d7bd6d1add4a5a903f8fbb74eab573","a7fe8d6d259f40739677daf3895aad90","2a4d19bb07f847d6be5a03933198f076","42e1222b7be1412aa7b2e61b13b5417e","005dbb67f7ca465caf3a28f4ac95952d","40f1ba2c79ee47bb8adf8e2e15c47c12","58df148be32a41ea86666d5cecc82f36","bd9127cd42aa4267a16ab09a5e96acfd","6ba2a4aed48c414daf2494408a16b40c","0d9ddddfa76c44b885e470d27371064b","40d727495bdd422c852ff971ab93e356","fc66448bf8b84e25905f4f47ae5384f8","17bf405f949649a8b0bc2db9d985fa5d","a26f4b5b42e04af99449731789d1c5d1","b5bd8c3e71934ea7af3e19d9e18028c5","d06ea01a951848b3a977ebb19bb765b8","47389ab33afb4149be503a004dcebbb5","17026c24ccf040f2826265df7159b3bc","49f84cff8a1244cfa0bc3c3a44128d31","308aa196d36b4cd78652a0c783db7a9b","91937de9cf25481892561465c45fa9f7","14816bd2ea044fa0871e76e879cd9ddf","752e7b73e7ea40018d5a8c989e27eb99","56a2246133ee4073b2a4d4c8b25d0280","05b8c7f7d8024f78883045779bb993d3","a971da1f455441a1bc332d29661852a6","fc9c491a2f934f70ad99125c027532c3","e34af12bab874f0aabfb61d9cdb96b21","c95378f122714a2f91494881724e1ff8","c634b4550af94738bcd136a925d581f4","a0074874acfc4b1e9f145006d70f52d8"]},"outputId":"82a4815e-05b7-4a40-9343-c82574d83bab"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-abc098b37b9e>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/trained_model3.pt')\n","/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n","comet_ml is installed but `COMET_API_KEY` is not set.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc7ff3035cb94fd3934e4b535bf47372"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6453733d215d420d9a48c0cb5a0cb42b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/3.78k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b0df0fa884f479ca281b367f4cd6ee7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ed120de8994e04be9e8df2a4b180bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fafecc7765442d5928a99c775f8bef7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b39f60423741cb879928a1d40a70c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b035ee7675b24c70a401cc1e88e84a8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fcb420e5c994e2d9b3461bb79744095"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"416c1e1699fd468594b092f6aaae0ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8190949780d43e4849a8d3227f67f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d9ddddfa76c44b885e470d27371064b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91937de9cf25481892561465c45fa9f7"}},"metadata":{}},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric.nn.conv.utils.inspector'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-abc098b37b9e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Master_2023_sept/COGMEN-main/trained_model3.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1098\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     \u001b[0;31m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1513\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric.nn.conv.utils.inspector'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["weights1=[]\n","bias1=[]\n","def get_wb(model):\n","    for name, param in model.named_parameters():\n","        if 'weight' in name:\n","            print(f'Weight matrix for {name}:')\n","            print(param)\n","            weights1.append(param.view(-1))\n","        elif 'bias' in name:\n","            print(f'Bias vector for {name}:')\n","            print(param)\n","            bias1.append(param.view(-1))\n","    # print(weights_and_biases_vector)\n","    weights_vec=torch.cat(weights1)\n","    bias_vec=torch.cat(bias1)\n","    #print('weights vector')\n","    #print(weights_vec)\n","    #print('bias vector')\n","    return weights1, weights_vec, bias_vec"],"metadata":{"id":"-nLJTfsG3s4F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights1, weights_vec, bias_vec = get_wb(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzjeSzXC3tCK","executionInfo":{"status":"ok","timestamp":1698925433673,"user_tz":-60,"elapsed":486,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"76f0ded9-386b-4d76-be97-262cac289731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weight matrix for rnn.encoding_layer.weight:\n","Parameter containing:\n","tensor([[-1.5405, -0.3515, -0.3186,  ...,  0.6964,  1.0487, -0.4811],\n","        [ 0.8839, -0.1836, -0.0400,  ...,  0.5956, -0.0908,  0.0568],\n","        [ 0.0724, -0.8025,  0.7511,  ...,  0.9484, -1.0034, -1.4723],\n","        ...,\n","        [ 1.0028,  0.0467, -0.6503,  ..., -0.5072, -0.6748,  1.6817],\n","        [ 1.0575, -0.2266,  0.2583,  ...,  0.2257, -0.0640,  0.3134],\n","        [-0.4202,  0.1140, -0.7010,  ...,  0.8381,  2.6865,  2.0627]],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.LayerNorm.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.LayerNorm.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.self_attn.in_proj_weight:\n","Parameter containing:\n","tensor([[-0.0259,  0.0252, -0.0164,  ...,  0.0188, -0.0027,  0.0262],\n","        [-0.0071,  0.0112, -0.0260,  ..., -0.0024,  0.0040,  0.0174],\n","        [-0.0320,  0.0311, -0.0278,  ...,  0.0122, -0.0134,  0.0101],\n","        ...,\n","        [ 0.0119, -0.0051,  0.0007,  ...,  0.0123, -0.0144,  0.0256],\n","        [ 0.0249, -0.0212,  0.0166,  ...,  0.0063, -0.0140,  0.0194],\n","        [ 0.0010,  0.0051, -0.0188,  ...,  0.0316,  0.0012, -0.0100]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.self_attn.in_proj_bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.self_attn.out_proj.weight:\n","Parameter containing:\n","tensor([[-0.0014, -0.0226, -0.0189,  ..., -0.0200, -0.0068,  0.0220],\n","        [ 0.0086,  0.0007,  0.0198,  ...,  0.0250,  0.0038, -0.0009],\n","        [ 0.0010, -0.0074, -0.0139,  ..., -0.0221,  0.0087, -0.0049],\n","        ...,\n","        [-0.0157, -0.0159,  0.0214,  ...,  0.0228,  0.0173, -0.0126],\n","        [-0.0174,  0.0208,  0.0102,  ..., -0.0101,  0.0187, -0.0011],\n","        [-0.0118,  0.0135,  0.0247,  ...,  0.0206, -0.0031, -0.0079]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.self_attn.out_proj.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.linear1.weight:\n","Parameter containing:\n","tensor([[-0.0084,  0.0118,  0.0040,  ..., -0.0175, -0.0062, -0.0097],\n","        [ 0.0020,  0.0058, -0.0152,  ..., -0.0127,  0.0120,  0.0075],\n","        [ 0.0050, -0.0022,  0.0027,  ...,  0.0217,  0.0047, -0.0232],\n","        ...,\n","        [-0.0251, -0.0140, -0.0253,  ..., -0.0110, -0.0251,  0.0013],\n","        [ 0.0171,  0.0218,  0.0146,  ...,  0.0206, -0.0252,  0.0053],\n","        [ 0.0104, -0.0117, -0.0199,  ..., -0.0194,  0.0004,  0.0190]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.linear1.bias:\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.linear2.weight:\n","Parameter containing:\n","tensor([[ 2.0869e-02, -8.5141e-03,  2.1004e-02,  ..., -1.8733e-03,\n","          1.1463e-02,  1.6535e-02],\n","        [-1.6825e-02,  1.6355e-02, -6.2599e-03,  ..., -4.5087e-05,\n","          1.2243e-02,  1.0091e-02],\n","        [ 3.3961e-04, -1.4036e-02, -6.5373e-03,  ..., -1.0413e-02,\n","         -1.9913e-03,  4.7169e-03],\n","        ...,\n","        [-2.0588e-02, -1.0654e-02,  1.2563e-02,  ...,  9.3520e-03,\n","          1.8594e-03,  7.0706e-03],\n","        [-6.6939e-03, -1.0174e-02, -5.4319e-03,  ...,  1.2738e-03,\n","          1.9165e-02, -2.0058e-02],\n","        [ 1.5700e-02, -6.7736e-03,  1.9677e-02,  ..., -8.6711e-03,\n","          4.6090e-03,  2.6161e-03]], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.linear2.bias:\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.norm1.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.norm1.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.norm2.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.norm2.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.self_attn.in_proj_weight:\n","Parameter containing:\n","tensor([[-0.0259,  0.0252, -0.0164,  ...,  0.0188, -0.0027,  0.0262],\n","        [-0.0071,  0.0112, -0.0260,  ..., -0.0024,  0.0040,  0.0174],\n","        [-0.0320,  0.0311, -0.0278,  ...,  0.0122, -0.0134,  0.0101],\n","        ...,\n","        [ 0.0119, -0.0051,  0.0007,  ...,  0.0123, -0.0144,  0.0256],\n","        [ 0.0249, -0.0212,  0.0166,  ...,  0.0063, -0.0140,  0.0194],\n","        [ 0.0010,  0.0051, -0.0188,  ...,  0.0316,  0.0012, -0.0100]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.self_attn.in_proj_bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.self_attn.out_proj.weight:\n","Parameter containing:\n","tensor([[-0.0014, -0.0226, -0.0189,  ..., -0.0200, -0.0068,  0.0220],\n","        [ 0.0086,  0.0007,  0.0198,  ...,  0.0250,  0.0038, -0.0009],\n","        [ 0.0010, -0.0074, -0.0139,  ..., -0.0221,  0.0087, -0.0049],\n","        ...,\n","        [-0.0157, -0.0159,  0.0214,  ...,  0.0228,  0.0173, -0.0126],\n","        [-0.0174,  0.0208,  0.0102,  ..., -0.0101,  0.0187, -0.0011],\n","        [-0.0118,  0.0135,  0.0247,  ...,  0.0206, -0.0031, -0.0079]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.self_attn.out_proj.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.linear1.weight:\n","Parameter containing:\n","tensor([[-0.0084,  0.0118,  0.0040,  ..., -0.0175, -0.0062, -0.0097],\n","        [ 0.0020,  0.0058, -0.0152,  ..., -0.0127,  0.0120,  0.0075],\n","        [ 0.0050, -0.0022,  0.0027,  ...,  0.0217,  0.0047, -0.0232],\n","        ...,\n","        [-0.0251, -0.0140, -0.0253,  ..., -0.0110, -0.0251,  0.0013],\n","        [ 0.0171,  0.0218,  0.0146,  ...,  0.0206, -0.0252,  0.0053],\n","        [ 0.0104, -0.0117, -0.0199,  ..., -0.0194,  0.0004,  0.0190]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.linear1.bias:\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.linear2.weight:\n","Parameter containing:\n","tensor([[ 2.0869e-02, -8.5141e-03,  2.1004e-02,  ..., -1.8733e-03,\n","          1.1463e-02,  1.6535e-02],\n","        [-1.6825e-02,  1.6355e-02, -6.2599e-03,  ..., -4.5087e-05,\n","          1.2243e-02,  1.0091e-02],\n","        [ 3.3961e-04, -1.4036e-02, -6.5373e-03,  ..., -1.0413e-02,\n","         -1.9913e-03,  4.7169e-03],\n","        ...,\n","        [-2.0588e-02, -1.0654e-02,  1.2563e-02,  ...,  9.3520e-03,\n","          1.8594e-03,  7.0706e-03],\n","        [-6.6939e-03, -1.0174e-02, -5.4319e-03,  ...,  1.2738e-03,\n","          1.9165e-02, -2.0058e-02],\n","        [ 1.5700e-02, -6.7736e-03,  1.9677e-02,  ..., -8.6711e-03,\n","          4.6090e-03,  2.6161e-03]], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.linear2.bias:\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.norm1.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.norm1.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.norm2.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.norm2.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_out.weight:\n","Parameter containing:\n","tensor([[ 2.4984e-02,  1.6558e-02, -2.6441e-02,  ..., -3.8561e-03,\n","          2.0609e-02,  1.2387e-02],\n","        [-8.8269e-03,  1.4057e-02, -1.1591e-02,  ..., -1.7771e-02,\n","         -1.2314e-02,  2.3355e-05],\n","        [ 1.8611e-02, -2.0347e-02,  6.3983e-03,  ..., -1.3365e-02,\n","          2.3725e-02,  3.1175e-03],\n","        ...,\n","        [ 1.4700e-02, -5.5198e-03,  9.9011e-03,  ..., -3.3344e-03,\n","         -2.0279e-02,  1.5662e-02],\n","        [-1.3611e-02,  2.5969e-02, -1.3062e-02,  ..., -2.4252e-02,\n","          7.9059e-03,  1.4950e-02],\n","        [ 1.8431e-02,  9.6439e-03,  2.5457e-02,  ..., -1.3059e-02,\n","          1.1863e-02,  7.4251e-03]], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_out.bias:\n","Parameter containing:\n","tensor([-0.0237, -0.0019,  0.0154, -0.0216,  0.0066, -0.0017,  0.0199,  0.0266,\n","         0.0194, -0.0110,  0.0025, -0.0085,  0.0250, -0.0166, -0.0241,  0.0258,\n","         0.0260, -0.0247, -0.0003, -0.0005,  0.0119,  0.0039, -0.0158, -0.0170,\n","        -0.0240, -0.0061,  0.0159,  0.0231,  0.0239, -0.0204,  0.0044, -0.0196,\n","         0.0142,  0.0097, -0.0032,  0.0267, -0.0169,  0.0210, -0.0201,  0.0115,\n","        -0.0181,  0.0268, -0.0008, -0.0108,  0.0223, -0.0038, -0.0031, -0.0022,\n","        -0.0057, -0.0128, -0.0033,  0.0261,  0.0150, -0.0189, -0.0142, -0.0236,\n","         0.0166, -0.0081,  0.0063,  0.0098,  0.0240, -0.0096,  0.0039,  0.0220,\n","        -0.0135, -0.0248,  0.0123,  0.0050, -0.0178, -0.0239, -0.0010,  0.0140,\n","        -0.0104,  0.0111, -0.0201, -0.0107, -0.0067, -0.0072, -0.0202,  0.0213,\n","        -0.0018, -0.0013, -0.0051, -0.0153,  0.0069,  0.0127, -0.0123, -0.0153,\n","         0.0236, -0.0034, -0.0097,  0.0066,  0.0089,  0.0014,  0.0149, -0.0040,\n","        -0.0189,  0.0242, -0.0119,  0.0069], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv1.weight:\n","Parameter containing:\n","tensor([[[ 1.6582e-02, -1.3431e-01,  1.6853e-01,  ...,  1.2562e-01,\n","          -6.8343e-02,  9.3560e-02],\n","         [-2.0877e-02,  1.6033e-01,  2.8398e-02,  ...,  4.4662e-02,\n","          -8.9625e-02,  1.3199e-01],\n","         [-9.5914e-03,  1.0323e-01,  3.0253e-02,  ..., -1.9400e-03,\n","          -1.4211e-01, -3.8304e-02],\n","         ...,\n","         [ 6.5313e-02,  1.4216e-01, -9.1744e-02,  ...,  9.6574e-02,\n","          -1.1501e-01,  1.1290e-01],\n","         [-1.1431e-01,  1.0135e-01,  1.4859e-01,  ..., -2.4445e-02,\n","           1.0971e-01,  1.5096e-01],\n","         [ 1.6420e-01, -3.7805e-02, -2.6450e-02,  ...,  1.1648e-01,\n","           7.9652e-02,  1.3288e-01]],\n","\n","        [[ 1.5409e-02, -5.6110e-02, -2.0907e-02,  ...,  9.3222e-02,\n","          -5.1245e-02,  1.6460e-01],\n","         [-1.2521e-01,  1.1457e-01, -6.1809e-02,  ..., -1.2908e-01,\n","          -1.7091e-03, -6.0869e-02],\n","         [ 2.4026e-03,  7.3515e-02, -1.3289e-01,  ...,  4.3223e-02,\n","          -9.7678e-02,  7.4335e-03],\n","         ...,\n","         [-8.4151e-02, -1.0343e-01, -4.8406e-02,  ..., -5.7894e-02,\n","          -1.4149e-01,  3.5637e-02],\n","         [-1.3587e-01, -5.7538e-02, -4.1014e-02,  ...,  6.7520e-02,\n","          -2.9771e-02, -3.5700e-02],\n","         [-3.0564e-02,  4.9192e-02, -3.5899e-03,  ..., -4.2687e-02,\n","          -1.0330e-01,  1.0585e-01]],\n","\n","        [[-1.1084e-01,  7.6488e-02, -1.6731e-01,  ..., -1.5689e-01,\n","           1.6446e-01,  3.8542e-02],\n","         [ 9.8609e-02, -1.0977e-01, -1.6547e-01,  ..., -4.6237e-02,\n","          -1.7273e-01, -1.2512e-01],\n","         [ 6.5630e-02, -1.2892e-01, -1.0988e-01,  ...,  9.2844e-02,\n","           7.1886e-02,  4.0516e-02],\n","         ...,\n","         [ 1.1855e-01,  4.7659e-02,  2.5397e-06,  ..., -4.1719e-02,\n","          -8.5762e-02,  1.2041e-02],\n","         [ 1.7116e-01,  1.2255e-03,  1.3028e-01,  ...,  7.5069e-02,\n","           4.1681e-02, -3.3303e-02],\n","         [ 1.5025e-01,  8.7002e-02, -1.3950e-01,  ..., -1.6624e-01,\n","           6.5730e-02, -1.3794e-01]],\n","\n","        ...,\n","\n","        [[ 1.1076e-01, -1.1498e-03, -1.4969e-02,  ...,  2.7424e-02,\n","           1.4174e-01, -1.0429e-01],\n","         [ 1.6850e-02,  3.6850e-03,  8.4550e-02,  ..., -7.5537e-02,\n","           3.7585e-02,  8.9450e-02],\n","         [-1.6513e-02, -6.2987e-02,  3.2054e-02,  ...,  5.5465e-02,\n","          -1.5556e-01,  8.0662e-02],\n","         ...,\n","         [-7.9558e-02,  6.9347e-02, -1.1021e-01,  ..., -8.0035e-02,\n","          -1.4888e-01, -2.9130e-02],\n","         [-3.1670e-02, -7.9053e-03, -3.4559e-02,  ...,  7.9934e-02,\n","           2.3772e-02,  1.0117e-01],\n","         [ 1.7169e-01, -4.5485e-02,  8.9173e-02,  ..., -1.3702e-01,\n","          -7.0493e-02, -1.3707e-01]],\n","\n","        [[-1.7282e-01, -6.7311e-02, -4.5677e-04,  ...,  8.2353e-02,\n","           3.5404e-02, -1.6631e-01],\n","         [ 9.6810e-02,  9.6563e-02, -4.6726e-02,  ..., -1.5660e-02,\n","          -4.4498e-02,  5.5897e-02],\n","         [-2.0039e-02,  2.3450e-02, -3.1461e-02,  ..., -8.4559e-02,\n","           6.4600e-02, -5.2359e-02],\n","         ...,\n","         [ 1.3008e-01,  8.9584e-03, -1.6023e-01,  ..., -7.9813e-02,\n","          -5.7333e-03, -6.1719e-02],\n","         [-7.5051e-02, -4.8246e-02,  1.2212e-01,  ...,  1.0150e-01,\n","          -1.3183e-01, -8.4711e-02],\n","         [-9.7848e-02,  7.1510e-02,  1.6363e-01,  ..., -1.1801e-01,\n","          -1.2522e-01, -1.5734e-02]],\n","\n","        [[ 3.2423e-02,  1.1153e-01, -2.2742e-02,  ...,  1.1291e-02,\n","          -3.5621e-03, -1.6378e-01],\n","         [ 1.7007e-03, -1.5814e-02,  3.9323e-02,  ..., -1.4504e-01,\n","          -3.6988e-02, -3.0379e-02],\n","         [-5.5274e-02, -9.2263e-02,  6.0870e-02,  ...,  5.1990e-02,\n","          -1.3338e-01, -2.5550e-02],\n","         ...,\n","         [-1.4579e-01, -3.0353e-02,  1.7217e-01,  ..., -1.3854e-02,\n","          -4.1705e-02,  7.1086e-02],\n","         [ 7.5531e-02,  1.0533e-02,  1.0539e-01,  ..., -1.5635e-01,\n","          -2.0977e-02,  1.1567e-01],\n","         [-9.1419e-02,  1.3962e-01,  6.3996e-02,  ...,  9.5708e-02,\n","          -1.6083e-01, -1.2422e-01]]], device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv1.bias:\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for gcn.conv2.lin_key.weight:\n","Parameter containing:\n","tensor([[-0.0865,  0.0557,  0.0943,  ...,  0.0423, -0.0932, -0.0796],\n","        [ 0.0401,  0.0460, -0.0147,  ...,  0.0491,  0.0223,  0.0244],\n","        [ 0.0470,  0.0826, -0.0856,  ...,  0.0547,  0.0779, -0.0666],\n","        ...,\n","        [-0.0128,  0.0663, -0.0294,  ...,  0.0499,  0.0731,  0.0199],\n","        [ 0.0939, -0.0319,  0.0667,  ..., -0.0079, -0.0990, -0.0265],\n","        [ 0.0504, -0.0166,  0.0392,  ..., -0.0230,  0.0501, -0.0204]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_key.bias:\n","Parameter containing:\n","tensor([-0.0991, -0.0645,  0.0659,  0.0654, -0.0402, -0.0288,  0.0769, -0.0589,\n","        -0.0395,  0.0581, -0.0294,  0.0154, -0.0524, -0.0345, -0.0896, -0.0972,\n","         0.0742, -0.0360, -0.0624,  0.0558, -0.0155,  0.0944, -0.0256,  0.0330,\n","        -0.0339,  0.0102, -0.0313,  0.0378,  0.0945,  0.0516,  0.0905, -0.0068,\n","        -0.0480,  0.0047, -0.0101,  0.0159,  0.0123,  0.0081, -0.0227,  0.0719,\n","        -0.0500, -0.0148,  0.0014, -0.0990, -0.0476, -0.0772,  0.0749,  0.0579,\n","         0.0348,  0.0828,  0.0040, -0.0983,  0.0519,  0.0715, -0.0695,  0.0353,\n","         0.0111,  0.0414,  0.0267,  0.0704,  0.0966,  0.0561, -0.0895, -0.0112,\n","         0.0244, -0.0855,  0.0741, -0.0169,  0.0806,  0.0364, -0.0460, -0.0708,\n","        -0.0234, -0.0690,  0.0912, -0.0198,  0.0560, -0.0923, -0.0191,  0.0723,\n","        -0.0498, -0.0692, -0.0081, -0.0869, -0.0146, -0.0728, -0.0717, -0.0291,\n","         0.0041, -0.0866,  0.0837, -0.0719,  0.0169, -0.0703, -0.0148,  0.0263,\n","         0.0859, -0.0849,  0.0308,  0.0992], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_query.weight:\n","Parameter containing:\n","tensor([[-0.0791,  0.0795,  0.0408,  ...,  0.0377,  0.0531, -0.0626],\n","        [-0.0050,  0.0656,  0.0530,  ...,  0.0558, -0.0417,  0.0387],\n","        [ 0.0983,  0.0689, -0.0153,  ..., -0.0122, -0.0768, -0.0312],\n","        ...,\n","        [-0.0043,  0.0522,  0.0273,  ..., -0.0355,  0.0241, -0.0647],\n","        [-0.0206, -0.0310,  0.0278,  ..., -0.0044,  0.0822,  0.0784],\n","        [ 0.0896, -0.0077,  0.0540,  ..., -0.0592,  0.0440, -0.0459]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_query.bias:\n","Parameter containing:\n","tensor([ 0.0844, -0.0540,  0.0126, -0.0950,  0.0963,  0.0158,  0.0484, -0.0252,\n","        -0.0592, -0.0308, -0.0575,  0.0020,  0.0458,  0.0818,  0.0884, -0.0058,\n","        -0.0778,  0.0817, -0.0452,  0.0860,  0.0510,  0.0915, -0.0950,  0.0601,\n","         0.0545,  0.0739, -0.0680,  0.0799,  0.0136,  0.0287, -0.0594, -0.0541,\n","         0.0699, -0.0706,  0.0047,  0.0079,  0.0449, -0.0395,  0.0789, -0.0041,\n","         0.0744, -0.0185, -0.0451,  0.0060, -0.0579,  0.0737, -0.0798, -0.0454,\n","        -0.0783,  0.0356,  0.0202, -0.0507, -0.0163, -0.0913,  0.0450, -0.0299,\n","         0.0291, -0.0776, -0.0830,  0.0933,  0.0382,  0.0338,  0.0806,  0.0377,\n","        -0.0619,  0.0079, -0.0473,  0.0775,  0.0367, -0.0272, -0.0228,  0.0356,\n","         0.0633,  0.0148, -0.0781,  0.0601, -0.0574, -0.0071,  0.0348,  0.0293,\n","        -0.0004,  0.0148, -0.0091, -0.0914,  0.0584, -0.0131,  0.0069,  0.0793,\n","         0.0437, -0.0174,  0.0669, -0.0204, -0.0894, -0.0581,  0.0307,  0.0181,\n","        -0.0044,  0.0399,  0.0194,  0.0123], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_value.weight:\n","Parameter containing:\n","tensor([[ 0.0830, -0.0755,  0.0408,  ...,  0.0959,  0.0083,  0.0700],\n","        [-0.0234, -0.0279,  0.0745,  ..., -0.0575,  0.0525,  0.0360],\n","        [ 0.0344, -0.0929,  0.0970,  ..., -0.0875,  0.0350, -0.0099],\n","        ...,\n","        [-0.0051, -0.0935, -0.0476,  ..., -0.0231, -0.0791, -0.0835],\n","        [ 0.0914, -0.0294, -0.0212,  ..., -0.0998,  0.0005, -0.0455],\n","        [-0.0267, -0.0676,  0.0431,  ..., -0.0472,  0.0400,  0.0232]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_value.bias:\n","Parameter containing:\n","tensor([ 0.0306, -0.0675,  0.0779, -0.0751,  0.0946,  0.0238,  0.0302,  0.0231,\n","         0.0905, -0.0692, -0.0250, -0.0581, -0.0854,  0.0074,  0.0140, -0.0213,\n","         0.0408, -0.0691, -0.0963,  0.0497,  0.0574,  0.0611, -0.0365,  0.0188,\n","         0.0154,  0.0268, -0.0787, -0.0108,  0.0175,  0.0115,  0.0355,  0.0209,\n","         0.0909,  0.0026, -0.0055, -0.0443, -0.0840, -0.0966,  0.0668,  0.0801,\n","         0.0125,  0.0825, -0.0179,  0.0365, -0.0724,  0.0683,  0.0884, -0.0132,\n","         0.0536, -0.0181, -0.0505, -0.0995,  0.0074,  0.0134,  0.0057,  0.0421,\n","        -0.0250, -0.0813,  0.0889, -0.0230,  0.0081,  0.0937,  0.0527,  0.0064,\n","        -0.0635,  0.0295,  0.0940,  0.0128, -0.0440, -0.0997,  0.0727, -0.0642,\n","         0.0064, -0.0042,  0.0485,  0.0016, -0.0898,  0.0380, -0.0373,  0.0329,\n","        -0.0438, -0.0771,  0.0502,  0.0544,  0.0896,  0.0860,  0.0351, -0.0568,\n","        -0.0504, -0.0295,  0.0136,  0.0565,  0.0154, -0.0799,  0.0566,  0.0004,\n","        -0.0276, -0.0160,  0.0806, -0.0563], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_skip.weight:\n","Parameter containing:\n","tensor([[ 0.0565, -0.0222, -0.0746,  ...,  0.0417, -0.0265, -0.0481],\n","        [-0.0166, -0.0396,  0.0173,  ..., -0.0797, -0.0762, -0.0712],\n","        [ 0.0338,  0.0527,  0.0186,  ...,  0.0390,  0.0497,  0.0731],\n","        ...,\n","        [ 0.0352,  0.0104, -0.0592,  ..., -0.0887, -0.0895, -0.0871],\n","        [ 0.0406, -0.0364, -0.0565,  ..., -0.0911,  0.0900,  0.0389],\n","        [-0.0684,  0.0821, -0.0839,  ..., -0.0797,  0.0916,  0.0085]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for gcn.conv2.lin_skip.bias:\n","Parameter containing:\n","tensor([-0.0308,  0.0801,  0.0266, -0.0314,  0.0104,  0.0130, -0.0156,  0.0803,\n","         0.0438, -0.0490, -0.0382, -0.0941, -0.0902, -0.0199, -0.0012,  0.0091,\n","        -0.0841,  0.0825,  0.0716,  0.0114,  0.0145,  0.0292, -0.0095, -0.0523,\n","        -0.0435,  0.0970, -0.0484, -0.0765,  0.0037,  0.0982,  0.0957, -0.0860,\n","         0.0990, -0.0020,  0.0885,  0.0925, -0.0574,  0.0311,  0.0379,  0.0964,\n","         0.0221, -0.0952, -0.0198,  0.0791,  0.0117, -0.0456, -0.0678, -0.0059,\n","        -0.0833, -0.0743,  0.0641,  0.0344,  0.0156,  0.0787, -0.0277, -0.0554,\n","         0.0258,  0.0452,  0.0385, -0.0764,  0.0068, -0.0177, -0.0807,  0.0157,\n","         0.0582, -0.0685, -0.0224,  0.0935, -0.0355, -0.0810,  0.0225,  0.0638,\n","        -0.0300,  0.0542, -0.0498,  0.0452,  0.0785, -0.0273,  0.0495,  0.0386,\n","        -0.0396, -0.0357,  0.0272,  0.0535, -0.0344,  0.0526,  0.0696,  0.0649,\n","        -0.0151, -0.0117, -0.0287, -0.0673, -0.0992,  0.0611, -0.0836,  0.0084,\n","         0.0388, -0.0170, -0.0613,  0.0066], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.bn.weight:\n","Parameter containing:\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.bn.bias:\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for clf.emotion_att.lin.weight:\n","Parameter containing:\n","tensor([[-0.0172,  0.0947, -0.0276,  ..., -0.0499,  0.0160, -0.0662],\n","        [ 0.0054,  0.0051, -0.0466,  ..., -0.0585, -0.0102, -0.0598],\n","        [ 0.0408, -0.0813,  0.0862,  ...,  0.0764,  0.0062, -0.0187],\n","        ...,\n","        [-0.0210,  0.0758, -0.0153,  ...,  0.0263, -0.0525, -0.0431],\n","        [-0.0590, -0.0256,  0.0882,  ..., -0.0912, -0.0024, -0.0855],\n","        [-0.0632,  0.0205, -0.0181,  ...,  0.0766,  0.0883,  0.0985]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for clf.emotion_att.lin.bias:\n","Parameter containing:\n","tensor([ 0.0310,  0.0380, -0.0270,  0.0616,  0.0820,  0.0194,  0.0414,  0.0748,\n","         0.0330,  0.0831,  0.0034,  0.0888,  0.0091,  0.0931, -0.0020, -0.0580,\n","         0.0661, -0.0747, -0.0491,  0.0810,  0.0530,  0.0116, -0.0121,  0.0282,\n","        -0.0779,  0.0609, -0.0757, -0.0821,  0.0575,  0.0776,  0.0181, -0.0829,\n","         0.0946, -0.0726, -0.0235,  0.0449, -0.0922,  0.0536, -0.0730,  0.0249,\n","         0.0904,  0.0433, -0.0917,  0.0633,  0.0089,  0.0950,  0.0087, -0.0402,\n","        -0.0597,  0.0468,  0.0204,  0.0430,  0.0969,  0.0721, -0.0305,  0.0817,\n","        -0.0891,  0.0436,  0.0550, -0.0598,  0.0487,  0.0882, -0.0499,  0.0563,\n","        -0.0053, -0.0135,  0.0023,  0.0129,  0.0088,  0.0951,  0.0256,  0.0588,\n","         0.0467, -0.0100,  0.0629,  0.0385,  0.0327, -0.0063,  0.0411,  0.0238,\n","        -0.0555,  0.0076, -0.0277,  0.0397,  0.0540, -0.0323,  0.0654,  0.0193,\n","         0.0073, -0.0495,  0.0974,  0.0709, -0.0407,  0.0425, -0.0466, -0.0998,\n","        -0.0476,  0.0579,  0.0170, -0.0154], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin1.weight:\n","Parameter containing:\n","tensor([[-0.0434,  0.0086, -0.0120,  ...,  0.0496,  0.0390, -0.0866],\n","        [-0.0749,  0.0350, -0.0951,  ..., -0.0706,  0.0588,  0.0021],\n","        [-0.0388,  0.0280,  0.0116,  ...,  0.0584, -0.0222, -0.0533],\n","        ...,\n","        [ 0.0911, -0.0513, -0.0338,  ...,  0.0881, -0.0520, -0.0913],\n","        [-0.0867, -0.0916,  0.0116,  ...,  0.0382, -0.0891,  0.0327],\n","        [ 0.0650,  0.0633, -0.0304,  ..., -0.0735, -0.0848,  0.0331]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for clf.lin1.bias:\n","Parameter containing:\n","tensor([ 0.0762,  0.0880,  0.0464, -0.0047, -0.0801,  0.0563, -0.0795,  0.0890,\n","        -0.0352,  0.0643,  0.0485, -0.0053,  0.0714,  0.0026, -0.0216, -0.0704,\n","        -0.0150, -0.0501,  0.0022, -0.0042, -0.0394, -0.0176, -0.0425, -0.0123,\n","         0.0639,  0.0825,  0.0975,  0.0034, -0.0228,  0.0310, -0.0805, -0.0970,\n","         0.0286,  0.0184, -0.0883, -0.0630, -0.0171,  0.0793, -0.0963,  0.0190,\n","        -0.0941,  0.0329, -0.0340,  0.0827, -0.0255, -0.0977, -0.0589, -0.0200,\n","         0.0264,  0.0662, -0.0427, -0.0884,  0.0804, -0.0999,  0.0478, -0.0508,\n","        -0.0996, -0.0331,  0.0474, -0.0676, -0.0393,  0.0500,  0.0556, -0.0434,\n","         0.0044,  0.0449, -0.0820,  0.0411,  0.0597, -0.0488, -0.0330, -0.0831,\n","        -0.0663,  0.0483,  0.0922,  0.0776,  0.0448,  0.0970, -0.0049,  0.0961,\n","        -0.0691, -0.0696,  0.0078,  0.0822,  0.0409, -0.0339, -0.0016,  0.0115,\n","         0.0268,  0.0511, -0.0959,  0.0652, -0.0786, -0.0495,  0.0145, -0.0486,\n","        -0.0473,  0.0061, -0.0123, -0.0757], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin2.weight:\n","Parameter containing:\n","tensor([[-0.0231,  0.0611, -0.0787,  0.0208, -0.0325, -0.0179,  0.0858,  0.0240,\n","          0.0452,  0.0141, -0.0551, -0.0677, -0.0971,  0.0159, -0.0582,  0.0989,\n","          0.0087,  0.0731,  0.0133, -0.0791,  0.0133, -0.0140, -0.0680, -0.0884,\n","          0.0878,  0.0514,  0.0080, -0.0810, -0.0717, -0.0309,  0.0464,  0.0950,\n","         -0.0992, -0.0224,  0.0128, -0.0534, -0.0526,  0.0388, -0.0183,  0.0360,\n","         -0.0100,  0.0593,  0.0493, -0.0215, -0.0399,  0.0005, -0.0545,  0.0124,\n","          0.0686,  0.0796, -0.0474,  0.0033, -0.0698, -0.0670, -0.0236,  0.0904,\n","         -0.0590,  0.0498,  0.0334, -0.0610,  0.0215, -0.0607, -0.0125, -0.0627,\n","         -0.0616, -0.0220, -0.0340,  0.0952, -0.0740, -0.0041,  0.0940, -0.0466,\n","          0.0726,  0.0101,  0.0199,  0.0670,  0.0270,  0.0532,  0.0753,  0.0052,\n","         -0.0570, -0.0499, -0.0217, -0.0514, -0.0888, -0.0517,  0.0741,  0.0367,\n","         -0.0051, -0.0141, -0.0624, -0.0814,  0.0996,  0.0777, -0.0336, -0.0545,\n","          0.0083, -0.0372, -0.0658,  0.0475],\n","        [-0.0887,  0.0061,  0.0557, -0.0997,  0.0822,  0.0523, -0.0168,  0.0312,\n","         -0.0675,  0.0925,  0.0723, -0.0089, -0.0586,  0.0305,  0.0751,  0.0910,\n","         -0.0702,  0.0365, -0.0543,  0.0682, -0.0177, -0.0043,  0.0875, -0.0217,\n","         -0.0706,  0.0450,  0.0845,  0.0509, -0.0112, -0.0370, -0.0791,  0.0290,\n","          0.0335,  0.0942,  0.0801,  0.0361, -0.0462, -0.0519, -0.0091, -0.0028,\n","          0.0286,  0.0074, -0.0334, -0.0272,  0.0954, -0.0801, -0.0716,  0.0755,\n","          0.0281,  0.0286,  0.0978, -0.0170, -0.0588, -0.0374, -0.0474,  0.0943,\n","          0.0406, -0.0713,  0.0811,  0.0846,  0.0425, -0.0403,  0.0748,  0.0964,\n","         -0.0210, -0.0854, -0.0432,  0.0674, -0.0986, -0.0366, -0.0024,  0.0736,\n","          0.0814,  0.0468,  0.0756,  0.0454,  0.0611,  0.0264, -0.0832, -0.0504,\n","          0.0090,  0.0613,  0.0328,  0.0011, -0.0781, -0.0569,  0.0580, -0.0612,\n","         -0.0112,  0.0953, -0.0890, -0.0999,  0.0757, -0.0432,  0.0427,  0.0807,\n","         -0.0198,  0.0426,  0.0032,  0.0097],\n","        [ 0.0825, -0.0316,  0.0453,  0.0068, -0.0850, -0.0506,  0.0938, -0.0513,\n","         -0.0469,  0.0407,  0.0207,  0.0267,  0.0225, -0.0345,  0.0514,  0.0943,\n","         -0.0311, -0.0429, -0.0698,  0.0349, -0.0202,  0.0334,  0.0748,  0.0123,\n","          0.0807, -0.0216,  0.0192,  0.0024, -0.0322,  0.0853,  0.0491, -0.0157,\n","         -0.0202, -0.0946,  0.0741,  0.0896,  0.0888, -0.0490, -0.0973,  0.0734,\n","         -0.0716,  0.0176, -0.0960,  0.0396,  0.0915,  0.0535, -0.0481, -0.0212,\n","          0.0518,  0.0345, -0.0641,  0.0643,  0.0553,  0.0081, -0.0131,  0.0127,\n","          0.0161, -0.0391, -0.0295, -0.0814,  0.0737, -0.0275, -0.0418, -0.0424,\n","          0.0463,  0.0891,  0.0742, -0.0046,  0.0606,  0.0959, -0.0709, -0.0815,\n","          0.0237,  0.0311,  0.0638,  0.0702, -0.0930,  0.0841, -0.0597, -0.0945,\n","          0.0463,  0.0697, -0.0951,  0.0020, -0.0887,  0.0725,  0.0481, -0.0451,\n","          0.0489,  0.0637, -0.0421, -0.0598, -0.0954,  0.0333,  0.0910,  0.0746,\n","          0.0395, -0.0464, -0.0081, -0.0824],\n","        [ 0.0778, -0.0546,  0.0047, -0.0767,  0.0650,  0.0398,  0.0628, -0.0937,\n","          0.0413, -0.0449, -0.0507, -0.0671,  0.0834,  0.0504,  0.0832, -0.0265,\n","          0.0783,  0.0608, -0.0791,  0.0599,  0.0739,  0.0311, -0.0644,  0.0349,\n","         -0.0015,  0.0565,  0.0164, -0.0660, -0.0076, -0.0227, -0.0965, -0.0106,\n","         -0.0431,  0.0682, -0.0372,  0.0505,  0.0818, -0.0070, -0.0835,  0.0195,\n","         -0.0873, -0.0902,  0.0371, -0.0529, -0.0749, -0.0305,  0.0309,  0.0817,\n","          0.0396,  0.0594, -0.0438,  0.0624,  0.0223, -0.0925, -0.0875, -0.0883,\n","          0.0504, -0.0554, -0.0019,  0.0331,  0.0189,  0.0051,  0.0196,  0.0796,\n","          0.0688,  0.0385,  0.0221, -0.0991,  0.0325,  0.0400, -0.0945,  0.0311,\n","          0.0793,  0.0572, -0.0698,  0.0879,  0.0373, -0.0683, -0.0723, -0.0222,\n","          0.0959,  0.0928,  0.0266, -0.0771, -0.0363,  0.0733,  0.0795,  0.0285,\n","         -0.0027, -0.0727,  0.0796,  0.0783,  0.0180,  0.0913, -0.0250, -0.0435,\n","         -0.0145, -0.0692,  0.0756, -0.0741]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for clf.lin2.bias:\n","Parameter containing:\n","tensor([-0.0843,  0.0371, -0.0800, -0.0725], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin_7.weight:\n","Parameter containing:\n","tensor([[ 0.0834, -0.0943, -0.0705,  0.0911, -0.0330, -0.0189,  0.0987,  0.0758,\n","          0.0289,  0.0720,  0.0602,  0.0332,  0.0455,  0.0811, -0.0423,  0.0805,\n","         -0.0394,  0.0671,  0.0845,  0.0420, -0.0059, -0.0127,  0.0781,  0.0794,\n","         -0.0482,  0.0572, -0.0529,  0.0534, -0.0361, -0.0407,  0.0101, -0.0319,\n","         -0.0118,  0.0230, -0.0789, -0.0331,  0.0113,  0.0227,  0.0860,  0.0705,\n","          0.0890,  0.0987,  0.0989, -0.0740, -0.0629, -0.0839, -0.0753,  0.0157,\n","         -0.0468, -0.0048, -0.0836,  0.0416, -0.0390, -0.0940, -0.0979, -0.0835,\n","         -0.0644, -0.0229, -0.0746,  0.0164, -0.0059, -0.0550, -0.0054,  0.0785,\n","         -0.0571,  0.0904, -0.0996,  0.0173, -0.0248, -0.0958, -0.0299, -0.0607,\n","          0.0070, -0.0818,  0.0665,  0.0225, -0.0498,  0.0327, -0.0248, -0.0195,\n","         -0.0613,  0.0506, -0.0522, -0.0319, -0.0972, -0.0708, -0.0468,  0.0667,\n","          0.0707, -0.0882, -0.0700,  0.0230, -0.0451,  0.0618,  0.0738, -0.0748,\n","         -0.0888,  0.0003, -0.0213, -0.0383],\n","        [ 0.0497, -0.0458,  0.0927, -0.0153,  0.0009,  0.0293,  0.0871, -0.0481,\n","          0.0630, -0.0508,  0.0252,  0.0323, -0.0280,  0.0664, -0.0858,  0.0442,\n","         -0.0731,  0.0453, -0.0157, -0.0409, -0.0930, -0.0486, -0.0395, -0.0944,\n","          0.0748,  0.0622,  0.0129, -0.0515, -0.0476,  0.0368, -0.0816,  0.0527,\n","         -0.0799,  0.0560,  0.0601, -0.0146,  0.0822,  0.0537,  0.0035, -0.0194,\n","         -0.0526, -0.0206,  0.0178,  0.0630, -0.0139,  0.0730,  0.0578, -0.0139,\n","         -0.0865, -0.0500, -0.0048, -0.0909,  0.0481,  0.0913, -0.0351, -0.0844,\n","         -0.0699,  0.0820, -0.0775,  0.0288, -0.0444, -0.0145, -0.0224, -0.0172,\n","         -0.0339,  0.0793,  0.0209, -0.0790,  0.0667,  0.0368, -0.0456,  0.0910,\n","          0.0074,  0.0121, -0.0539,  0.0283, -0.0199,  0.0225,  0.0534,  0.0749,\n","         -0.0153,  0.0936, -0.0455,  0.0848,  0.0759,  0.0415,  0.0477, -0.0499,\n","         -0.0073,  0.0589, -0.0157,  0.0777, -0.0837, -0.0231, -0.0239,  0.0670,\n","          0.0211,  0.0998, -0.0108, -0.0313],\n","        [-0.0044, -0.0766,  0.0886,  0.0985, -0.0030, -0.0609,  0.0598, -0.0406,\n","          0.0581,  0.0063, -0.0064, -0.0004, -0.0520,  0.0610, -0.0324, -0.0353,\n","          0.0076, -0.0156,  0.0271, -0.0889, -0.0285,  0.0449,  0.0864,  0.0541,\n","         -0.0959,  0.0447,  0.0733,  0.0415,  0.0349,  0.0182, -0.0116, -0.0967,\n","          0.0041,  0.0286,  0.0215, -0.0519,  0.0629, -0.0355,  0.0282,  0.0492,\n","          0.0018,  0.0136,  0.0058, -0.0089,  0.0610,  0.0892,  0.0526,  0.0336,\n","         -0.0876, -0.0336, -0.0566,  0.0631,  0.0933, -0.0117,  0.0882,  0.0115,\n","          0.0193, -0.0981, -0.0300,  0.0051,  0.0401, -0.0464, -0.0553, -0.0293,\n","          0.0426, -0.0720,  0.0768, -0.0069, -0.0725,  0.0814,  0.0939,  0.0849,\n","          0.0276,  0.0921, -0.0836,  0.0572, -0.0279,  0.0794, -0.0763, -0.0896,\n","          0.0899,  0.0730, -0.0071, -0.0560,  0.0354, -0.0346, -0.0768, -0.0906,\n","         -0.0238, -0.0126,  0.0227, -0.0536, -0.0682,  0.0545,  0.0326, -0.0374,\n","          0.0867, -0.0085, -0.0234, -0.0539],\n","        [ 0.0988, -0.0278,  0.0172,  0.0964, -0.0943, -0.0260,  0.0052, -0.0308,\n","          0.0644,  0.0345, -0.0402,  0.0902, -0.0790,  0.0657,  0.0951,  0.0436,\n","         -0.0865, -0.0450,  0.0290, -0.0203, -0.0309,  0.0625, -0.0372,  0.0942,\n","          0.0334, -0.0268, -0.0774,  0.0576, -0.0727,  0.0482,  0.0437, -0.0098,\n","          0.0723,  0.0262, -0.0801,  0.0842,  0.0108,  0.0202, -0.0788, -0.0456,\n","         -0.0515,  0.0389, -0.0465,  0.0086,  0.0035,  0.0658,  0.0625,  0.0381,\n","         -0.0832,  0.0167, -0.0885,  0.0868, -0.0384, -0.0213, -0.0223,  0.0176,\n","         -0.0634, -0.0803, -0.0502, -0.0043,  0.0372,  0.0203, -0.0668, -0.0611,\n","          0.0760, -0.0323,  0.0928,  0.0137, -0.0029, -0.0912,  0.0032, -0.0700,\n","         -0.0506,  0.0061,  0.0126,  0.0724,  0.0073,  0.0654, -0.0269, -0.0865,\n","          0.0970, -0.0166, -0.0321,  0.0384, -0.0476, -0.0943,  0.0246,  0.0782,\n","          0.0913,  0.0398,  0.0495,  0.0481,  0.0314,  0.0634,  0.0430,  0.0513,\n","          0.0203, -0.0662, -0.0516, -0.0097],\n","        [ 0.0053,  0.0321,  0.0597,  0.0981,  0.0801, -0.0124,  0.0739,  0.0257,\n","          0.0044,  0.0693, -0.0201,  0.0722, -0.0360,  0.0197,  0.0762, -0.0949,\n","         -0.0464, -0.0865,  0.0838, -0.0212,  0.0503, -0.0560,  0.0530,  0.0675,\n","         -0.0285,  0.0816,  0.0473, -0.0365, -0.0081, -0.0398, -0.0872, -0.0282,\n","          0.0220,  0.0824, -0.0558,  0.0553,  0.0835,  0.0524,  0.0593, -0.0467,\n","         -0.0999, -0.0225, -0.0604,  0.0902, -0.0133, -0.0549,  0.0590, -0.0328,\n","         -0.0773, -0.0715,  0.0832,  0.0928, -0.0181, -0.0761,  0.0081,  0.0977,\n","         -0.0420, -0.0114,  0.0421,  0.0971,  0.0026,  0.0032, -0.0531,  0.0744,\n","          0.0503, -0.0076, -0.0771,  0.0600, -0.0271,  0.0825,  0.0879, -0.0415,\n","          0.0207,  0.0258,  0.0167, -0.0342,  0.0966, -0.0766, -0.0261,  0.0056,\n","          0.0188,  0.0993, -0.0326,  0.0800,  0.0157,  0.0716, -0.0925,  0.0570,\n","          0.0349, -0.0835, -0.0458,  0.0830, -0.0727,  0.0977, -0.0981,  0.0615,\n","         -0.0933, -0.0832,  0.0037, -0.0677],\n","        [ 0.0606, -0.0847, -0.0863, -0.0942, -0.0155, -0.0866, -0.0359, -0.0417,\n","          0.0576,  0.0920,  0.0527, -0.0705,  0.0965, -0.0434, -0.0656, -0.0341,\n","         -0.0035,  0.0793, -0.0757,  0.0104,  0.0389,  0.0310,  0.0682, -0.0947,\n","         -0.0813, -0.0803, -0.0248,  0.0200, -0.0964, -0.0205, -0.0373,  0.0561,\n","          0.0146,  0.0463, -0.0118, -0.0605, -0.0317, -0.0645, -0.0037,  0.0946,\n","         -0.0662,  0.0861,  0.0470, -0.0370,  0.0128, -0.0678,  0.0611, -0.0047,\n","         -0.0314, -0.0583, -0.0399, -0.0407,  0.0028,  0.0023, -0.0588, -0.0990,\n","          0.0073, -0.0277, -0.0750,  0.0258,  0.0632,  0.0005,  0.0089, -0.0121,\n","         -0.0017,  0.0884, -0.0091,  0.0768,  0.0894,  0.0743,  0.0424, -0.0002,\n","         -0.0688,  0.0524,  0.0670,  0.0388, -0.0205,  0.0624, -0.0983, -0.0177,\n","         -0.0486,  0.0553,  0.0246,  0.0269,  0.0305, -0.0652, -0.0485,  0.0919,\n","         -0.0216, -0.0200,  0.0214,  0.0211, -0.0773,  0.0633,  0.0704,  0.0210,\n","         -0.0108,  0.0251,  0.0873,  0.0616],\n","        [-0.0254,  0.0773,  0.0265,  0.0140, -0.0605,  0.0805,  0.0552,  0.0976,\n","          0.0713, -0.0765, -0.0159,  0.0100, -0.0533, -0.0970,  0.0002, -0.0736,\n","         -0.0393,  0.0227, -0.0079, -0.0616,  0.0222, -0.0873,  0.0775, -0.0589,\n","         -0.0828,  0.0047,  0.0745,  0.0901, -0.0091, -0.0408,  0.0549,  0.0559,\n","          0.0198, -0.0997,  0.0980, -0.0453,  0.0699,  0.0590, -0.0176, -0.0028,\n","         -0.0762, -0.0339,  0.0825,  0.0282, -0.0280,  0.0690, -0.0955,  0.0282,\n","          0.0971,  0.0300, -0.0761, -0.0903, -0.0982, -0.0928,  0.0668, -0.0974,\n","         -0.0169,  0.0213, -0.0546,  0.0489, -0.0981,  0.0656,  0.0099,  0.0584,\n","          0.0716, -0.0411,  0.0817,  0.0224,  0.0323, -0.0643, -0.0453, -0.0654,\n","          0.0893,  0.0732, -0.0483,  0.0959, -0.0846,  0.0975,  0.0915, -0.0078,\n","         -0.0387,  0.0094, -0.0690, -0.0198, -0.0028, -0.0963, -0.0324, -0.0567,\n","          0.0942,  0.0600,  0.0350,  0.0691,  0.0972, -0.0835,  0.0025, -0.0361,\n","         -0.0909, -0.0528,  0.0532,  0.0739]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for clf.lin_7.bias:\n","Parameter containing:\n","tensor([-0.0149, -0.0465,  0.0099,  0.0570,  0.0250,  0.0233,  0.0425],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for clf.linear.weight:\n","Parameter containing:\n","tensor([[-3.7008e-02,  7.9037e-02, -9.6631e-02, -7.0181e-02, -7.6220e-02,\n","          7.1087e-02, -7.5496e-02,  8.5444e-02,  8.7223e-02, -9.8911e-03,\n","         -3.8743e-02, -8.4766e-03,  2.1881e-03, -2.2703e-02, -7.0989e-02,\n","         -6.1675e-02,  9.1017e-02,  1.4013e-03,  2.3171e-02,  6.5210e-02,\n","          7.9242e-02, -9.6024e-02,  6.0686e-02,  5.0447e-02,  1.6530e-02,\n","          6.9341e-02, -7.2576e-02,  2.7377e-02, -6.3856e-02, -5.2966e-02,\n","          5.3378e-02,  7.0123e-02, -5.0479e-02, -5.2138e-02, -3.8304e-03,\n","         -8.3463e-02,  7.4907e-02,  2.8172e-02,  3.7462e-02, -7.6788e-03,\n","          1.8110e-02,  7.7666e-02, -9.6967e-02,  1.3185e-02, -2.1135e-02,\n","         -2.3898e-02, -3.2826e-02, -4.0910e-03, -7.9721e-02,  8.5199e-05,\n","          2.4464e-02,  9.9989e-02, -5.4309e-02,  7.1346e-02,  6.5091e-02,\n","          1.5353e-03, -4.1694e-02, -2.0742e-02, -3.5608e-02,  9.5540e-02,\n","          5.2335e-02,  5.4811e-02, -1.8522e-02,  9.6849e-02, -4.3480e-02,\n","          1.1354e-02, -4.5472e-02, -1.7418e-02, -4.4014e-02, -6.7276e-02,\n","          4.8936e-02, -6.7930e-02, -8.2183e-02, -5.6574e-02, -9.4692e-02,\n","          1.7621e-02, -3.1185e-02, -8.5019e-02,  9.4946e-02,  9.2544e-02,\n","         -4.0547e-02, -3.5450e-02,  8.7012e-03, -7.7085e-02,  7.3096e-02,\n","         -7.1997e-02,  3.8798e-02, -8.4740e-02, -2.8832e-02, -7.5049e-02,\n","         -6.9656e-02,  9.5774e-02, -3.8677e-02,  6.0808e-02,  9.4806e-02,\n","         -4.9833e-02, -3.1621e-02,  9.3813e-02, -6.9384e-02, -9.3193e-03],\n","        [-3.7745e-02, -7.9007e-02, -1.7935e-02,  6.8221e-02, -9.0862e-02,\n","         -6.8590e-02,  5.1396e-02,  7.7880e-02, -9.4537e-02,  6.0982e-03,\n","          2.9019e-02, -8.7506e-02,  6.8044e-02, -9.6501e-02,  4.1874e-02,\n","          2.8795e-02, -7.7057e-02, -4.1877e-02,  5.0183e-02,  6.6718e-02,\n","          2.0940e-02, -9.5209e-02, -1.9943e-02,  8.4095e-02, -9.0228e-02,\n","          3.4417e-02,  5.2373e-02, -8.8105e-04,  5.8477e-02, -6.2850e-02,\n","          8.4223e-02, -9.5687e-02, -2.4482e-02, -7.8081e-02,  7.9597e-02,\n","          7.3302e-02, -5.9369e-02, -9.9129e-02, -6.3159e-02, -3.4013e-02,\n","         -1.7812e-02,  6.3520e-02, -5.9161e-02, -1.3957e-02, -6.4666e-02,\n","         -4.7442e-04,  6.0808e-02,  3.7877e-02, -6.4255e-02, -1.6429e-02,\n","          2.5644e-02,  7.2984e-02,  6.0184e-02, -8.8059e-02, -1.7612e-04,\n","          1.4169e-02,  1.3707e-02,  4.0183e-03, -7.9349e-02,  3.1504e-02,\n","          6.0621e-02,  2.9338e-03, -2.1643e-02,  6.5091e-02,  3.2192e-02,\n","         -3.1672e-02, -6.6403e-02,  4.1171e-02, -5.7829e-02,  3.3459e-02,\n","         -8.2749e-02,  6.7642e-02, -7.0015e-02,  1.8995e-02, -2.2135e-02,\n","          6.3580e-02,  9.7481e-02, -9.5915e-02,  1.7965e-02,  7.9938e-02,\n","          8.7038e-02, -7.5593e-02,  6.1347e-02, -2.1588e-02, -8.8184e-02,\n","         -7.1365e-02,  5.0654e-02, -8.8025e-02,  5.5075e-02, -8.3050e-02,\n","          9.2819e-02, -4.7950e-02,  3.8860e-03, -9.7744e-02, -7.4342e-02,\n","          5.2791e-02, -2.1618e-02,  2.3624e-02,  7.2822e-02, -5.7874e-02],\n","        [-2.3270e-02, -1.5211e-03,  4.1247e-02,  1.9910e-02, -1.9437e-02,\n","          8.8854e-02, -9.8614e-02,  5.6692e-03,  4.9072e-02, -4.2134e-02,\n","         -7.2613e-02, -6.7751e-02,  1.4715e-03,  8.6936e-02, -5.6619e-02,\n","         -8.2791e-02,  1.9850e-02,  6.4453e-02,  7.8848e-02, -4.4176e-02,\n","         -1.6888e-03,  3.1146e-02, -4.6494e-02, -4.0280e-02, -5.5082e-02,\n","         -4.7983e-02,  1.3688e-02, -8.2617e-02, -3.1518e-02,  2.5145e-02,\n","         -2.5668e-02, -6.8683e-02, -1.3039e-02, -8.6417e-02,  8.1937e-02,\n","          6.1219e-02,  7.5593e-02,  5.3760e-02, -1.8178e-02,  7.2424e-02,\n","         -4.9915e-04,  1.8730e-02, -2.2597e-02, -1.4228e-02,  8.8367e-02,\n","         -3.0545e-02,  5.3947e-02,  8.5745e-02,  6.6053e-02, -3.2359e-02,\n","          7.6245e-02,  7.8341e-02, -2.8932e-02, -6.8282e-02, -5.8860e-02,\n","          4.4998e-02, -6.3171e-02, -8.1229e-02,  1.4758e-02,  4.3752e-02,\n","         -8.5168e-02, -3.8906e-03, -1.4217e-02,  6.2258e-02, -2.4902e-03,\n","          3.6246e-02,  5.4489e-02, -7.9997e-02, -8.1948e-02, -4.3276e-02,\n","         -7.6598e-02,  4.6952e-03,  2.6509e-02, -8.0612e-02, -7.7331e-02,\n","          4.3601e-02, -5.4205e-02, -1.4563e-02, -1.1350e-03, -4.4241e-02,\n","         -3.3826e-02, -3.9662e-02, -4.4156e-02, -8.6949e-02, -8.3765e-02,\n","          9.8169e-02, -2.1302e-02, -5.2295e-02, -7.6495e-02,  2.2235e-02,\n","          1.9128e-03, -1.6625e-02,  3.9996e-03,  1.1191e-02, -3.9572e-02,\n","          8.5813e-03,  7.1226e-02,  7.7405e-02, -8.5258e-02,  6.7660e-02],\n","        [ 7.8416e-03,  1.2034e-02,  8.2138e-02, -3.5759e-02, -2.0921e-02,\n","          7.2613e-02, -7.2832e-04, -3.1847e-03,  3.6389e-02, -9.4404e-02,\n","          9.1278e-02,  9.2122e-02, -2.1923e-02,  8.1143e-02,  4.8857e-02,\n","         -2.4481e-02,  7.3477e-03,  3.0317e-02, -8.8428e-02,  4.7145e-02,\n","          2.5772e-02,  6.5719e-02,  1.9353e-02,  3.0849e-02, -9.5636e-02,\n","          8.7274e-02, -1.8570e-02,  2.7611e-02,  5.5938e-02,  7.1570e-02,\n","          9.8848e-02,  7.0887e-02, -9.6928e-02, -6.4049e-02, -4.0442e-02,\n","          1.0175e-02, -6.8428e-02, -6.2817e-02, -8.2198e-02, -1.7435e-02,\n","         -8.0656e-02, -7.7271e-02, -1.0531e-02, -7.3998e-02,  2.5480e-02,\n","          8.6857e-02, -3.2961e-02,  9.4465e-02, -5.0641e-02,  1.0545e-02,\n","         -3.4710e-02,  5.8775e-02,  8.7024e-02,  1.0644e-02, -4.8731e-03,\n","          6.0092e-02, -9.9729e-02, -5.0344e-03,  1.2238e-02,  9.4780e-02,\n","         -5.3323e-03, -5.2668e-02,  9.1019e-02, -7.5829e-02, -5.8037e-02,\n","          7.5552e-02,  2.1613e-02,  2.8930e-03,  2.0486e-02,  2.2625e-02,\n","         -7.9617e-02,  5.8514e-02,  9.8570e-02, -4.8506e-02,  8.5897e-02,\n","         -9.6173e-02, -9.1424e-02, -2.9320e-02, -8.3531e-02,  6.1074e-02,\n","         -8.1568e-02, -4.6341e-02, -6.3764e-02, -2.3561e-02, -6.6538e-02,\n","          5.4579e-02,  6.2349e-02, -1.8254e-02,  9.6255e-02,  8.4739e-02,\n","          1.1746e-02, -1.8906e-02, -8.3243e-02, -9.6534e-02,  7.4305e-02,\n","          4.1302e-02,  4.1058e-02, -1.0615e-02,  6.3407e-02, -2.0454e-03]],\n","       device='cuda:0', requires_grad=True)\n","Bias vector for clf.linear.bias:\n","Parameter containing:\n","tensor([ 0.0163,  0.0140, -0.0578, -0.0828], device='cuda:0',\n","       requires_grad=True)\n"]}]},{"cell_type":"code","source":["novi_param = []\n","poz = []\n","for i in range(len(weights1)):\n","    print(weights1[i].size)\n","    novi = torch.where(weights1[i] > 0, torch.tensor(1), torch.tensor(-1))\n","    a = novi.cpu()\n","    novi_np = a.detach().numpy()\n","\n","    novi_np = np.asarray(novi_np).astype(np.float32)\n","    print(novi_np.shape)\n","    #novi = np.asarray(novi).astype(np.float32)\n","    print(novi_np)\n","    #print(int(novi_np.numel()))\n","    poz.append(i)\n","    novi_param.append(novi_np)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5iMDkeZ03zoL","executionInfo":{"status":"ok","timestamp":1698925441107,"user_tz":-60,"elapsed":385,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"0f1a6954-605b-4bfa-fe4a-44ac4b8768b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<built-in method size of Tensor object at 0x7efd4017be70>\n","(151800,)\n","[-1. -1. -1. ...  1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd40148b30>\n","(1380,)\n","[1. 1. 1. ... 1. 1. 1.]\n","<built-in method size of Tensor object at 0x7efd40194a40>\n","(5713200,)\n","[-1.  1. -1. ...  1.  1. -1.]\n","<built-in method size of Tensor object at 0x7efd401949a0>\n","(1904400,)\n","[-1. -1. -1. ...  1. -1. -1.]\n","<built-in method size of Tensor object at 0x7efd401949f0>\n","(2826240,)\n","[-1.  1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd401940e0>\n","(2826240,)\n","[ 1. -1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd40195260>\n","(1380,)\n","[1. 1. 1. ... 1. 1. 1.]\n","<built-in method size of Tensor object at 0x7efd401947c0>\n","(1380,)\n","[1. 1. 1. ... 1. 1. 1.]\n","<built-in method size of Tensor object at 0x7efd401951c0>\n","(5713200,)\n","[-1.  1. -1. ...  1.  1. -1.]\n","<built-in method size of Tensor object at 0x7efd40194130>\n","(1904400,)\n","[-1. -1. -1. ...  1. -1. -1.]\n","<built-in method size of Tensor object at 0x7efd401948b0>\n","(2826240,)\n","[-1.  1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd40194bd0>\n","(2826240,)\n","[ 1. -1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd40195620>\n","(1380,)\n","[1. 1. 1. ... 1. 1. 1.]\n","<built-in method size of Tensor object at 0x7efd40194180>\n","(1380,)\n","[1. 1. 1. ... 1. 1. 1.]\n","<built-in method size of Tensor object at 0x7efd40194c20>\n","(138000,)\n","[ 1.  1. -1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efe50090b30>\n","(80000,)\n","[ 1. -1.  1. ...  1. -1. -1.]\n","<built-in method size of Tensor object at 0x7efd40194cc0>\n","(10000,)\n","[-1.  1.  1. ... -1.  1. -1.]\n","<built-in method size of Tensor object at 0x7efd40194540>\n","(10000,)\n","[-1.  1.  1. ... -1.  1. -1.]\n","<built-in method size of Tensor object at 0x7efd40194310>\n","(10000,)\n","[ 1. -1.  1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd40194270>\n","(10000,)\n","[ 1. -1. -1. ... -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd40194360>\n","(100,)\n","[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1.]\n","<built-in method size of Tensor object at 0x7efd40194220>\n","(10000,)\n","[-1.  1. -1. ...  1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd40197100>\n","(10000,)\n","[-1.  1. -1. ... -1. -1.  1.]\n","<built-in method size of Tensor object at 0x7efd401970b0>\n","(400,)\n","[-1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1.\n","  1. -1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.\n"," -1.  1. -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.\n"," -1.  1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.\n","  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n"," -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.\n"," -1.  1.  1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.\n","  1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.\n","  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.\n","  1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.\n","  1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1.\n","  1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n"," -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1.\n","  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1.  1.\n","  1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.\n"," -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.\n","  1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n","  1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1.\n"," -1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.\n","  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.\n","  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.\n"," -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.\n"," -1. -1.  1. -1.]\n","<built-in method size of Tensor object at 0x7efd40194400>\n","(700,)\n","[ 1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.\n","  1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.\n","  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.\n"," -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.\n","  1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1.\n"," -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1.\n","  1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1.\n","  1. -1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.\n"," -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.\n"," -1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.\n"," -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1.  1.\n"," -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1.\n","  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.\n","  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.\n","  1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.\n","  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.\n"," -1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.\n","  1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.\n","  1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.\n"," -1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.\n","  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.\n"," -1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n","  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.\n","  1. -1. -1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.\n","  1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1.\n","  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.\n"," -1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n"," -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1.\n"," -1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1.\n","  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.  1.\n"," -1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.\n"," -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.\n"," -1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1.  1.\n","  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.\n"," -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1. -1. -1.\n","  1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1.\n","  1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.\n","  1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.\n"," -1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1.]\n","<built-in method size of Tensor object at 0x7efd401955d0>\n","(400,)\n","[-1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.\n","  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1.\n","  1.  1.  1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.\n","  1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1.\n"," -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1.\n"," -1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.\n"," -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1. -1.  1.\n","  1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.\n"," -1. -1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n"," -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.\n","  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1.\n","  1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.\n","  1.  1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.\n","  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.\n"," -1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.\n"," -1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n"," -1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.\n"," -1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.\n"," -1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n"," -1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.\n"," -1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1. -1.\n"," -1.  1. -1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.\n","  1. -1.  1. -1.]\n"]}]},{"cell_type":"code","source":["i=0\n","with torch.no_grad():\n","  for name, params in model.named_parameters():\n","    if 'weight' in name:\n","      print(name)\n","      print(params.shape)\n","\n","      print(i)\n","      velicina = params.shape\n","      novi_param[i] = np.asarray(novi_param[i]).astype(np.float32)\n","      print(novi_param[i].dtype)\n","      novi_reshaped = np.reshape(novi_param[i], velicina)\n","      params.data.copy_(torch.from_numpy(novi_reshaped))\n","      i=i+1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNAMHweh3zzB","executionInfo":{"status":"ok","timestamp":1698925488545,"user_tz":-60,"elapsed":470,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"6bea1930-306d-451c-8d32-257352341e96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rnn.encoding_layer.weight\n","torch.Size([110, 1380])\n","0\n","float32\n","rnn.LayerNorm.weight\n","torch.Size([1380])\n","1\n","float32\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_weight\n","torch.Size([4140, 1380])\n","2\n","float32\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.weight\n","torch.Size([1380, 1380])\n","3\n","float32\n","rnn.transformer_encoder.layers.0.linear1.weight\n","torch.Size([2048, 1380])\n","4\n","float32\n","rnn.transformer_encoder.layers.0.linear2.weight\n","torch.Size([1380, 2048])\n","5\n","float32\n","rnn.transformer_encoder.layers.0.norm1.weight\n","torch.Size([1380])\n","6\n","float32\n","rnn.transformer_encoder.layers.0.norm2.weight\n","torch.Size([1380])\n","7\n","float32\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_weight\n","torch.Size([4140, 1380])\n","8\n","float32\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.weight\n","torch.Size([1380, 1380])\n","9\n","float32\n","rnn.transformer_encoder.layers.1.linear1.weight\n","torch.Size([2048, 1380])\n","10\n","float32\n","rnn.transformer_encoder.layers.1.linear2.weight\n","torch.Size([1380, 2048])\n","11\n","float32\n","rnn.transformer_encoder.layers.1.norm1.weight\n","torch.Size([1380])\n","12\n","float32\n","rnn.transformer_encoder.layers.1.norm2.weight\n","torch.Size([1380])\n","13\n","float32\n","rnn.transformer_out.weight\n","torch.Size([100, 1380])\n","14\n","float32\n","gcn.conv1.weight\n","torch.Size([8, 100, 100])\n","15\n","float32\n","gcn.conv2.lin_key.weight\n","torch.Size([100, 100])\n","16\n","float32\n","gcn.conv2.lin_query.weight\n","torch.Size([100, 100])\n","17\n","float32\n","gcn.conv2.lin_value.weight\n","torch.Size([100, 100])\n","18\n","float32\n","gcn.conv2.lin_skip.weight\n","torch.Size([100, 100])\n","19\n","float32\n","gcn.bn.weight\n","torch.Size([100])\n","20\n","float32\n","clf.emotion_att.lin.weight\n","torch.Size([100, 100])\n","21\n","float32\n","clf.lin1.weight\n","torch.Size([100, 100])\n","22\n","float32\n","clf.lin2.weight\n","torch.Size([4, 100])\n","23\n","float32\n","clf.lin_7.weight\n","torch.Size([7, 100])\n","24\n","float32\n","clf.linear.weight\n","torch.Size([4, 100])\n","25\n","float32\n"]}]},{"cell_type":"code","source":["for name, params in model.named_parameters():\n","  print(name)\n","  print(params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42ulhEYa4AoK","executionInfo":{"status":"ok","timestamp":1698925494559,"user_tz":-60,"elapsed":386,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"6bd71875-533f-4fae-c7d0-444622e4f2e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rnn.encoding_layer.weight\n","Parameter containing:\n","tensor([[-1., -1., -1.,  ...,  1.,  1., -1.],\n","        [ 1., -1., -1.,  ...,  1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n","        ...,\n","        [ 1.,  1., -1.,  ..., -1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [-1.,  1., -1.,  ...,  1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.LayerNorm.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.LayerNorm.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_weight\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        ...,\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.in_proj_bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.weight\n","Parameter containing:\n","tensor([[-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1., -1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1., -1.],\n","        [-1.,  1.,  1.,  ..., -1.,  1., -1.],\n","        [-1.,  1.,  1.,  ...,  1., -1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.0.self_attn.out_proj.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear1.weight\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ..., -1., -1., -1.],\n","        [ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1., -1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear1.bias\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear2.weight\n","Parameter containing:\n","tensor([[ 1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1., -1.,  ..., -1., -1.,  1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1.,  1.],\n","        [-1., -1., -1.,  ...,  1.,  1., -1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.0.linear2.bias\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm1.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm1.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm2.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.0.norm2.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_weight\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        ...,\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.in_proj_bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.weight\n","Parameter containing:\n","tensor([[-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1., -1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1., -1.],\n","        [-1.,  1.,  1.,  ..., -1.,  1., -1.],\n","        [-1.,  1.,  1.,  ...,  1., -1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.1.self_attn.out_proj.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear1.weight\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ..., -1., -1., -1.],\n","        [ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1., -1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear1.bias\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear2.weight\n","Parameter containing:\n","tensor([[ 1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1., -1.,  ..., -1., -1.,  1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1.,  1.],\n","        [-1., -1., -1.,  ...,  1.,  1., -1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_encoder.layers.1.linear2.bias\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm1.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm1.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm2.weight\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","rnn.transformer_encoder.layers.1.norm2.bias\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","rnn.transformer_out.weight\n","Parameter containing:\n","tensor([[ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1., -1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        ...,\n","        [ 1., -1.,  1.,  ..., -1., -1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1.,  1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","rnn.transformer_out.bias\n","Parameter containing:\n","tensor([-0.0237, -0.0019,  0.0154, -0.0216,  0.0066, -0.0017,  0.0199,  0.0266,\n","         0.0194, -0.0110,  0.0025, -0.0085,  0.0250, -0.0166, -0.0241,  0.0258,\n","         0.0260, -0.0247, -0.0003, -0.0005,  0.0119,  0.0039, -0.0158, -0.0170,\n","        -0.0240, -0.0061,  0.0159,  0.0231,  0.0239, -0.0204,  0.0044, -0.0196,\n","         0.0142,  0.0097, -0.0032,  0.0267, -0.0169,  0.0210, -0.0201,  0.0115,\n","        -0.0181,  0.0268, -0.0008, -0.0108,  0.0223, -0.0038, -0.0031, -0.0022,\n","        -0.0057, -0.0128, -0.0033,  0.0261,  0.0150, -0.0189, -0.0142, -0.0236,\n","         0.0166, -0.0081,  0.0063,  0.0098,  0.0240, -0.0096,  0.0039,  0.0220,\n","        -0.0135, -0.0248,  0.0123,  0.0050, -0.0178, -0.0239, -0.0010,  0.0140,\n","        -0.0104,  0.0111, -0.0201, -0.0107, -0.0067, -0.0072, -0.0202,  0.0213,\n","        -0.0018, -0.0013, -0.0051, -0.0153,  0.0069,  0.0127, -0.0123, -0.0153,\n","         0.0236, -0.0034, -0.0097,  0.0066,  0.0089,  0.0014,  0.0149, -0.0040,\n","        -0.0189,  0.0242, -0.0119,  0.0069], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv1.weight\n","Parameter containing:\n","tensor([[[ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","         [-1.,  1.,  1.,  ...,  1., -1.,  1.],\n","         [-1.,  1.,  1.,  ..., -1., -1., -1.],\n","         ...,\n","         [ 1.,  1., -1.,  ...,  1., -1.,  1.],\n","         [-1.,  1.,  1.,  ..., -1.,  1.,  1.],\n","         [ 1., -1., -1.,  ...,  1.,  1.,  1.]],\n","\n","        [[ 1., -1., -1.,  ...,  1., -1.,  1.],\n","         [-1.,  1., -1.,  ..., -1., -1., -1.],\n","         [ 1.,  1., -1.,  ...,  1., -1.,  1.],\n","         ...,\n","         [-1., -1., -1.,  ..., -1., -1.,  1.],\n","         [-1., -1., -1.,  ...,  1., -1., -1.],\n","         [-1.,  1., -1.,  ..., -1., -1.,  1.]],\n","\n","        [[-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","         [ 1., -1., -1.,  ..., -1., -1., -1.],\n","         [ 1., -1., -1.,  ...,  1.,  1.,  1.],\n","         ...,\n","         [ 1.,  1.,  1.,  ..., -1., -1.,  1.],\n","         [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n","         [ 1.,  1., -1.,  ..., -1.,  1., -1.]],\n","\n","        ...,\n","\n","        [[ 1., -1., -1.,  ...,  1.,  1., -1.],\n","         [ 1.,  1.,  1.,  ..., -1.,  1.,  1.],\n","         [-1., -1.,  1.,  ...,  1., -1.,  1.],\n","         ...,\n","         [-1.,  1., -1.,  ..., -1., -1., -1.],\n","         [-1., -1., -1.,  ...,  1.,  1.,  1.],\n","         [ 1., -1.,  1.,  ..., -1., -1., -1.]],\n","\n","        [[-1., -1., -1.,  ...,  1.,  1., -1.],\n","         [ 1.,  1., -1.,  ..., -1., -1.,  1.],\n","         [-1.,  1., -1.,  ..., -1.,  1., -1.],\n","         ...,\n","         [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","         [-1., -1.,  1.,  ...,  1., -1., -1.],\n","         [-1.,  1.,  1.,  ..., -1., -1., -1.]],\n","\n","        [[ 1.,  1., -1.,  ...,  1., -1., -1.],\n","         [ 1., -1.,  1.,  ..., -1., -1., -1.],\n","         [-1., -1.,  1.,  ...,  1., -1., -1.],\n","         ...,\n","         [-1., -1.,  1.,  ..., -1., -1.,  1.],\n","         [ 1.,  1.,  1.,  ..., -1., -1.,  1.],\n","         [-1.,  1.,  1.,  ...,  1., -1., -1.]]], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv1.root\n","Parameter containing:\n","tensor([[ 0.0274, -0.0502, -0.0844,  ..., -0.0995, -0.0979, -0.1528],\n","        [-0.1539,  0.1320,  0.0259,  ..., -0.0222,  0.0257, -0.1293],\n","        [ 0.0880,  0.1243,  0.1588,  ..., -0.0705, -0.1279, -0.0586],\n","        ...,\n","        [ 0.0058, -0.0671, -0.1112,  ..., -0.0300,  0.0224,  0.0741],\n","        [ 0.0670, -0.0065, -0.0570,  ..., -0.0187,  0.0265,  0.1021],\n","        [ 0.0439,  0.1176, -0.0520,  ...,  0.0585, -0.0172, -0.0924]],\n","       device='cuda:0', requires_grad=True)\n","gcn.conv1.bias\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","gcn.conv2.lin_key.weight\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ...,  1., -1., -1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1.,  1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1.,  1., -1.,  ...,  1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1., -1., -1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_key.bias\n","Parameter containing:\n","tensor([-0.0991, -0.0645,  0.0659,  0.0654, -0.0402, -0.0288,  0.0769, -0.0589,\n","        -0.0395,  0.0581, -0.0294,  0.0154, -0.0524, -0.0345, -0.0896, -0.0972,\n","         0.0742, -0.0360, -0.0624,  0.0558, -0.0155,  0.0944, -0.0256,  0.0330,\n","        -0.0339,  0.0102, -0.0313,  0.0378,  0.0945,  0.0516,  0.0905, -0.0068,\n","        -0.0480,  0.0047, -0.0101,  0.0159,  0.0123,  0.0081, -0.0227,  0.0719,\n","        -0.0500, -0.0148,  0.0014, -0.0990, -0.0476, -0.0772,  0.0749,  0.0579,\n","         0.0348,  0.0828,  0.0040, -0.0983,  0.0519,  0.0715, -0.0695,  0.0353,\n","         0.0111,  0.0414,  0.0267,  0.0704,  0.0966,  0.0561, -0.0895, -0.0112,\n","         0.0244, -0.0855,  0.0741, -0.0169,  0.0806,  0.0364, -0.0460, -0.0708,\n","        -0.0234, -0.0690,  0.0912, -0.0198,  0.0560, -0.0923, -0.0191,  0.0723,\n","        -0.0498, -0.0692, -0.0081, -0.0869, -0.0146, -0.0728, -0.0717, -0.0291,\n","         0.0041, -0.0866,  0.0837, -0.0719,  0.0169, -0.0703, -0.0148,  0.0263,\n","         0.0859, -0.0849,  0.0308,  0.0992], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_query.weight\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ...,  1.,  1., -1.],\n","        [-1.,  1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","        ...,\n","        [-1.,  1.,  1.,  ..., -1.,  1., -1.],\n","        [-1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_query.bias\n","Parameter containing:\n","tensor([ 0.0844, -0.0540,  0.0126, -0.0950,  0.0963,  0.0158,  0.0484, -0.0252,\n","        -0.0592, -0.0308, -0.0575,  0.0020,  0.0458,  0.0818,  0.0884, -0.0058,\n","        -0.0778,  0.0817, -0.0452,  0.0860,  0.0510,  0.0915, -0.0950,  0.0601,\n","         0.0545,  0.0739, -0.0680,  0.0799,  0.0136,  0.0287, -0.0594, -0.0541,\n","         0.0699, -0.0706,  0.0047,  0.0079,  0.0449, -0.0395,  0.0789, -0.0041,\n","         0.0744, -0.0185, -0.0451,  0.0060, -0.0579,  0.0737, -0.0798, -0.0454,\n","        -0.0783,  0.0356,  0.0202, -0.0507, -0.0163, -0.0913,  0.0450, -0.0299,\n","         0.0291, -0.0776, -0.0830,  0.0933,  0.0382,  0.0338,  0.0806,  0.0377,\n","        -0.0619,  0.0079, -0.0473,  0.0775,  0.0367, -0.0272, -0.0228,  0.0356,\n","         0.0633,  0.0148, -0.0781,  0.0601, -0.0574, -0.0071,  0.0348,  0.0293,\n","        -0.0004,  0.0148, -0.0091, -0.0914,  0.0584, -0.0131,  0.0069,  0.0793,\n","         0.0437, -0.0174,  0.0669, -0.0204, -0.0894, -0.0581,  0.0307,  0.0181,\n","        -0.0044,  0.0399,  0.0194,  0.0123], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_value.weight\n","Parameter containing:\n","tensor([[ 1., -1.,  1.,  ...,  1.,  1.,  1.],\n","        [-1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1., -1.],\n","        ...,\n","        [-1., -1., -1.,  ..., -1., -1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1., -1.],\n","        [-1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_value.bias\n","Parameter containing:\n","tensor([ 0.0306, -0.0675,  0.0779, -0.0751,  0.0946,  0.0238,  0.0302,  0.0231,\n","         0.0905, -0.0692, -0.0250, -0.0581, -0.0854,  0.0074,  0.0140, -0.0213,\n","         0.0408, -0.0691, -0.0963,  0.0497,  0.0574,  0.0611, -0.0365,  0.0188,\n","         0.0154,  0.0268, -0.0787, -0.0108,  0.0175,  0.0115,  0.0355,  0.0209,\n","         0.0909,  0.0026, -0.0055, -0.0443, -0.0840, -0.0966,  0.0668,  0.0801,\n","         0.0125,  0.0825, -0.0179,  0.0365, -0.0724,  0.0683,  0.0884, -0.0132,\n","         0.0536, -0.0181, -0.0505, -0.0995,  0.0074,  0.0134,  0.0057,  0.0421,\n","        -0.0250, -0.0813,  0.0889, -0.0230,  0.0081,  0.0937,  0.0527,  0.0064,\n","        -0.0635,  0.0295,  0.0940,  0.0128, -0.0440, -0.0997,  0.0727, -0.0642,\n","         0.0064, -0.0042,  0.0485,  0.0016, -0.0898,  0.0380, -0.0373,  0.0329,\n","        -0.0438, -0.0771,  0.0502,  0.0544,  0.0896,  0.0860,  0.0351, -0.0568,\n","        -0.0504, -0.0295,  0.0136,  0.0565,  0.0154, -0.0799,  0.0566,  0.0004,\n","        -0.0276, -0.0160,  0.0806, -0.0563], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_skip.weight\n","Parameter containing:\n","tensor([[ 1., -1., -1.,  ...,  1., -1., -1.],\n","        [-1., -1.,  1.,  ..., -1., -1., -1.],\n","        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n","        ...,\n","        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","gcn.conv2.lin_skip.bias\n","Parameter containing:\n","tensor([-0.0308,  0.0801,  0.0266, -0.0314,  0.0104,  0.0130, -0.0156,  0.0803,\n","         0.0438, -0.0490, -0.0382, -0.0941, -0.0902, -0.0199, -0.0012,  0.0091,\n","        -0.0841,  0.0825,  0.0716,  0.0114,  0.0145,  0.0292, -0.0095, -0.0523,\n","        -0.0435,  0.0970, -0.0484, -0.0765,  0.0037,  0.0982,  0.0957, -0.0860,\n","         0.0990, -0.0020,  0.0885,  0.0925, -0.0574,  0.0311,  0.0379,  0.0964,\n","         0.0221, -0.0952, -0.0198,  0.0791,  0.0117, -0.0456, -0.0678, -0.0059,\n","        -0.0833, -0.0743,  0.0641,  0.0344,  0.0156,  0.0787, -0.0277, -0.0554,\n","         0.0258,  0.0452,  0.0385, -0.0764,  0.0068, -0.0177, -0.0807,  0.0157,\n","         0.0582, -0.0685, -0.0224,  0.0935, -0.0355, -0.0810,  0.0225,  0.0638,\n","        -0.0300,  0.0542, -0.0498,  0.0452,  0.0785, -0.0273,  0.0495,  0.0386,\n","        -0.0396, -0.0357,  0.0272,  0.0535, -0.0344,  0.0526,  0.0696,  0.0649,\n","        -0.0151, -0.0117, -0.0287, -0.0673, -0.0992,  0.0611, -0.0836,  0.0084,\n","         0.0388, -0.0170, -0.0613,  0.0066], device='cuda:0',\n","       requires_grad=True)\n","gcn.bn.weight\n","Parameter containing:\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n","       requires_grad=True)\n","gcn.bn.bias\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","clf.emotion_att.lin.weight\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ..., -1.,  1., -1.],\n","        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1.,  1., -1.,  ...,  1., -1., -1.],\n","        [-1., -1.,  1.,  ..., -1., -1., -1.],\n","        [-1.,  1., -1.,  ...,  1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","clf.emotion_att.lin.bias\n","Parameter containing:\n","tensor([ 0.0310,  0.0380, -0.0270,  0.0616,  0.0820,  0.0194,  0.0414,  0.0748,\n","         0.0330,  0.0831,  0.0034,  0.0888,  0.0091,  0.0931, -0.0020, -0.0580,\n","         0.0661, -0.0747, -0.0491,  0.0810,  0.0530,  0.0116, -0.0121,  0.0282,\n","        -0.0779,  0.0609, -0.0757, -0.0821,  0.0575,  0.0776,  0.0181, -0.0829,\n","         0.0946, -0.0726, -0.0235,  0.0449, -0.0922,  0.0536, -0.0730,  0.0249,\n","         0.0904,  0.0433, -0.0917,  0.0633,  0.0089,  0.0950,  0.0087, -0.0402,\n","        -0.0597,  0.0468,  0.0204,  0.0430,  0.0969,  0.0721, -0.0305,  0.0817,\n","        -0.0891,  0.0436,  0.0550, -0.0598,  0.0487,  0.0882, -0.0499,  0.0563,\n","        -0.0053, -0.0135,  0.0023,  0.0129,  0.0088,  0.0951,  0.0256,  0.0588,\n","         0.0467, -0.0100,  0.0629,  0.0385,  0.0327, -0.0063,  0.0411,  0.0238,\n","        -0.0555,  0.0076, -0.0277,  0.0397,  0.0540, -0.0323,  0.0654,  0.0193,\n","         0.0073, -0.0495,  0.0974,  0.0709, -0.0407,  0.0425, -0.0466, -0.0998,\n","        -0.0476,  0.0579,  0.0170, -0.0154], device='cuda:0',\n","       requires_grad=True)\n","clf.lin1.weight\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ...,  1.,  1., -1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1.,  1.,  ...,  1., -1., -1.],\n","        ...,\n","        [ 1., -1., -1.,  ...,  1., -1., -1.],\n","        [-1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ..., -1., -1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","clf.lin1.bias\n","Parameter containing:\n","tensor([ 0.0762,  0.0880,  0.0464, -0.0047, -0.0801,  0.0563, -0.0795,  0.0890,\n","        -0.0352,  0.0643,  0.0485, -0.0053,  0.0714,  0.0026, -0.0216, -0.0704,\n","        -0.0150, -0.0501,  0.0022, -0.0042, -0.0394, -0.0176, -0.0425, -0.0123,\n","         0.0639,  0.0825,  0.0975,  0.0034, -0.0228,  0.0310, -0.0805, -0.0970,\n","         0.0286,  0.0184, -0.0883, -0.0630, -0.0171,  0.0793, -0.0963,  0.0190,\n","        -0.0941,  0.0329, -0.0340,  0.0827, -0.0255, -0.0977, -0.0589, -0.0200,\n","         0.0264,  0.0662, -0.0427, -0.0884,  0.0804, -0.0999,  0.0478, -0.0508,\n","        -0.0996, -0.0331,  0.0474, -0.0676, -0.0393,  0.0500,  0.0556, -0.0434,\n","         0.0044,  0.0449, -0.0820,  0.0411,  0.0597, -0.0488, -0.0330, -0.0831,\n","        -0.0663,  0.0483,  0.0922,  0.0776,  0.0448,  0.0970, -0.0049,  0.0961,\n","        -0.0691, -0.0696,  0.0078,  0.0822,  0.0409, -0.0339, -0.0016,  0.0115,\n","         0.0268,  0.0511, -0.0959,  0.0652, -0.0786, -0.0495,  0.0145, -0.0486,\n","        -0.0473,  0.0061, -0.0123, -0.0757], device='cuda:0',\n","       requires_grad=True)\n","clf.lin2.weight\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","         -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,\n","          1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n","         -1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n","          1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n","         -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n","         -1.,  1.],\n","        [-1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","          1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n","         -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n","         -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,\n","          1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,\n","         -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n","         -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n","          1.,  1.],\n","        [ 1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n","          1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n","         -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n","          1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n","         -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n","         -1., -1.],\n","        [ 1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n","          1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n","         -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,\n","          1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,\n","          1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","         -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n","          1., -1.]], device='cuda:0', requires_grad=True)\n","clf.lin2.bias\n","Parameter containing:\n","tensor([-0.0843,  0.0371, -0.0800, -0.0725], device='cuda:0',\n","       requires_grad=True)\n","clf.lin_7.weight\n","Parameter containing:\n","tensor([[ 1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n","         -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n","         -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n","          1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n","         -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,\n","         -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.,\n","         -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","         -1., -1.],\n","        [ 1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n","         -1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","         -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,\n","          1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.,\n","         -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n","         -1., -1.],\n","        [-1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n","          1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n","          1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n","          1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,\n","          1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,\n","          1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,\n","         -1., -1.],\n","        [ 1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","         -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n","         -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,\n","          1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,\n","         -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n","         -1., -1.],\n","        [ 1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n","         -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n","         -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n","          1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n","          1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,\n","          1., -1.],\n","        [ 1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n","         -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,\n","         -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.,\n","          1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.,\n","          1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n","          1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n","          1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n","          1.,  1.],\n","        [-1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,\n","          1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,\n","          1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,\n","         -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n","         -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,\n","         -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,\n","          1.,  1.]], device='cuda:0', requires_grad=True)\n","clf.lin_7.bias\n","Parameter containing:\n","tensor([-0.0149, -0.0465,  0.0099,  0.0570,  0.0250,  0.0233,  0.0425],\n","       device='cuda:0', requires_grad=True)\n","clf.linear.weight\n","Parameter containing:\n","tensor([[-1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n","         -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n","         -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n","         -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,\n","          1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n","          1., -1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","         -1., -1.],\n","        [-1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n","          1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,\n","          1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,\n","         -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n","          1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n","         -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n","         -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n","          1., -1.],\n","        [-1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n","         -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","         -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,\n","         -1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","         -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n","         -1.,  1.],\n","        [ 1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n","          1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n","         -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n","         -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n","         -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n","         -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","          1., -1.]], device='cuda:0', requires_grad=True)\n","clf.linear.bias\n","Parameter containing:\n","tensor([ 0.0163,  0.0140, -0.0578, -0.0828], device='cuda:0',\n","       requires_grad=True)\n"]}]},{"cell_type":"code","source":["torch.save(model, '/content/drive/MyDrive/Master_2023_sept/COGMEN-main/new_model.pt')"],"metadata":{"id":"uYr_rkEeyNIC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.load('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/new_model.pt')"],"metadata":{"id":"qme42h4UsCWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights1, weights_vec, bias_vec = get_wb(model)"],"metadata":{"id":"OTifxvciEwTT","executionInfo":{"status":"ok","timestamp":1698925509241,"user_tz":-60,"elapsed":396,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"28c57b4f-71a7-490b-b0ce-ac69143d3c40","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weight matrix for rnn.encoding_layer.weight:\n","Parameter containing:\n","tensor([[-1., -1., -1.,  ...,  1.,  1., -1.],\n","        [ 1., -1., -1.,  ...,  1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n","        ...,\n","        [ 1.,  1., -1.,  ..., -1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [-1.,  1., -1.,  ...,  1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for rnn.LayerNorm.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.LayerNorm.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.self_attn.in_proj_weight:\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        ...,\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.self_attn.in_proj_bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.self_attn.out_proj.weight:\n","Parameter containing:\n","tensor([[-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1., -1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1., -1.],\n","        [-1.,  1.,  1.,  ..., -1.,  1., -1.],\n","        [-1.,  1.,  1.,  ...,  1., -1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.self_attn.out_proj.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.linear1.weight:\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ..., -1., -1., -1.],\n","        [ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1., -1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.linear1.bias:\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.linear2.weight:\n","Parameter containing:\n","tensor([[ 1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1., -1.,  ..., -1., -1.,  1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1.,  1.],\n","        [-1., -1., -1.,  ...,  1.,  1., -1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.linear2.bias:\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.norm1.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.norm1.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.0.norm2.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.0.norm2.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.self_attn.in_proj_weight:\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ...,  1., -1.,  1.],\n","        ...,\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.self_attn.in_proj_bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.self_attn.out_proj.weight:\n","Parameter containing:\n","tensor([[-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1., -1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1., -1.],\n","        [-1.,  1.,  1.,  ..., -1.,  1., -1.],\n","        [-1.,  1.,  1.,  ...,  1., -1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.self_attn.out_proj.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.linear1.weight:\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ..., -1., -1., -1.],\n","        [ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1., -1., -1.,  ..., -1., -1.,  1.],\n","        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1., -1., -1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.linear1.bias:\n","Parameter containing:\n","tensor([-0.0134,  0.0247, -0.0166,  ...,  0.0163,  0.0239,  0.0060],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.linear2.weight:\n","Parameter containing:\n","tensor([[ 1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1., -1.,  ..., -1., -1.,  1.],\n","        ...,\n","        [-1., -1.,  1.,  ...,  1.,  1.,  1.],\n","        [-1., -1., -1.,  ...,  1.,  1., -1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.linear2.bias:\n","Parameter containing:\n","tensor([ 0.0094, -0.0024, -0.0083,  ...,  0.0087,  0.0195,  0.0199],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.norm1.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.norm1.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_encoder.layers.1.norm2.weight:\n","Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","Bias vector for rnn.transformer_encoder.layers.1.norm2.bias:\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for rnn.transformer_out.weight:\n","Parameter containing:\n","tensor([[ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1., -1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        ...,\n","        [ 1., -1.,  1.,  ..., -1., -1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [ 1.,  1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for rnn.transformer_out.bias:\n","Parameter containing:\n","tensor([-0.0237, -0.0019,  0.0154, -0.0216,  0.0066, -0.0017,  0.0199,  0.0266,\n","         0.0194, -0.0110,  0.0025, -0.0085,  0.0250, -0.0166, -0.0241,  0.0258,\n","         0.0260, -0.0247, -0.0003, -0.0005,  0.0119,  0.0039, -0.0158, -0.0170,\n","        -0.0240, -0.0061,  0.0159,  0.0231,  0.0239, -0.0204,  0.0044, -0.0196,\n","         0.0142,  0.0097, -0.0032,  0.0267, -0.0169,  0.0210, -0.0201,  0.0115,\n","        -0.0181,  0.0268, -0.0008, -0.0108,  0.0223, -0.0038, -0.0031, -0.0022,\n","        -0.0057, -0.0128, -0.0033,  0.0261,  0.0150, -0.0189, -0.0142, -0.0236,\n","         0.0166, -0.0081,  0.0063,  0.0098,  0.0240, -0.0096,  0.0039,  0.0220,\n","        -0.0135, -0.0248,  0.0123,  0.0050, -0.0178, -0.0239, -0.0010,  0.0140,\n","        -0.0104,  0.0111, -0.0201, -0.0107, -0.0067, -0.0072, -0.0202,  0.0213,\n","        -0.0018, -0.0013, -0.0051, -0.0153,  0.0069,  0.0127, -0.0123, -0.0153,\n","         0.0236, -0.0034, -0.0097,  0.0066,  0.0089,  0.0014,  0.0149, -0.0040,\n","        -0.0189,  0.0242, -0.0119,  0.0069], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv1.weight:\n","Parameter containing:\n","tensor([[[ 1., -1.,  1.,  ...,  1., -1.,  1.],\n","         [-1.,  1.,  1.,  ...,  1., -1.,  1.],\n","         [-1.,  1.,  1.,  ..., -1., -1., -1.],\n","         ...,\n","         [ 1.,  1., -1.,  ...,  1., -1.,  1.],\n","         [-1.,  1.,  1.,  ..., -1.,  1.,  1.],\n","         [ 1., -1., -1.,  ...,  1.,  1.,  1.]],\n","\n","        [[ 1., -1., -1.,  ...,  1., -1.,  1.],\n","         [-1.,  1., -1.,  ..., -1., -1., -1.],\n","         [ 1.,  1., -1.,  ...,  1., -1.,  1.],\n","         ...,\n","         [-1., -1., -1.,  ..., -1., -1.,  1.],\n","         [-1., -1., -1.,  ...,  1., -1., -1.],\n","         [-1.,  1., -1.,  ..., -1., -1.,  1.]],\n","\n","        [[-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","         [ 1., -1., -1.,  ..., -1., -1., -1.],\n","         [ 1., -1., -1.,  ...,  1.,  1.,  1.],\n","         ...,\n","         [ 1.,  1.,  1.,  ..., -1., -1.,  1.],\n","         [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n","         [ 1.,  1., -1.,  ..., -1.,  1., -1.]],\n","\n","        ...,\n","\n","        [[ 1., -1., -1.,  ...,  1.,  1., -1.],\n","         [ 1.,  1.,  1.,  ..., -1.,  1.,  1.],\n","         [-1., -1.,  1.,  ...,  1., -1.,  1.],\n","         ...,\n","         [-1.,  1., -1.,  ..., -1., -1., -1.],\n","         [-1., -1., -1.,  ...,  1.,  1.,  1.],\n","         [ 1., -1.,  1.,  ..., -1., -1., -1.]],\n","\n","        [[-1., -1., -1.,  ...,  1.,  1., -1.],\n","         [ 1.,  1., -1.,  ..., -1., -1.,  1.],\n","         [-1.,  1., -1.,  ..., -1.,  1., -1.],\n","         ...,\n","         [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","         [-1., -1.,  1.,  ...,  1., -1., -1.],\n","         [-1.,  1.,  1.,  ..., -1., -1., -1.]],\n","\n","        [[ 1.,  1., -1.,  ...,  1., -1., -1.],\n","         [ 1., -1.,  1.,  ..., -1., -1., -1.],\n","         [-1., -1.,  1.,  ...,  1., -1., -1.],\n","         ...,\n","         [-1., -1.,  1.,  ..., -1., -1.,  1.],\n","         [ 1.,  1.,  1.,  ..., -1., -1.,  1.],\n","         [-1.,  1.,  1.,  ...,  1., -1., -1.]]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.conv1.bias:\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for gcn.conv2.lin_key.weight:\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ...,  1., -1., -1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1.,  1.],\n","        [ 1.,  1., -1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1.,  1., -1.,  ...,  1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1., -1., -1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.conv2.lin_key.bias:\n","Parameter containing:\n","tensor([-0.0991, -0.0645,  0.0659,  0.0654, -0.0402, -0.0288,  0.0769, -0.0589,\n","        -0.0395,  0.0581, -0.0294,  0.0154, -0.0524, -0.0345, -0.0896, -0.0972,\n","         0.0742, -0.0360, -0.0624,  0.0558, -0.0155,  0.0944, -0.0256,  0.0330,\n","        -0.0339,  0.0102, -0.0313,  0.0378,  0.0945,  0.0516,  0.0905, -0.0068,\n","        -0.0480,  0.0047, -0.0101,  0.0159,  0.0123,  0.0081, -0.0227,  0.0719,\n","        -0.0500, -0.0148,  0.0014, -0.0990, -0.0476, -0.0772,  0.0749,  0.0579,\n","         0.0348,  0.0828,  0.0040, -0.0983,  0.0519,  0.0715, -0.0695,  0.0353,\n","         0.0111,  0.0414,  0.0267,  0.0704,  0.0966,  0.0561, -0.0895, -0.0112,\n","         0.0244, -0.0855,  0.0741, -0.0169,  0.0806,  0.0364, -0.0460, -0.0708,\n","        -0.0234, -0.0690,  0.0912, -0.0198,  0.0560, -0.0923, -0.0191,  0.0723,\n","        -0.0498, -0.0692, -0.0081, -0.0869, -0.0146, -0.0728, -0.0717, -0.0291,\n","         0.0041, -0.0866,  0.0837, -0.0719,  0.0169, -0.0703, -0.0148,  0.0263,\n","         0.0859, -0.0849,  0.0308,  0.0992], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_query.weight:\n","Parameter containing:\n","tensor([[-1.,  1.,  1.,  ...,  1.,  1., -1.],\n","        [-1.,  1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","        ...,\n","        [-1.,  1.,  1.,  ..., -1.,  1., -1.],\n","        [-1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1., -1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.conv2.lin_query.bias:\n","Parameter containing:\n","tensor([ 0.0844, -0.0540,  0.0126, -0.0950,  0.0963,  0.0158,  0.0484, -0.0252,\n","        -0.0592, -0.0308, -0.0575,  0.0020,  0.0458,  0.0818,  0.0884, -0.0058,\n","        -0.0778,  0.0817, -0.0452,  0.0860,  0.0510,  0.0915, -0.0950,  0.0601,\n","         0.0545,  0.0739, -0.0680,  0.0799,  0.0136,  0.0287, -0.0594, -0.0541,\n","         0.0699, -0.0706,  0.0047,  0.0079,  0.0449, -0.0395,  0.0789, -0.0041,\n","         0.0744, -0.0185, -0.0451,  0.0060, -0.0579,  0.0737, -0.0798, -0.0454,\n","        -0.0783,  0.0356,  0.0202, -0.0507, -0.0163, -0.0913,  0.0450, -0.0299,\n","         0.0291, -0.0776, -0.0830,  0.0933,  0.0382,  0.0338,  0.0806,  0.0377,\n","        -0.0619,  0.0079, -0.0473,  0.0775,  0.0367, -0.0272, -0.0228,  0.0356,\n","         0.0633,  0.0148, -0.0781,  0.0601, -0.0574, -0.0071,  0.0348,  0.0293,\n","        -0.0004,  0.0148, -0.0091, -0.0914,  0.0584, -0.0131,  0.0069,  0.0793,\n","         0.0437, -0.0174,  0.0669, -0.0204, -0.0894, -0.0581,  0.0307,  0.0181,\n","        -0.0044,  0.0399,  0.0194,  0.0123], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_value.weight:\n","Parameter containing:\n","tensor([[ 1., -1.,  1.,  ...,  1.,  1.,  1.],\n","        [-1., -1.,  1.,  ..., -1.,  1.,  1.],\n","        [ 1., -1.,  1.,  ..., -1.,  1., -1.],\n","        ...,\n","        [-1., -1., -1.,  ..., -1., -1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1., -1.],\n","        [-1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.conv2.lin_value.bias:\n","Parameter containing:\n","tensor([ 0.0306, -0.0675,  0.0779, -0.0751,  0.0946,  0.0238,  0.0302,  0.0231,\n","         0.0905, -0.0692, -0.0250, -0.0581, -0.0854,  0.0074,  0.0140, -0.0213,\n","         0.0408, -0.0691, -0.0963,  0.0497,  0.0574,  0.0611, -0.0365,  0.0188,\n","         0.0154,  0.0268, -0.0787, -0.0108,  0.0175,  0.0115,  0.0355,  0.0209,\n","         0.0909,  0.0026, -0.0055, -0.0443, -0.0840, -0.0966,  0.0668,  0.0801,\n","         0.0125,  0.0825, -0.0179,  0.0365, -0.0724,  0.0683,  0.0884, -0.0132,\n","         0.0536, -0.0181, -0.0505, -0.0995,  0.0074,  0.0134,  0.0057,  0.0421,\n","        -0.0250, -0.0813,  0.0889, -0.0230,  0.0081,  0.0937,  0.0527,  0.0064,\n","        -0.0635,  0.0295,  0.0940,  0.0128, -0.0440, -0.0997,  0.0727, -0.0642,\n","         0.0064, -0.0042,  0.0485,  0.0016, -0.0898,  0.0380, -0.0373,  0.0329,\n","        -0.0438, -0.0771,  0.0502,  0.0544,  0.0896,  0.0860,  0.0351, -0.0568,\n","        -0.0504, -0.0295,  0.0136,  0.0565,  0.0154, -0.0799,  0.0566,  0.0004,\n","        -0.0276, -0.0160,  0.0806, -0.0563], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.conv2.lin_skip.weight:\n","Parameter containing:\n","tensor([[ 1., -1., -1.,  ...,  1., -1., -1.],\n","        [-1., -1.,  1.,  ..., -1., -1., -1.],\n","        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n","        ...,\n","        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","        [ 1., -1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.conv2.lin_skip.bias:\n","Parameter containing:\n","tensor([-0.0308,  0.0801,  0.0266, -0.0314,  0.0104,  0.0130, -0.0156,  0.0803,\n","         0.0438, -0.0490, -0.0382, -0.0941, -0.0902, -0.0199, -0.0012,  0.0091,\n","        -0.0841,  0.0825,  0.0716,  0.0114,  0.0145,  0.0292, -0.0095, -0.0523,\n","        -0.0435,  0.0970, -0.0484, -0.0765,  0.0037,  0.0982,  0.0957, -0.0860,\n","         0.0990, -0.0020,  0.0885,  0.0925, -0.0574,  0.0311,  0.0379,  0.0964,\n","         0.0221, -0.0952, -0.0198,  0.0791,  0.0117, -0.0456, -0.0678, -0.0059,\n","        -0.0833, -0.0743,  0.0641,  0.0344,  0.0156,  0.0787, -0.0277, -0.0554,\n","         0.0258,  0.0452,  0.0385, -0.0764,  0.0068, -0.0177, -0.0807,  0.0157,\n","         0.0582, -0.0685, -0.0224,  0.0935, -0.0355, -0.0810,  0.0225,  0.0638,\n","        -0.0300,  0.0542, -0.0498,  0.0452,  0.0785, -0.0273,  0.0495,  0.0386,\n","        -0.0396, -0.0357,  0.0272,  0.0535, -0.0344,  0.0526,  0.0696,  0.0649,\n","        -0.0151, -0.0117, -0.0287, -0.0673, -0.0992,  0.0611, -0.0836,  0.0084,\n","         0.0388, -0.0170, -0.0613,  0.0066], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for gcn.bn.weight:\n","Parameter containing:\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for gcn.bn.bias:\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Weight matrix for clf.emotion_att.lin.weight:\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ..., -1.,  1., -1.],\n","        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n","        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n","        ...,\n","        [-1.,  1., -1.,  ...,  1., -1., -1.],\n","        [-1., -1.,  1.,  ..., -1., -1., -1.],\n","        [-1.,  1., -1.,  ...,  1.,  1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for clf.emotion_att.lin.bias:\n","Parameter containing:\n","tensor([ 0.0310,  0.0380, -0.0270,  0.0616,  0.0820,  0.0194,  0.0414,  0.0748,\n","         0.0330,  0.0831,  0.0034,  0.0888,  0.0091,  0.0931, -0.0020, -0.0580,\n","         0.0661, -0.0747, -0.0491,  0.0810,  0.0530,  0.0116, -0.0121,  0.0282,\n","        -0.0779,  0.0609, -0.0757, -0.0821,  0.0575,  0.0776,  0.0181, -0.0829,\n","         0.0946, -0.0726, -0.0235,  0.0449, -0.0922,  0.0536, -0.0730,  0.0249,\n","         0.0904,  0.0433, -0.0917,  0.0633,  0.0089,  0.0950,  0.0087, -0.0402,\n","        -0.0597,  0.0468,  0.0204,  0.0430,  0.0969,  0.0721, -0.0305,  0.0817,\n","        -0.0891,  0.0436,  0.0550, -0.0598,  0.0487,  0.0882, -0.0499,  0.0563,\n","        -0.0053, -0.0135,  0.0023,  0.0129,  0.0088,  0.0951,  0.0256,  0.0588,\n","         0.0467, -0.0100,  0.0629,  0.0385,  0.0327, -0.0063,  0.0411,  0.0238,\n","        -0.0555,  0.0076, -0.0277,  0.0397,  0.0540, -0.0323,  0.0654,  0.0193,\n","         0.0073, -0.0495,  0.0974,  0.0709, -0.0407,  0.0425, -0.0466, -0.0998,\n","        -0.0476,  0.0579,  0.0170, -0.0154], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin1.weight:\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  ...,  1.,  1., -1.],\n","        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n","        [-1.,  1.,  1.,  ...,  1., -1., -1.],\n","        ...,\n","        [ 1., -1., -1.,  ...,  1., -1., -1.],\n","        [-1., -1.,  1.,  ...,  1., -1.,  1.],\n","        [ 1.,  1., -1.,  ..., -1., -1.,  1.]], device='cuda:0',\n","       requires_grad=True)\n","Bias vector for clf.lin1.bias:\n","Parameter containing:\n","tensor([ 0.0762,  0.0880,  0.0464, -0.0047, -0.0801,  0.0563, -0.0795,  0.0890,\n","        -0.0352,  0.0643,  0.0485, -0.0053,  0.0714,  0.0026, -0.0216, -0.0704,\n","        -0.0150, -0.0501,  0.0022, -0.0042, -0.0394, -0.0176, -0.0425, -0.0123,\n","         0.0639,  0.0825,  0.0975,  0.0034, -0.0228,  0.0310, -0.0805, -0.0970,\n","         0.0286,  0.0184, -0.0883, -0.0630, -0.0171,  0.0793, -0.0963,  0.0190,\n","        -0.0941,  0.0329, -0.0340,  0.0827, -0.0255, -0.0977, -0.0589, -0.0200,\n","         0.0264,  0.0662, -0.0427, -0.0884,  0.0804, -0.0999,  0.0478, -0.0508,\n","        -0.0996, -0.0331,  0.0474, -0.0676, -0.0393,  0.0500,  0.0556, -0.0434,\n","         0.0044,  0.0449, -0.0820,  0.0411,  0.0597, -0.0488, -0.0330, -0.0831,\n","        -0.0663,  0.0483,  0.0922,  0.0776,  0.0448,  0.0970, -0.0049,  0.0961,\n","        -0.0691, -0.0696,  0.0078,  0.0822,  0.0409, -0.0339, -0.0016,  0.0115,\n","         0.0268,  0.0511, -0.0959,  0.0652, -0.0786, -0.0495,  0.0145, -0.0486,\n","        -0.0473,  0.0061, -0.0123, -0.0757], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin2.weight:\n","Parameter containing:\n","tensor([[-1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","         -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,\n","          1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n","         -1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n","          1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n","         -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n","         -1.,  1.],\n","        [-1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","          1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n","         -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n","         -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,\n","          1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,\n","         -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n","         -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n","          1.,  1.],\n","        [ 1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n","          1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n","         -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n","          1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n","         -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n","         -1., -1.],\n","        [ 1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n","          1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n","         -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,\n","          1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,\n","          1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","         -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n","          1., -1.]], device='cuda:0', requires_grad=True)\n","Bias vector for clf.lin2.bias:\n","Parameter containing:\n","tensor([-0.0843,  0.0371, -0.0800, -0.0725], device='cuda:0',\n","       requires_grad=True)\n","Weight matrix for clf.lin_7.weight:\n","Parameter containing:\n","tensor([[ 1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n","         -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n","         -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n","          1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n","         -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,\n","         -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.,\n","         -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","         -1., -1.],\n","        [ 1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n","         -1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","         -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,\n","          1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.,\n","         -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n","         -1., -1.],\n","        [-1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n","          1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n","          1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n","          1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,\n","          1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,\n","          1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,\n","         -1., -1.],\n","        [ 1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","         -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n","         -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,\n","          1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,\n","         -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n","         -1., -1.],\n","        [ 1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n","         -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n","         -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n","          1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n","          1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,\n","          1., -1.],\n","        [ 1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n","         -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,\n","         -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.,\n","          1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.,\n","          1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n","          1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n","          1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n","          1.,  1.],\n","        [-1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,\n","          1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,\n","          1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,\n","         -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n","         -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,\n","         -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,\n","          1.,  1.]], device='cuda:0', requires_grad=True)\n","Bias vector for clf.lin_7.bias:\n","Parameter containing:\n","tensor([-0.0149, -0.0465,  0.0099,  0.0570,  0.0250,  0.0233,  0.0425],\n","       device='cuda:0', requires_grad=True)\n","Weight matrix for clf.linear.weight:\n","Parameter containing:\n","tensor([[-1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n","         -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n","         -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n","         -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,\n","          1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n","          1., -1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n","         -1., -1.],\n","        [-1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n","          1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,\n","          1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,\n","         -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n","          1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n","         -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n","         -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n","          1., -1.],\n","        [-1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n","         -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n","         -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","         -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,\n","         -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,\n","         -1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","         -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n","         -1.,  1.],\n","        [ 1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n","          1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n","          1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n","         -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n","         -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n","         -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n","         -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n","          1., -1.]], device='cuda:0', requires_grad=True)\n","Bias vector for clf.linear.bias:\n","Parameter containing:\n","tensor([ 0.0163,  0.0140, -0.0578, -0.0828], device='cuda:0',\n","       requires_grad=True)\n"]}]},{"cell_type":"code","source":["!python eval.py --dataset=\"iemocap_4\" --modalities=\"atv\" --model='model'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OEyfEDmm7T9O","executionInfo":{"status":"ok","timestamp":1698922808296,"user_tz":-60,"elapsed":15083,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"0c4a7e0f-8edf-4ac5-8f74-ecba67fab4d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test: 100% 1/1 [00:00<00:00,  1.28it/s]\n","              precision    recall  f1-score   support\n","\n","           0     0.1905    0.0278    0.0485       144\n","           1     0.2637    0.7061    0.3840       245\n","           2     0.3784    0.1094    0.1697       384\n","           3     0.1419    0.1294    0.1354       170\n","\n","    accuracy                         0.2556       943\n","   macro avg     0.2436    0.2432    0.1844       943\n","weighted avg     0.2773    0.2556    0.2007       943\n","\n","F1 Score: 0.20068418863442186\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Master_2023_sept/COGMEN-main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_RSyiHM3iMw","executionInfo":{"status":"ok","timestamp":1698925824862,"user_tz":-60,"elapsed":542,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"d8193792-7480-4d0c-fb6e-73329151d097"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Master_2023_sept/COGMEN-main\n"]}]},{"cell_type":"code","source":["import cogmen"],"metadata":{"id":"3NjiTsin3uTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = cogmen.utils.load_pkl('/content/drive/MyDrive/Master_2023_sept/COGMEN-main/data/iemocap/data_iemocap.pkl')"],"metadata":{"id":"F6SOnAwe31Li"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyClass:\n","    def __init__(self, args):\n","        self.args = args\n","    def pr(self):\n","      print(self.args)\n","\n"],"metadata":{"id":"r927afyr47J2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args.data = data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"Qoco-xBF4Epm","executionInfo":{"status":"error","timestamp":1698926239916,"user_tz":-60,"elapsed":419,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"c3f8efe2-8da5-4dbb-917b-6ba192666a07"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-1e2aa2634652>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"]}]},{"cell_type":"code","source":["testset = cogmen.Dataset(data[\"test\"],**args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"IF6StedW3YUe","executionInfo":{"status":"error","timestamp":1698925892860,"user_tz":-60,"elapsed":406,"user":{"displayName":"Tijana Djurkic","userId":"06093330132114198133"}},"outputId":"1fdafa24-ca84-43d4-dd22-9f375a17b3de"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-e64a5fb7d6ad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcogmen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: Dataset.__init__() missing 1 required positional argument: 'args'"]}]},{"cell_type":"code","source":["import torch\n","test_dataset=\n","# Assuming you have a test_dataset\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f'Test Accuracy: {accuracy * 100:.2f}%')\n","\n"],"metadata":{"id":"OKtjxY-8qQuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 8\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","Y_pred = model.predict_generator(test_dataset, 3254 // batch_size+1)\n","\n","y_pred = np.argmax(Y_pred, axis=1)\n","\n","print('                     ')\n","print('Confusion Matrix')\n","print('                     ')\n","print(confusion_matrix(test_dataset.classes, y_pred))\n","print('------------------------------------------------')\n","print('Classification Report')\n","print('                     ')\n","target_names = ['0', '1', '2','3']\n","print(classification_report(test_dataset.classes, y_pred, target_names=target_names))"],"metadata":{"id":"frdlexCe2hyl"},"execution_count":null,"outputs":[]}]}